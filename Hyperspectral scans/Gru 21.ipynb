{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864b57f9-1f2d-4ccc-b126-4285f78e6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Indices weed-crop.xlsx\", sheet_name=\"winter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70be28f3-b7da-4851-9ddb-16b9822e31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 427 entries, 0 to 426\n",
      "Data columns (total 34 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   species  427 non-null    object \n",
      " 1   RARSa    427 non-null    float64\n",
      " 2   RARSb    427 non-null    float64\n",
      " 3   NDVI705  427 non-null    float64\n",
      " 4   PSSRa    427 non-null    float64\n",
      " 5   PSSRb    427 non-null    float64\n",
      " 6   PSNDa    427 non-null    float64\n",
      " 7   PSNDb    427 non-null    float64\n",
      " 8   YI       427 non-null    float64\n",
      " 9   mSR      427 non-null    float64\n",
      " 10  mNDI     427 non-null    float64\n",
      " 11  DD       427 non-null    float64\n",
      " 12  RES      427 non-null    float64\n",
      " 13  RARSc    427 non-null    float64\n",
      " 14  SIPI     427 non-null    float64\n",
      " 15  PSSRc    427 non-null    float64\n",
      " 16  PRI      427 non-null    float64\n",
      " 17  CARI     427 non-null    float64\n",
      " 18  MSI      427 non-null    float64\n",
      " 19  WI       427 non-null    float64\n",
      " 20  TM5TM7   427 non-null    float64\n",
      " 21  NDVIa    427 non-null    float64\n",
      " 22  NDVIb    427 non-null    float64\n",
      " 23  NDVIc    427 non-null    float64\n",
      " 24  TBRIa    427 non-null    float64\n",
      " 25  TBRIb    427 non-null    float64\n",
      " 26  NDWIa    427 non-null    float64\n",
      " 27  NDWIb    427 non-null    float64\n",
      " 28  NDWIc    427 non-null    float64\n",
      " 29  WABIa    427 non-null    float64\n",
      " 30  WABIb    427 non-null    float64\n",
      " 31  WABIc    427 non-null    float64\n",
      " 32  NDlma    427 non-null    float64\n",
      " 33  NDMI     427 non-null    float64\n",
      "dtypes: float64(33), object(1)\n",
      "memory usage: 113.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RARSa</th>\n",
       "      <th>RARSb</th>\n",
       "      <th>NDVI705</th>\n",
       "      <th>PSSRa</th>\n",
       "      <th>PSSRb</th>\n",
       "      <th>PSNDa</th>\n",
       "      <th>PSNDb</th>\n",
       "      <th>YI</th>\n",
       "      <th>mSR</th>\n",
       "      <th>mNDI</th>\n",
       "      <th>...</th>\n",
       "      <th>TBRIa</th>\n",
       "      <th>TBRIb</th>\n",
       "      <th>NDWIa</th>\n",
       "      <th>NDWIb</th>\n",
       "      <th>NDWIc</th>\n",
       "      <th>WABIa</th>\n",
       "      <th>WABIb</th>\n",
       "      <th>WABIc</th>\n",
       "      <th>NDlma</th>\n",
       "      <th>NDMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.479991</td>\n",
       "      <td>0.039907</td>\n",
       "      <td>0.374527</td>\n",
       "      <td>6.304836</td>\n",
       "      <td>5.481765</td>\n",
       "      <td>0.714953</td>\n",
       "      <td>0.680246</td>\n",
       "      <td>-0.006930</td>\n",
       "      <td>1.219566</td>\n",
       "      <td>0.524746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996485</td>\n",
       "      <td>0.957436</td>\n",
       "      <td>0.499127</td>\n",
       "      <td>0.213137</td>\n",
       "      <td>0.497993</td>\n",
       "      <td>-0.004312</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.069035</td>\n",
       "      <td>0.105343</td>\n",
       "      <td>-0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.082271</td>\n",
       "      <td>0.013327</td>\n",
       "      <td>0.062810</td>\n",
       "      <td>1.556932</td>\n",
       "      <td>1.269091</td>\n",
       "      <td>0.055084</td>\n",
       "      <td>0.059466</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.227350</td>\n",
       "      <td>0.084494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020331</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.062240</td>\n",
       "      <td>0.040186</td>\n",
       "      <td>0.069550</td>\n",
       "      <td>0.122955</td>\n",
       "      <td>0.120615</td>\n",
       "      <td>0.123851</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>0.004076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.260412</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.174108</td>\n",
       "      <td>3.244437</td>\n",
       "      <td>2.828939</td>\n",
       "      <td>0.528795</td>\n",
       "      <td>0.477662</td>\n",
       "      <td>-0.016645</td>\n",
       "      <td>0.610123</td>\n",
       "      <td>0.289688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923857</td>\n",
       "      <td>0.893970</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>0.129609</td>\n",
       "      <td>0.294296</td>\n",
       "      <td>-0.524922</td>\n",
       "      <td>-0.509767</td>\n",
       "      <td>-0.552210</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>-0.011542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.433957</td>\n",
       "      <td>0.031622</td>\n",
       "      <td>0.331348</td>\n",
       "      <td>5.229335</td>\n",
       "      <td>4.574821</td>\n",
       "      <td>0.678938</td>\n",
       "      <td>0.641244</td>\n",
       "      <td>-0.009284</td>\n",
       "      <td>1.053960</td>\n",
       "      <td>0.463717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982449</td>\n",
       "      <td>0.953540</td>\n",
       "      <td>0.454845</td>\n",
       "      <td>0.185480</td>\n",
       "      <td>0.449475</td>\n",
       "      <td>-0.069111</td>\n",
       "      <td>-0.064806</td>\n",
       "      <td>-0.138272</td>\n",
       "      <td>0.089703</td>\n",
       "      <td>-0.003392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.492896</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>0.370343</td>\n",
       "      <td>5.995831</td>\n",
       "      <td>5.265335</td>\n",
       "      <td>0.714115</td>\n",
       "      <td>0.680783</td>\n",
       "      <td>-0.007561</td>\n",
       "      <td>1.211962</td>\n",
       "      <td>0.530809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993282</td>\n",
       "      <td>0.959521</td>\n",
       "      <td>0.491747</td>\n",
       "      <td>0.209246</td>\n",
       "      <td>0.492381</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>-0.055959</td>\n",
       "      <td>0.102968</td>\n",
       "      <td>-0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.537403</td>\n",
       "      <td>0.045757</td>\n",
       "      <td>0.418957</td>\n",
       "      <td>7.043973</td>\n",
       "      <td>6.168050</td>\n",
       "      <td>0.751366</td>\n",
       "      <td>0.720984</td>\n",
       "      <td>-0.005704</td>\n",
       "      <td>1.349123</td>\n",
       "      <td>0.585265</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011581</td>\n",
       "      <td>0.964434</td>\n",
       "      <td>0.540127</td>\n",
       "      <td>0.233098</td>\n",
       "      <td>0.538271</td>\n",
       "      <td>0.072542</td>\n",
       "      <td>0.073784</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.117877</td>\n",
       "      <td>0.002021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.673341</td>\n",
       "      <td>0.167071</td>\n",
       "      <td>0.525403</td>\n",
       "      <td>12.239014</td>\n",
       "      <td>10.427906</td>\n",
       "      <td>0.848931</td>\n",
       "      <td>0.824990</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>1.912162</td>\n",
       "      <td>0.749449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038022</td>\n",
       "      <td>0.973905</td>\n",
       "      <td>0.715957</td>\n",
       "      <td>0.427457</td>\n",
       "      <td>0.741952</td>\n",
       "      <td>0.309083</td>\n",
       "      <td>0.315830</td>\n",
       "      <td>0.251761</td>\n",
       "      <td>0.207107</td>\n",
       "      <td>0.012492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RARSa       RARSb     NDVI705       PSSRa       PSSRb       PSNDa  \\\n",
       "count  427.000000  427.000000  427.000000  427.000000  427.000000  427.000000   \n",
       "mean     0.479991    0.039907    0.374527    6.304836    5.481765    0.714953   \n",
       "std      0.082271    0.013327    0.062810    1.556932    1.269091    0.055084   \n",
       "min      0.260412    0.015435    0.174108    3.244437    2.828939    0.528795   \n",
       "25%      0.433957    0.031622    0.331348    5.229335    4.574821    0.678938   \n",
       "50%      0.492896    0.037196    0.370343    5.995831    5.265335    0.714115   \n",
       "75%      0.537403    0.045757    0.418957    7.043973    6.168050    0.751366   \n",
       "max      0.673341    0.167071    0.525403   12.239014   10.427906    0.848931   \n",
       "\n",
       "            PSNDb          YI         mSR        mNDI  ...       TBRIa  \\\n",
       "count  427.000000  427.000000  427.000000  427.000000  ...  427.000000   \n",
       "mean     0.680246   -0.006930    1.219566    0.524746  ...    0.996485   \n",
       "std      0.059466    0.003811    0.227350    0.084494  ...    0.020331   \n",
       "min      0.477662   -0.016645    0.610123    0.289688  ...    0.923857   \n",
       "25%      0.641244   -0.009284    1.053960    0.463717  ...    0.982449   \n",
       "50%      0.680783   -0.007561    1.211962    0.530809  ...    0.993282   \n",
       "75%      0.720984   -0.005704    1.349123    0.585265  ...    1.011581   \n",
       "max      0.824990    0.011261    1.912162    0.749449  ...    1.038022   \n",
       "\n",
       "            TBRIb       NDWIa       NDWIb       NDWIc       WABIa       WABIb  \\\n",
       "count  427.000000  427.000000  427.000000  427.000000  427.000000  427.000000   \n",
       "mean     0.957436    0.499127    0.213137    0.497993   -0.004312   -0.000136   \n",
       "std      0.010765    0.062240    0.040186    0.069550    0.122955    0.120615   \n",
       "min      0.893970    0.329630    0.129609    0.294296   -0.524922   -0.509767   \n",
       "25%      0.953540    0.454845    0.185480    0.449475   -0.069111   -0.064806   \n",
       "50%      0.959521    0.491747    0.209246    0.492381    0.013464    0.013057   \n",
       "75%      0.964434    0.540127    0.233098    0.538271    0.072542    0.073784   \n",
       "max      0.973905    0.715957    0.427457    0.741952    0.309083    0.315830   \n",
       "\n",
       "            WABIc       NDlma        NDMI  \n",
       "count  427.000000  427.000000  427.000000  \n",
       "mean    -0.069035    0.105343   -0.000520  \n",
       "std      0.123851    0.024212    0.004076  \n",
       "min     -0.552210    0.054411   -0.011542  \n",
       "25%     -0.138272    0.089703   -0.003392  \n",
       "50%     -0.055959    0.102968   -0.000605  \n",
       "75%      0.009367    0.117877    0.002021  \n",
       "max      0.251761    0.207107    0.012492  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()       # Shows the first five rows\n",
    "df.info()       # Gives an overview of columns, data types, and non-null counts\n",
    "df.describe()   # Provides summary statistics for numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b07fbca-40f0-48f4-997d-599221148bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8023255813953488\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAIhCAYAAADpZpN1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACrw0lEQVR4nOzdeVhV1f4/8PdmOgwHjsjg0WQUAXMAc0o04DjhmJqmOINTalmJI1xTMBGxQZOrmSmD3VLpat60X2YqR80hMYU0vA4piQkOCBwEZNy/P7zsr0cGOYQS8H49z3quZ5211v6sDfb4uWvttQVRFEUQERERERFRg6RX3wEQERERERFR7TGpIyIiIiIiasCY1BERERERETVgTOqIiIiIiIgaMCZ1REREREREDRiTOiIiIiIiogaMSR0REREREVEDxqSOiIiIiIioAWNSR0RERERE1IAxqSOiJiE2NhaCIFRaFixY8EyumZKSgtDQUKSmpj6T8f+K1NRUCIKADz/8sL5DqbUTJ04gNDQU2dnZ9R3Kc7V06VLY29vDwMAAzZo1q+9wqhUQEKD1d83IyAht2rTBggULoNFo6i0uX19f+Pr61tv1nxQaGlrlf5/++c9/1nd4FeTn5yM0NBRqtbq+QyGi/zGo7wCIiJ6nmJgYuLu7a9W1atXqmVwrJSUFYWFh8PX1haOj4zO5RlN24sQJhIWFISAg4G+f3NSV//znPwgPD8c//vEPDBo0CDKZrL5DeioTExMcPnwYAJCdnY1///vf+Oijj/Drr7/iwIED9Rzd38v+/fuhUCi06pycnOopmqrl5+cjLCwMAP5WyTFRU8akjoialA4dOqBr1671HcZfUlxcDEEQYGDQNP8TXlBQAGNj4/oOo15cuHABAPD222/D1ta22rYFBQUwMTF5HmFVS09PDy+//LL0eeDAgbh27Rp+/PFHXL9+/W+ZtNSXLl26wNraus7Hzc/Ph6mpaZ2PS0R/H9x+SUT0mJ07d6Jnz54wMzODXC6Hn58fzp07p9XmzJkz8Pf3h6OjI0xMTODo6Ihx48bhjz/+kNrExsbi9ddfBwCoVCppK1VsbCwAwNHREQEBARWu/+S2MLVaDUEQ8MUXX2D+/Pl44YUXIJPJcPXqVQDAwYMH0bdvX1hYWMDU1BS9evXCoUOHajX38i2qhw8fxowZM2BlZQULCwtMnjwZeXl5yMjIwJgxY9CsWTO0bNkSCxYsQHFxsdS/fEvnmjVrEB4eDnt7exgbG6Nr166VxvTTTz+hb9++MDc3h6mpKby8vPDdd99VGtOBAwcwdepU2NjYwNTUFMHBwVi4cCGARysZ5fe3fDvYzp07MWDAALRs2RImJiZo164dlixZgry8PK3xAwICIJfLcfXqVQwePBhyuRx2dnaYP38+CgsLtdoWFhZixYoVaNeuHYyNjWFlZQWVSoUTJ05IbURRxMaNG+Hp6QkTExNYWlpi9OjRuHbtmtZY586dw9ChQ2FrawuZTIZWrVphyJAhuHnzZpU/H0dHRyxduhQA0KJFCwiCgNDQUOm7oUOHYvfu3ejcuTOMjY2llZQLFy5g+PDhsLS0hLGxMTw9PREXF6c1dvnv2VdffYXFixejZcuWkMvlGDZsGG7fvo3c3FzMnDkT1tbWsLa2RmBgIB48eFBlrE9T/n+s3L59W6q7evUqAgMD0bZtW5iamuKFF17AsGHDcP78+Upj3b59O/7xj3+gVatWsLCwQL9+/XDp0iWttqIoYs2aNXBwcICxsTFeeuklfP/995XGdOPGDUycOFH6mbRr1w4fffQRysrKpDblv+MffPABIiMjpf8G+Pr64vLlyyguLsaSJUvQqlUrKBQKjBw5Enfu3Kn1fXpSdHQ0PDw8YGxsjObNm2PkyJG4ePGiVpvy3+nz589jwIABMDc3R9++fQEARUVFWLlyJdzd3SGTyWBjY4PAwEDcvXtXa4zDhw/D19cXVlZWMDExgb29PUaNGoX8/HykpqbCxsYGABAWFib93avsv2dE9Pw0zf+bl4iarNLSUpSUlGjVla94rVq1CkuXLkVgYCCWLl2KoqIifPDBB3jllVdw+vRpvPjiiwAe/cPOzc0N/v7+aN68OdLT0/Hpp5+iW7duSElJgbW1NYYMGYJVq1YhJCQEGzZswEsvvQQAaNOmTa3iDg4ORs+ePbFp0ybo6enB1tYW//rXvzB58mQMHz4ccXFxMDQ0xGeffQY/Pz/88MMP0j/kdDV9+nS89tpr2LFjB86dO4eQkBCUlJTg0qVLeO211zBz5kwcPHgQkZGRaNWqFYKCgrT6//Of/4SDgwPWrVuHsrIyrFmzBoMGDcKRI0fQs2dPAMCRI0fQv39/dOrUCVu3boVMJsPGjRsxbNgwbN++HWPHjtUac+rUqRgyZAi++OIL5OXloWvXrsjPz0dUVBR2796Nli1bAoD0M7py5QoGDx6Md999F2ZmZvjvf/+LyMhInD59WtoKWK64uBivvvoqpk2bhvnz5+Po0aN4//33oVAosGzZMgBASUkJBg0ahGPHjuHdd99Fnz59UFJSglOnTuHGjRvw8vICALzxxhuIjY3F22+/jcjISNy/fx8rVqyAl5cXkpOT0aJFC+Tl5aF///5wcnLChg0b0KJFC2RkZCAhIQG5ublV/ly++eYbbNiwAVu3bpW26bVu3Vr6/uzZs7h48SKWLl0KJycnmJmZ4dKlS/Dy8oKtrS3Wr18PKysr/Otf/0JAQABu376NRYsWaV0jJCQEKpUKsbGxSE1NxYIFCzBu3DgYGBjAw8MD27dvl34nzM3NsX79+hr/Xj3u+vXrMDAwgLOzs1R369YtWFlZYfXq1bCxscH9+/cRFxeHHj164Ny5c3Bzc6sQa69evbBlyxZoNBosXrwYw4YNw8WLF6Gvrw/gUdIRFhaGadOmYfTo0UhLS8OMGTNQWlqqNd7du3fh5eWFoqIivP/++3B0dMS+ffuwYMEC/P7779i4caPWtTds2IBOnTphw4YNyM7Oxvz58zFs2DD06NEDhoaGiI6Oxh9//IEFCxZg+vTp+Pbbb2t0X57875MgCNJcIiIiEBISgnHjxiEiIgKZmZkIDQ1Fz549kZiYiLZt20r9ioqK8Oqrr+KNN97AkiVLUFJSgrKyMgwfPhzHjh3DokWL4OXlhT/++APLly+Hr68vzpw5AxMTE6SmpmLIkCF45ZVXEB0djWbNmuHPP//E/v37UVRUhJYtW2L//v0YOHAgpk2bhunTpwOAlOgRUT0RiYiagJiYGBFApaW4uFi8ceOGaGBgIM6dO1erX25urqhUKsUxY8ZUOXZJSYn44MED0czMTPzkk0+k+q+//loEICYkJFTo4+DgIE6ZMqVCvY+Pj+jj4yN9TkhIEAGI3t7eWu3y8vLE5s2bi8OGDdOqLy0tFT08PMTu3btXczdE8fr16yIA8YMPPpDqyu/Rk/dgxIgRIgDx448/1qr39PQUX3rppQpjtmrVSiwoKJDqNRqN2Lx5c7Ffv35S3csvvyza2tqKubm5Ul1JSYnYoUMHsXXr1mJZWZlWTJMnT64whw8++EAEIF6/fr3auZaVlYnFxcXikSNHRABicnKy9N2UKVNEAGJ8fLxWn8GDB4tubm7S523btokAxM8//7zK65w8eVIEIH700Uda9WlpaaKJiYm4aNEiURRF8cyZMyIAcc+ePdXGXZnly5eLAMS7d+9q1Ts4OIj6+vripUuXtOr9/f1FmUwm3rhxQ6t+0KBBoqmpqZidnS2K4v/9nj35+/Tuu++KAMS3335bq37EiBFi8+bNnxrvlClTRDMzM7G4uFgsLi4W7927J3766aeinp6eGBISUm3fkpISsaioSGzbtq04b948qb481sGDB2u1j4+PFwGIJ0+eFEVRFLOyskRjY2Nx5MiRWu2OHz8uAtD6e7ZkyRIRgPjzzz9rtZ09e7YoCIJ0X8t/xz08PMTS0lKp3bp160QA4quvvqrVv/z+5eTkVDvX8p/rk+WFF16Q5mJiYlJhzjdu3BBlMpk4fvx4qa78dzo6Olqr7fbt20UA4q5du7TqExMTRQDixo0bRVEUxX//+98iADEpKanKeO/evSsCEJcvX17tvIjo+eH2SyJqUrZt24bExEStYmBggB9++AElJSWYPHkySkpKpGJsbAwfHx+tU94ePHiAxYsXw8XFBQYGBjAwMIBcLkdeXl6FrVB1ZdSoUVqfT5w4gfv372PKlCla8ZaVlWHgwIFITEyssNWwpoYOHar1uV27dgCAIUOGVKh/fMtpuddee03rmTdzc3MMGzYMR48eRWlpKfLy8vDzzz9j9OjRkMvlUjt9fX1MmjQJN2/erLCN7sn5P821a9cwfvx4KJVK6Ovrw9DQED4+PgBQ4WckCAKGDRumVdepUyetuX3//fcwNjbG1KlTq7zmvn37IAgCJk6cqPUzUSqV8PDwkH6HXFxcYGlpicWLF2PTpk1ISUnRaW5V6dSpE1xdXbXqDh8+jL59+8LOzk6rPiAgAPn5+Th58qRWvS4/+/v379doC2ZeXh4MDQ1haGgIa2trzJ49G2PHjkV4eLhWu5KSEqxatQovvvgijIyMYGBgACMjI1y5cqXSv1evvvpqhfkDkH5uJ0+exMOHDzFhwgStdl5eXnBwcNCqO3z4MF588UV0795dqz4gIACiKFZY3R08eDD09P7vn1DV3Sfg0dbOmjh48KDWf5v+3//7f9JcCgoKKmxxtLOzQ58+fSrd3vzk35l9+/ahWbNmGDZsmNbvp6enJ5RKpfT76enpCSMjI8ycORNxcXEVtg4T0d8Tt18SUZPSrl27Sg9KKX+2p1u3bpX2e/wfcOPHj8ehQ4fw3nvvoVu3brCwsIAgCBg8eDAKCgqeSdzl2wufjHf06NFV9rl//z7MzMx0vlbz5s21PhsZGVVZ//Dhwwr9lUplpXVFRUV48OABcnNzIYpihTkB/3cSaWZmplZ9ZW2r8uDBA7zyyiswNjbGypUr4erqClNTU6SlpeG1116r8DMyNTWtcPCKTCbTmtvdu3fRqlUrrd+DJ92+fRuiKKJFixaVfl++1VChUODIkSMIDw9HSEgIsrKy0LJlS8yYMQNLly6FoaFhjef6uMruUWZmpk73WZefPQA8fPhQKzGvjImJCY4ePQoAyMjIwEcffYTt27ejU6dOWLJkidQuKCgIGzZswOLFi+Hj4wNLS0vo6elh+vTplf69srKy0vpcfhJoedvyuVX1+/i4zMzMSk+orcv7VBMeHh6VHpRSfv2qfpY//vijVp2pqSksLCy06m7fvo3s7Gwppifdu3cPwKMt4gcPHsSaNWvw5ptvIi8vD87Oznj77bfxzjvv1GgeRPT8MakjIgKkf0j9+9//rvD/4j8uJycH+/btw/Lly7X+QVpYWIj79+/X+HrGxsYVDuIAHv3DqrJ/1AmCUGm8UVFRWicLPq6q5OJZy8jIqLTOyMgIcrkcBgYG0NPTQ3p6eoV2t27dAoAK9+DJ+Vfn8OHDuHXrFtRqtbQ6B+Avvc/OxsYGP/30E8rKyqpM7KytrSEIAo4dO1bpqwYer+vYsSN27NgBURTx66+/IjY2FitWrICJiYnW75UuKrtHVlZWOt3nZ0FPT0/r/0jp378/unTpgrCwMEyYMEFaRSx/RnTVqlVa/e/du1erV1aUJ31V/T4+nsT9He5TdcrnUlWMNfn7Ym1tDSsrK+zfv7/Sa5ibm0t/fuWVV/DKK6+gtLQUZ86cQVRUFN599120aNEC/v7+f2UqRPSMcPslEREAPz8/GBgY4Pfff0fXrl0rLcCjfyyJoljhH+1btmxBaWmpVt2TKwePc3R0xK+//qpVd/ny5QrbDqvSq1cvNGvWDCkpKVXGW9X/I/+s7d69W2tlIjc3F3v37sUrr7wCfX19mJmZoUePHti9e7fWvSkrK8O//vUvtG7dusI2wspUdX/L/0H75M/os88+q/WcBg0ahIcPH0qnl1Zm6NChEEURf/75Z6U/j44dO1boIwgCPDw8sHbtWjRr1gxnz56tdYyV6du3r5TkPm7btm0wNTWt8v8QeJZkMhk2bNiAhw8fYuXKlVK9IAgVfmbfffcd/vzzz1pd5+WXX4axsTG+/PJLrfoTJ05U2Dbct29fpKSkVLj/27ZtgyAIUKlUtYqhrvTs2RMmJib417/+pVV/8+ZNaYvt0wwdOhSZmZkoLS2t9PfzyYNogEdbonv06IENGzYAgHR/qvtvGxHVD67UERHhUZK1YsUK/OMf/8C1a9cwcOBAWFpa4vbt2zh9+jTMzMwQFhYGCwsLeHt744MPPoC1tTUcHR1x5MgRbN26tcJqQocOHQAAmzdvhrm5OYyNjeHk5AQrKytMmjQJEydOxJw5czBq1Cj88ccfWLNmTY1PkJPL5YiKisKUKVNw//59jB49Gra2trh79y6Sk5Nx9+5dfPrpp3V9m2pEX18f/fv3R1BQEMrKyhAZGQmNRiMdsQ88Osmvf//+UKlUWLBgAYyMjLBx40ZcuHAB27dvr9HKXHmS9Mknn2DKlCkwNDSEm5sbvLy8YGlpiVmzZmH58uUwNDTEl19+ieTk5FrPady4cYiJicGsWbNw6dIlqFQqlJWV4eeff0a7du3g7++PXr16YebMmQgMDMSZM2fg7e0NMzMzpKen46effkLHjh0xe/Zs7Nu3Dxs3bsSIESPg7OwMURSxe/duZGdno3///rWOsTLLly/Hvn37oFKpsGzZMjRv3hxffvklvvvuO6xZs6bCi66fFx8fHwwePBgxMTFYsmQJnJycMHToUMTGxsLd3R2dOnXCL7/8gg8++EDrhE9dWFpaYsGCBVi5ciWmT5+O119/HWlpaQgNDa2w/XLevHnYtm0bhgwZghUrVsDBwQHfffcdNm7ciNmzZ9fo/2R4lpo1a4b33nsPISEhmDx5MsaNG4fMzEyEhYXB2NgYy5cvf+oY/v7++PLLLzF48GC888476N69OwwNDXHz5k0kJCRg+PDhGDlyJDZt2oTDhw9jyJAhsLe3x8OHDxEdHQ0A6NevH4BHq3oODg74z3/+g759+6J58+bSfw+JqJ7U4yEtRETPTfkpiomJidW227Nnj6hSqUQLCwtRJpOJDg4O4ujRo8WDBw9KbW7evCmOGjVKtLS0FM3NzcWBAweKFy5cqPREy3Xr1olOTk6ivr6+CECMiYkRRfHRiYxr1qwRnZ2dRWNjY7Fr167i4cOHqzz98uuvv6403iNHjohDhgwRmzdvLhoaGoovvPCCOGTIkCrbl6vu9Msn71FVJy6Wn2z45JiRkZFiWFiY2Lp1a9HIyEjs3Lmz+MMPP1SI4dixY2KfPn1EMzMz0cTERHz55ZfFvXv3arV52s8tODhYbNWqlainp6d10uiJEyfEnj17iqampqKNjY04ffp08ezZs1o/g8rm8OScH1dQUCAuW7ZMbNu2rWhkZCRaWVmJffr0EU+cOKHVLjo6WuzRo4c0rzZt2oiTJ08Wz5w5I4qiKP73v/8Vx40bJ7Zp00Y0MTERFQqF2L17dzE2NrbSOVYWV2WnXw4ZMqTSPufPnxeHDRsmKhQK0cjISPTw8NC6B6JY9e+Zrr8TT6rq/pbHpaenJwYGBoqi+OiEx2nTpom2traiqamp2Lt3b/HYsWM1/jtR/vv3+NzKysrEiIgI0c7OTjQyMhI7deok7t27t8KYoiiKf/zxhzh+/HjRyspKNDQ0FN3c3MQPPvhA65TLyv7e1Ob+Pamm93PLli1ip06dRCMjI1GhUIjDhw8Xf/vtN6021d3z4uJi8cMPPxQ9PDxEY2NjUS6Xi+7u7uIbb7whXrlyRRTFR6e4jhw5UnRwcBBlMploZWUl+vj4iN9++63WWAcPHhQ7d+4symQyEUClp/kS0fMjiKIoPs8kkoiIGqfU1FQ4OTnhgw8+wIIFC+o7HCIioiaDz9QRERERERE1YEzqiIiIiIiIGjBuvyQiIiIiImrAuFJHRERERETUgDGpIyIiIiIiasCY1BERERERETVgfPn430hZWRlu3boFc3PzGr14l4iIiIiIGidRFJGbm4tWrVpBT6/6tTgmdX8jt27dgp2dXX2HQUREREREfxNpaWlo3bp1tW2Y1P2NmJubA3j0g7OwsKjnaIiIiIiIqL5oNBrY2dlJOUJ1mNT9jZRvubSwsGBSR0RERERENXosiwelEBERERERNWBM6oiIiIiIiBowJnVEREREREQNGJM6IiIiIiKiBoxJHRERERERUQPGpI6IiIiIiKgBY1JHRERERETUgDGpIyIiIiIiasCY1BERERERETVgTOqIiIiIiIgaMCZ1REREREREDRiTOiIiIiIiogaMSR0REREREVEDxqSOiIiIiIioAWNSR0RERERE1IAxqSMiIiIiImrAmNQRERERERE1YEzqiIiIiIiIGjCD+g6AKvo4ORPG8qL6DoOIiIiIqMlY0tm6vkOoNa7UAQgICIAgCBAEAQYGBrC3t8fs2bORlZUltXF0dJTaPF5Wr14ttdm1axd69OgBhUIBc3NztG/fHvPnz6+PKRERERERURPBlbr/GThwIGJiYlBSUoKUlBRMnToV2dnZ2L59u9RmxYoVmDFjhlY/c3NzAMDBgwfh7++PVatW4dVXX4UgCEhJScGhQ4ee6zyIiIiIiKhpYVL3PzKZDEqlEgDQunVrjB07FrGxsVptzM3NpTZP2rdvH3r37o2FCxdKda6urhgxYsSzCpmIiIiIiIjbLytz7do17N+/H4aGhjXuo1Qq8dtvv+HChQs17lNYWAiNRqNViIiIiIiIdMGk7n/27dsHuVwOExMTtGnTBikpKVi8eLFWm8WLF0Mul2sVtVoNAJg7dy66deuGjh07wtHREf7+/oiOjkZhYWGV14yIiIBCoZCKnZ3ds5wiERERERE1QoIoimJ9B1HfAgIC8Oeff+LTTz9Ffn4+tmzZgsuXL2Pfvn0wMHi0Q9XR0RETJ05EQECAVt8XXngBJiYm0ufff/8dCQkJOHXqFHbt2gV7e3ucPHkSpqamFa5bWFiolfRpNBrY2dlh+dFrMJabP5vJEhERERFRBX+30y81Gg0UCgVycnJgYWFRbVuu1P2PmZkZXFxc0KlTJ6xfvx6FhYUICwvTamNtbQ0XFxet8nhCBwBt2rTB9OnTsWXLFpw9exYpKSnYuXNnpdeUyWSwsLDQKkRERERERLpgUleF5cuX48MPP8StW7dqPYajoyNMTU2Rl5dXh5ERERERERH9H55+WQVfX1+0b98eq1atwj//+U8AQG5uLjIyMrTamZqawsLCAqGhocjPz8fgwYPh4OCA7OxsrF+/HsXFxejfv399TIGIiIiIiJoAJnXVCAoKQmBgoHRgyrJly7Bs2TKtNm+88QY2bdoEHx8fbNiwAZMnT8bt27dhaWmJzp0748CBA3Bzc9Ptuh5W3IpJREREREQ1woNS/kZ0eRiSiIiIiIgaLx6UQkRERERE1ERw++Xf0MfJmTCWF9V3GERERESko7/bsfjUNDTYlbqAgAAIggBBEGBgYAB7e3vMnj0bWVlZWu0KCgpgaWmJ5s2bo6CgoMI4jo6O0jgmJiZwd3fHBx98gCd3pe7atQs9evSAQqGAubk52rdvj/nz5z/TORIRERERET1Ng03qAGDgwIFIT09HamoqtmzZgr1792LOnDlabXbt2oUOHTrgxRdfxO7duysdZ8WKFUhPT8fFixexYMEChISEYPPmzdL3Bw8ehL+/P0aPHo3Tp0/jl19+QXh4OIqKuJpGRERERET1q0EndTKZDEqlEq1bt8aAAQMwduxYHDhwQKvN1q1bMXHiREycOBFbt26tdBxzc3MolUo4Ojpi+vTp6NSpk9Y4+/btQ+/evbFw4UK4ubnB1dUVI0aMQFRUlNTm999/x/Dhw9GiRQvI5XJ069YNBw8efDYTJyIiIiIi+p8GndQ97tq1a9i/fz8MDQ2lut9//x0nT57EmDFjMGbMGJw4cQLXrl2rcgxRFKFWq3Hx4kWtcZRKJX777TdcuHChyr4PHjzA4MGDcfDgQZw7dw5+fn4YNmwYbty4UWWfwsJCaDQarUJERERERKSLBp3U7du3D3K5HCYmJmjTpg1SUlKkd8oBQHR0NAYNGiQ9Uzdw4EBER0dXGGfx4sWQy+WQyWRQqVQQRRFvv/229P3cuXPRrVs3dOzYEY6OjvD390d0dDQKCwulNh4eHnjjjTfQsWNHtG3bFitXroSzszO+/fbbKuOPiIiAQqGQip2dXR3dGSIiIiIiaioadFKnUqmQlJSEn3/+GXPnzoWfnx/mzp0LACgtLUVcXBwmTpwotZ84cSLi4uJQWlqqNc7ChQuRlJSEI0eOQKVS4R//+Ae8vLyk783MzPDdd9/h6tWrWLp0KeRyOebPn4/u3bsjPz8fAJCXl4dFixbhxRdfRLNmzSCXy/Hf//632pW64OBg5OTkSCUtLa0ubw8RERERETUBDTqpMzMzg4uLCzp16oT169ejsLAQYWFhAIAffvgBf/75J8aOHQsDAwMYGBjA398fN2/erPDcnbW1NVxcXNCzZ0/s2rULa9eurfR5uDZt2mD69OnYsmULzp49i5SUFOzcuRPAo8Rw165dCA8Px7Fjx5CUlISOHTtWe5iKTCaDhYWFViEiIiIiItJFg07qnrR8+XJ8+OGHuHXrFrZu3Qp/f38kJSVplQkTJlR5YAoAWFpaYu7cuViwYEGF1xo8ztHREaampsjLywMAHDt2DAEBARg5ciQ6duwIpVKJ1NTUup4iERERERGRlkb18nFfX1+0b98e4eHh2Lt3L7799lt06NBBq82UKVMwZMgQ3L17FzY2NpWO8+abbyIyMhK7du3C6NGjERoaivz8fAwePBgODg7Izs7G+vXrUVxcjP79+wMAXFxcsHv3bgwbNgyCIOC9995DWVnZM58zERERERE1bY0qqQOAoKAgTJkyBSUlJejbt2+F71UqFczNzfHFF18gKCio0jFsbGwwadIkhIaG4rXXXoOPjw82bNiAyZMn4/bt27C0tETnzp1x4MABuLm5AQDWrl2LqVOnwsvLC9bW1li8eHGtT7MM8rDiVkwiIiIiIqoRQaxujyE9VxqNBgqFAjk5OUzqiIiIiIiaMF1yg0a3UtcYfJycCWN51QesEBERETUkSzpb13cIRI1aozoohYiIiIiIqKlhUlcDmzZtgrm5OUpKSqS6Bw8ewNDQEK+88opW22PHjkEQBFy+fBmOjo5Yt27dc46WiIiIiIiaEiZ1NaBSqfDgwQOcOXNGqjt27BiUSiUSExOlF5ADgFqtRqtWreDq6lofoRIRERERURPDpK4G3Nzc0KpVK6jVaqlOrVZj+PDhaNOmDU6cOKFVr1KpajRuYWEhNBqNViEiIiIiItIFk7oa8vX1RUJCgvQ5ISEBvr6+8PHxkeqLiopw8uTJGid1ERERUCgUUrGzs3smsRMRERERUePFpK6GfH19cfz4cZSUlCA3Nxfnzp2Dt7c3fHx8pBW8U6dOoaCgoMZJXXBwMHJycqSSlpb2DGdARERERESNEV9pUEMqlQp5eXlITExEVlYWXF1dYWtrCx8fH0yaNAl5eXlQq9Wwt7eHs7NzjcaUyWSQyWTPOHIiIiIiImrMmNTVkIuLC1q3bo2EhARkZWXBx8cHAKBUKuHk5ITjx48jISEBffr0qedIiYiIiIioKeH2Sx2oVCqo1Wqo1Wr4+vpK9T4+Pvjhhx9w6tSpGm+9JCIiIiIiqgtM6nSgUqnw008/ISkpSVqpAx4ldZ9//jkePnzIpI6IiIiIiJ4rbr/UgUqlQkFBAdzd3dGiRQup3sfHB7m5uWjTpk2dnGAZ5GEFCwuLvzwOERERERE1fkzqdODo6AhRFCvUt27dutL61NTU5xAVERERERE1ZUzq/oY+Ts6EsbyovsMgIiIiAEs6W9d3CERE1WrQz9Rt2rQJ5ubmKCkpkeoePHgAQ0NDvPLKK1ptjx07BkEQcPnyZQDAiRMnoK+vj4EDB1YYNzU1FYIgSMXIyAguLi5YuXKl1opcaGgoPD09n83kiIiIiIiIaqBBJ3UqlQoPHjzAmTNnpLpjx45BqVQiMTER+fn5Ur1arUarVq3g6uoKAIiOjsbcuXPx008/4caNG5WOf/DgQaSnp+PKlSsICwtDeHg4oqOjn+2kiIiIiIiIdNCgkzo3Nze0atUKarVaqlOr1Rg+fDjatGmDEydOaNWXn0yZl5eH+Ph4zJ49G0OHDkVsbGyl41tZWUGpVMLBwQETJkyAl5cXzp49W21M0dHRaN++PWQyGVq2bIm33nrrL8+TiIiIiIioKg06qQMAX19fJCQkSJ8TEhLg6+sLHx8fqb6oqAgnT56UkrqdO3fCzc0Nbm5umDhxImJiYio96ORxZ86cwdmzZ9GjR48q23z66ad48803MXPmTJw/fx7ffvstXFxcqmxfWFgIjUajVYiIiIiIiHTR4A9K8fX1xbx581BSUoKCggKcO3cO3t7eKC0txfr16wEAp06dQkFBgZTUbd26FRMnTgQADBw4EA8ePMChQ4fQr18/rbG9vLygp6eHoqIiFBcXY+bMmZg8eXKVsaxcuRLz58/HO++8I9V169atyvYREREICwur9dyJiIiIiIga/EqdSqVCXl4eEhMTcezYMbi6usLW1hY+Pj5ITExEXl4e1Go17O3t4ezsjEuXLuH06dPw9/cHABgYGGDs2LGVPiu3c+dOJCUlITk5GTt37sR//vMfLFmypNI47ty5g1u3bqFv3741jj04OBg5OTlSSUtLq91NICIiIiKiJqvBr9S5uLigdevWSEhIQFZWFnx8fAAASqUSTk5OOH78OBISEtCnTx8Aj1bpSkpK8MILL0hjiKIIQ0NDZGVlwdLSUqq3s7OTtk+2a9cO165dw3vvvYfQ0FAYGxtrxWFiYqJz7DKZDDKZTOd+RERERERE5Rr8Sh3waLVOrVZDrVbD19dXqvfx8cEPP/yAU6dOQaVSoaSkBNu2bcNHH32EpKQkqSQnJ8PBwQFffvlltdfR19dHSUkJiooqvkPO3Nwcjo6OOHToUF1Pj4iIiIiIqEoNfqUOeJTUvfnmmyguLpZW6oBHSd3s2bPx8OFDqFQq7Nu3D1lZWZg2bRoUCoXWGKNHj8bWrVu1TqvMzMxERkYGSkpKcP78eXzyySdQqVSwsLCoNI7Q0FDMmjULtra2GDRoEHJzc3H8+HHMnTv32UyciIiIiIiavEaT1BUUFMDd3R0tWrSQ6n18fJCbm4s2bdrAzs4Oc+bMQb9+/SokdAAwatQorFq1CmfPnkXz5s0BQDo4RV9fHy1btsTgwYMRHh5eZRxTpkzBw4cPsXbtWixYsADW1tYYPXq0zvMJ8rCqMnEkIiIiIiJ6nCA+7Sx/em40Gg0UCgVycnKY1BERERERNWG65AaN4pk6IiIiIiKipqpRbL9sbD5OzoSxvOJhLERERPR8LOlsXd8hEBHVWINbqQsICIAgCFi9erVW/Z49eyAIAgBArVZDEAQIggA9PT0oFAp07twZixYtQnp6utRn//79EAQBGRkZWmMplUrY2dlp1d28eROCIODAgQMAHr30/N13330GMyQiIiIiIqq5BpfUAYCxsTEiIyORlZVVbbtLly7h1q1bSExMxOLFi3Hw4EF06NAB58+fBwD07t0bBgYGUKvVUp+LFy/i4cOH0Gg0uHr1qlSfkJAAQ0ND9OrV65nMiYiIiIiIqDYaZFLXr18/KJVKREREVNvO1tYWSqUSrq6u8Pf3x/Hjx2FjY4PZs2cDAORyObp166aV1KnVavTu3Ru9e/euUN+9e3eYmZlVeq1//etf6Nq1K8zNzaFUKjF+/HjcuXPnL8+ViIiIiIioOg0yqdPX18eqVasQFRWFmzdv1rifiYkJZs2ahePHj0sJl0qlQkJCgtQmISEBvr6+8PHxqVCvUqmqHLuoqAjvv/8+kpOTsWfPHly/fh0BAQHVxlNYWAiNRqNViIiIiIiIdNEgkzoAGDlyJDw9PbF8+XKd+rm7uwMAUlNTATx6Nu7y5cvSs3ZHjhyBj48PfHx8pJW6tLQ0XL9+vdqkburUqRg0aBCcnZ3x8ssvY/369fj+++/x4MGDKvtERERAoVBI5cnn+IiIiIiIiJ6mwSZ1ABAZGYm4uDikpKTUuE/5a/nKD1Xp1asXjIyMoFarkZKSgoKCArz00kvo0qULNBoNrly5goSEBMhkMnh5eVU57rlz5zB8+HA4ODjA3Nwcvr6+AIAbN25U2Sc4OBg5OTlSSUtLq/E8iIiIiIiIgAae1Hl7e8PPzw8hISE17nPx4kUAgKOjIwDA1NQU3bt3R0JCAhISEtC7d2/o6+vDwMAAXl5eUn3Pnj1hbGxc6Zh5eXkYMGAA5HI5/vWvfyExMRHffPMNgEfbMqsik8lgYWGhVYiIiIiIiHTR4N9Tt3r1anh6esLV1fWpbQsKCrB582Z4e3vDxsZGqlepVNixYweysrKkFTYA0hbMkydPIjAwsMpx//vf/+LevXtYvXq1tIXyzJkztZ8UERERERFRDTXolToA6NixIyZMmICoqKgK3925cwcZGRm4cuUKduzYgV69euHevXv49NNPtdqpVCpcuXIF+/fvh4+Pj1Tv4+ODffv2ITU1tdrn6ezt7WFkZISoqChcu3YN3377Ld5///26myQREREREVEVGvxKHQC8//77iI+Pr1Dv5uYGQRAgl8vh7OyMAQMGICgoCEqlUqtdz549IZPJAABdunSR6rt164bS0lKYmJigR48eVV7fxsYGsbGxCAkJwfr16/HSSy/hww8/xKuvvlqr+QR5WHErJhERERER1Ygglp8cQvVOo9FAoVAgJyeHSR0RERERUROmS27Q4LdfEhERERERNWWNYvtlY/NxciaM5VWfmklERER1a0ln6/oOgYio1hrNSp0gCNWWgICACu0MDAxgb2+PoKAgFBYWSmPFxsZqtWvRogWGDRuG3377TeuaAQEBGDFixHOcJRERERERkbZGs1KXnp4u/Xnnzp1YtmwZLl26JNWZmJhIf46JicHAgQNRXFyM5ORkBAYGwszMTOvESgsLC1y6dAmiKOLPP//EokWLMGTIEFy+fBlGRkbPZ1JERERERERP0WhW6pRKpVQUCgUEQahQV65Zs2ZQKpWws7PD0KFD8eqrr+Ls2bNa45X3b9myJbp27Yp58+bhjz/+0EoUn7R//3707t0bzZo1g5WVFYYOHYrff//9mc2ZiIiIiIio0SR1tXX58mUkJCRU+8qC7OxsfPXVVwAAQ0PDKtvl5eUhKCgIiYmJOHToEPT09DBy5EiUlZVV2r6wsBAajUarEBERERER6aLRbL/Uxbhx46Cvr4+SkhIUFhZi6NChCA4O1mqTk5MDuVwOURSRn58PAHj11Vfh7u5e5bijRo3S+rx161bY2toiJSUFHTp0qNA+IiICYWFhdTAjIiIiIiJqqprkSt3atWuRlJSE5ORk7Nu3D5cvX8akSZO02pibmyMpKQm//PILNm3ahDZt2mDTpk3Vjvv7779j/PjxcHZ2hoWFBZycnAAAN27cqLR9cHAwcnJypJKWllY3EyQiIiIioiajSa7UKZVKuLi4AADc3NyQm5uLcePGYeXKlVK9np6e9Gd3d3dkZGRg7NixOHr0aJXjDhs2DHZ2dvj888/RqlUrlJWVoUOHDigqqvz1BDKZDDKZrI5nR0RERERETUmTXKl7kr6+PgCgoKCgyjbz5s1DcnIyvvnmm0q/z8zMxMWLF7F06VL07dsX7dq1Q1ZW1jOJl4iIiIiIqFyTXKnLzs5GRkYGysrKcOXKFaxYsQKurq5o165dlX0sLCwwffp0LF++HCNGjIAgCFrfW1pawsrKCps3b0bLli1x48YNLFmy5FlPhYiIiIiImrgmmdQFBgYC+L/XFnh7e2PVqlUwMKj+drzzzjtYv349vv76a4wZM0brOz09PezYsQNvv/02OnToADc3N6xfvx6+vr46xxfkYQULCwud+xERERERUdMjiKIo1ncQ9IhGo4FCoUBOTg6TOiIiIiKiJkyX3IDP1BERERERETVgTXL75d/dx8mZMJZXfmImERFRU7Cks3V9h0BE1GDU+0qdIAjVloCAAK12p06d0upfWFgIKysrCIIAtVot1Ts6OlYYq/zgktDQ0KdeNzU1VWo3cODACnGvWbMGgiBoPTPn6+tb6VhDhgyp8/tGREREREQE/A1W6tLT06U/79y5E8uWLcOlS5ekOhMTE+nPdnZ2iImJwcsvvyzVffPNN5DL5bh//36FsVesWIEZM2ZIn+VyOQBgwYIFmDVrllTfrVs3zJw5U6utjY0NAKBly5ZISEjAzZs30bp1a+n7mJgY2Nvba11v9+7dWu+ky8zMhIeHB15//fUa3AkiIiIiIiLd1ftKnVKplIpCoZBOpHy8rtyUKVOwY8cOrffJRUdHY8qUKZWObW5urjVWeVInl8u16vX19Su0LX93na2tLQYMGIC4uDhp3BMnTuDevXsVVuCaN2+uNcaPP/4IU1NTJnVERERERPTM1HtSp4suXbrAyckJu3btAgCkpaXh6NGjmDRpUqXtIyMjYWVlBU9PT4SHh2utouli6tSpiI2NlT5HR0djwoQJMDIyqrbf1q1b4e/vDzMzs0q/LywshEaj0SpERERERES6aFBJHfDoHXPR0dEAHm2BHDx4sLRV8nHvvPMOduzYgYSEBLz11ltYt24d5syZU6trDh06FBqNBkePHkVeXh7i4+MxderUavucPn0aFy5cwPTp06tsExERAYVCIRU7O7taxUdERERERE1XvT9Tp6uJEydiyZIluHbtGmJjY7F+/fpK282bN0/6c6dOnWBpaYnRo0dLq3e6MDQ0xMSJExETE4Nr167B1dUVnTp1qrbP1q1b0aFDB3Tv3r3KNsHBwQgKCpI+azQaJnZERERERKSTBpfUWVlZYejQoZg2bRoePnyIQYMGITc396n9yg9XuXr1qs5JHfBoC2aPHj1w4cKFp67S5efnY8eOHVixYkW17WQyGWQymc6xEBERERERlWtw2y+BRwmWWq3G5MmTpQNNnubcuXMAHp1mWRvt27dH+/btceHCBYwfP77atvHx8SgsLMTEiRNrdS0iIiIiIqKaanArdQAwcOBA3L17FxYWFpV+f/LkSZw6dQoqlQoKhQKJiYmYN28eXn311QqvIdDF4cOHUVxcjGbNmlXbbuvWrRgxYkStVgSJiIiIiIh00SCTOkEQYG1tXeX3MpkMO3fuRFhYGAoLC+Hg4IAZM2Zg0aJFf+m6VZ1i+bjLly/jp59+woEDB2p9nSAPqyoTViIiIiIioscJoiiK9R0EPaLRaKBQKJCTk8OkjoiIiIioCdMlN2iQK3WN3cfJmTCW1+6dekRERA3Zks5V78QhIqLKNciDUupaQEAARowYUd9hEBERERER6axBJnUBAQEQBAGrV6/Wqt+zZw8EQQAAqNVqCIIAQRCgp6cHhUKBzp07Y9GiRUhPT6+PsImIiIiIiOpcg0zqAMDY2BiRkZHIysqqtt2lS5dw69YtJCYmYvHixTh48CA6dOiA8+fPP6dIiYiIiIiInp0Gm9T169cPSqUSERER1baztbWFUqmEq6sr/P39cfz4cdjY2GD27NlV9vH19cXcuXPx7rvvwtLSEi1atMDmzZuRl5eHwMBAmJubo02bNvj++++lPqWlpZg2bRqcnJxgYmICNzc3fPLJJ9XGVlhYCI1Go1WIiIiIiIh00WCTOn19faxatQpRUVG4efNmjfuZmJhg1qxZOH78OO7cuVNlu7i4OFhbW+P06dOYO3cuZs+ejddffx1eXl44e/Ys/Pz8MGnSJOTn5wMAysrK0Lp1a8THxyMlJQXLli1DSEgI4uPjq7xGREQEFAqFVOzs7Gp+A4iIiIiIiNCAkzoAGDlyJDw9PbF8+XKd+rm7uwMAUlNTq2zj4eGBpUuXom3btggODoaJiQmsra0xY8YMtG3bFsuWLUNmZiZ+/fVXAIChoSHCwsLQrVs3ODk5YcKECQgICKg2qQsODkZOTo5U0tLSdJoHERERERFRg3+lQWRkJPr06YP58+fXuE/5q/nKD1WpTKdOnaQ/6+vrw8rKCh07dpTqWrRoAQBaq32bNm3Cli1b8Mcff6CgoABFRUXw9PSs8hoymQwymazGcRMRERERET2pQa/UAYC3tzf8/PwQEhJS4z4XL14EADg6OlbZxtDQUOuzIAhadeUJYVlZGQAgPj4e8+bNw9SpU3HgwAEkJSUhMDAQRUV83xwRERERET07DX6lDgBWr14NT09PuLq6PrVtQUEBNm/eDG9vb9jY2NRZDMeOHYOXlxfmzJkj1f3+++91Nj4REREREVFlGkVS17FjR0yYMAFRUVEVvrtz5w4ePnyI3Nxc/PLLL1izZg3u3buH3bt312kMLi4u2LZtG3744Qc4OTnhiy++QGJiIpycnOr0OkRERERERI9rFEkdALz//vuVHkri5uYGQRAgl8vh7OyMAQMGICgoCEqlsk6vP2vWLCQlJWHs2LEQBAHjxo3DnDlztF57UFNBHlawsLCo0/iIiIiIiKhxEsTyU0Oo3mk0GigUCuTk5DCpIyIiIiJqwnTJDRrNSl1j8nFyJozlPGCFiIievyWdres7BCIi0lGDP/2yXEBAAARBwOrVq7Xq9+zZI51UqVarIQgCBEGAnp4eFAoFOnfujEWLFiE9PV3q07FjR0yfPr3S62zfvh2Ghoa4ffu2NF52dvYzmxcREREREVF1Gk1SBwDGxsaIjIxEVlZWte0uXbqEW7duITExEYsXL8bBgwfRoUMHnD9/HgAwbdo0xMfHIz8/v0Lf6OhoDB06VHpPHRERERERUX1qVEldv379oFQqERERUW07W1tbKJVKuLq6wt/fH8ePH4eNjQ1mz54NAJg0aRIKCwvx9ddfa/W7ceMGDh8+jGnTplU59vHjx+Hj4wNTU1NYWlrCz8/vqUkmERERERFRbTWqpE5fXx+rVq1CVFQUbt68WeN+JiYmmDVrFo4fP447d+7AysoKw4cPR0xMjFa7mJgYtGjRAoMGDap0nKSkJPTt2xft27fHyZMn8dNPP2HYsGEoLS2ttH1hYSE0Go1WISIiIiIi0kWjSuoAYOTIkfD09MTy5ct16ufu7g4ASE1NBQBMnToVR48exbVr1wAAoigiNjYWAQEB0NfXr3SMNWvWoGvXrti4cSM8PDzQvn17vPXWW7C2rvyh84iICCgUCqnY2dnpFDMREREREVGjS+oAIDIyEnFxcUhJSalxn/I3O5QfqjJgwAC0bt1aWq07fPgwUlNTERgYWOUY5St1NRUcHIycnByppKWl1bgvERERERER0EiTOm9vb/j5+SEkJKTGfS5evAgAcHR0BADo6ekhICAAcXFxKCsrQ0xMDLy9vdG2bdsqxzAxMdEpTplMBgsLC61CRERERESki0aZ1AHA6tWrsXfvXpw4ceKpbQsKCrB582Z4e3vDxsZGqg8MDMTNmzexe/du7N69u9oDUgCgU6dOOHTo0F+OnYiIiIiIqKYabVLXsWNHTJgwAVFRURW+u3PnDjIyMnDlyhXs2LEDvXr1wr179/Dpp59qtXNyckKfPn0wc+ZMGBoaYvTo0dVeMzg4GImJiZgzZw5+/fVX/Pe//8Wnn36Ke/fu1enciIiIiIiIyhnUdwDP0vvvv4/4+PgK9W5ubhAEAXK5HM7OzhgwYACCgoKgVCortJ02bRoOHTqEmTNnwtTUtNrrubq64sCBAwgJCUH37t1hYmKCHj16YNy4cTrFHeRhxa2YRERERERUI4JYfkII1TuNRgOFQoGcnBwmdURERERETZguuUGj3X5JRERERETUFDTq7ZcN1cfJmTCWF9V3GERE1Mgt6Vz5e1SJiKhh4UpdFQICAiAIAgRBgKGhIZydnbFgwQLk5eUhNTVV+k4QBCgUCrz88svYu3ev1hixsbFo1qxZ/UyAiIiIiIiaBCZ11Rg4cCDS09Nx7do1rFy5Ehs3bsSCBQuk7w8ePIj09HT8/PPP6N69O0aNGoULFy7UY8RERERERNTUMKmrhkwmg1KphJ2dHcaPH48JEyZgz5490vdWVlZQKpVwd3dHeHg4iouLkZCQUH8BExERERFRk8Nn6nRgYmKC4uLiCvXFxcX4/PPPAQCGhoY1Hq+wsBCFhYXSZ41G89eDJCIiIiKiJoVJXQ2dPn0aX331Ffr27SvVeXl5QU9PDwUFBSgrK4OjoyPGjBlT4zEjIiIQFhb2LMIlIiIiIqImgtsvq7Fv3z7I5XIYGxujZ8+e8Pb2RlRUlPT9zp07ce7cOXz77bdwcXHBli1b0Lx58xqPHxwcjJycHKmkpaU9i2kQEREREVEjxpW6aqhUKnz66acwNDREq1atpK2VqampAAA7Ozu0bdsWbdu2hVwux6hRo5CSkgJbW9sajS+TySCTyZ5V+ERERERE1ARwpa4aZmZmcHFxgYODw1OflfPx8UGHDh0QHh7+nKIjIiIiIiJiUlen5s+fj88++wx//vlnfYdCRERERERNBLdf1qGhQ4fC0dER4eHh2LhxY63HCfKwgoWFRR1GRkREREREjZUgiqJY30HQIxqNBgqFAjk5OUzqiIiIiIiaMF1yA26/JCIiIiIiasC4/bKOhIaGYs+ePUhKSvrLY32cnAljedFfD4qIiLCks3V9h0BERPRMNdiVuoCAAAiCAEEQYGBgAHt7e8yePRtZWVla7QoKCmBpaYnmzZujoKCgwjiOjo7SOCYmJnB3d8cHH3yAJ3el7tq1Cz169IBCoYC5uTnat2+P+fPnP9M5EhERERERPU2DTeoAYODAgUhPT0dqaiq2bNmCvXv3Ys6cOVptdu3ahQ4dOuDFF1/E7t27Kx1nxYoVSE9Px8WLF7FgwQKEhIRg8+bN0vcHDx6Ev78/Ro8ejdOnT+OXX35BeHg4ioq4mkZERERERPWrQSd1MpkMSqUSrVu3xoABAzB27FgcOHBAq83WrVsxceJETJw4EVu3bq10HHNzcyiVSjg6OmL69Ono1KmT1jj79u1D7969sXDhQri5ucHV1RUjRoxAVFRUhbE+++wz2NnZwdTUFK+//jqys7PrdM5ERERERESPa9BJ3eOuXbuG/fv3a70k/Pfff8fJkycxZswYjBkzBidOnMC1a9eqHEMURajValy8eFFrHKVSid9++w0XLlyoNoarV68iPj4ee/fuxf79+5GUlIQ333yzyvaFhYXQaDRahYiIiIiISBcNOqnbt28f5HI5TExM0KZNG6SkpGDx4sXS99HR0Rg0aJD0TN3AgQMRHR1dYZzFixdDLpdDJpNBpVJBFEW8/fbb0vdz585Ft27d0LFjRzg6OsLf3x/R0dEoLCzUGufhw4eIi4uDp6cnvL29ERUVhR07diAjI6PS+CMiIqBQKKRiZ2dXR3eGiIiIiIiaigad1KlUKiQlJeHnn3/G3Llz4efnh7lz5wIASktLERcXh4kTJ0rtJ06ciLi4OJSWlmqNs3DhQiQlJeHIkSNQqVT4xz/+AS8vL+l7MzMzfPfdd7h69SqWLl0KuVyO+fPno3v37sjPz5fa2dvbo3Xr1tLnnj17oqysDJcuXao0/uDgYOTk5EglLS2tTu4LERERERE1HQ06qTMzM4OLiws6deqE9evXo7CwEGFhYQCAH374AX/++SfGjh0LAwMDGBgYwN/fHzdv3qzw3J21tTVcXFzQs2dP7Nq1C2vXrsXBgwcrXK9NmzaYPn06tmzZgrNnzyIlJQU7d+6sMj5BELT+90kymQwWFhZahYiIiIiISBcNOql70vLly/Hhhx/i1q1b2Lp1K/z9/ZGUlKRVJkyYUOWBKQBgaWmJuXPnYsGCBRVea/A4R0dHmJqaIi8vT6q7ceMGbt26JX0+efIk9PT04OrqWjcTJCIiIiIiekKjevm4r68v2rdvj/DwcOzduxfffvstOnTooNVmypQpGDJkCO7evQsbG5tKx3nzzTcRGRmJXbt2YfTo0QgNDUV+fj4GDx4MBwcHZGdnY/369SguLkb//v2lfsbGxpgyZQo+/PBDaDQavP322xgzZgyUSuUznTcRERERETVdjSqpA4CgoCBMmTIFJSUl6Nu3b4XvVSoVzM3N8cUXXyAoKKjSMWxsbDBp0iSEhobitddeg4+PDzZs2IDJkyfj9u3bsLS0ROfOnXHgwAG4ublJ/VxcXPDaa69h8ODBuH//PgYPHoyNGzfqPgcPK27FJCIiIiKiGhHE6vYY0nOl0WigUCiQk5PDpI6IiIiIqAnTJTdoVM/UERERERERNTWNbvtlY/BxciaM5UX1HQYRUYOypLN1fYdARERULxrkSl1AQAAEQcDq1au16vfs2SO9PkCtVkMQBAiCAD09PSgUCnTu3BmLFi1Cenq61Gf//v0QBKHCC8KVSmWFl4HfvHkTgiBIr0Tw9fXFu++++wxmSEREREREVDMNMqkDHp00GRkZiaysrGrbXbp0Cbdu3UJiYiIWL16MgwcPokOHDjh//jwAoHfv3jAwMIBarZb6XLx4EQ8fPoRGo8HVq1el+oSEBBgaGqJXr17PZE5ERERERES6arBJXb9+/aBUKhEREVFtO1tbWyiVSri6usLf3x/Hjx+HjY0NZs+eDQCQy+Xo1q2bVlKnVqvRu3dv9O7du0J99+7dYWZmVum1CgsLsWjRItjZ2UEmk6Ft27bVvhOPiIiIiIjor2qwSZ2+vj5WrVqFqKgo3Lx5s8b9TExMMGvWLBw/fhx37twB8Og1BwkJCVKbhIQE+Pr6wsfHp0K9SqWqcuzJkydjx44dWL9+PS5evIhNmzZBLpdX2b6wsBAajUarEBERERER6aLBJnUAMHLkSHh6emL58uU69XN3dwcApKamAnj0bNzly5elZ+2OHDkCHx8f+Pj4SCt1aWlpuH79epVJ3eXLlxEfH4/o6GiMHDkSzs7O6Nu3L8aOHVtlHBEREVAoFFJ58hk+IiIiIiKip2nQSR0AREZGIi4uDikpKTXuU/5qvvJDVXr16gUjIyOo1WqkpKSgoKAAL730Erp06QKNRoMrV64gISEBMpkMXl5elY6ZlJQEfX19+Pj41DiO4OBg5OTkSCUtLa3GfYmIiIiIiIBG8EoDb29v+Pn5ISQkBAEBATXqc/HiRQCAo6MjAMDU1BTdu3dHQkIC7t+/j969e0NfXx8A4OXlhYSEBJw8eRI9e/aEsbFxpWOamJjoHLtMJoNMJtO5HxERERERUbkGv1IHAKtXr8bevXtx4sSJp7YtKCjA5s2b4e3tDRsbG6lepVJBrVZDrVbD19dXqi/fgqlWq6t9nq5jx44oKyvDkSNH/tJciIiIiIiIdNEokrqOHTtiwoQJiIqKqvDdnTt3kJGRgStXrmDHjh3o1asX7t27h08//VSrnUqlwpUrV7B//36tLZQ+Pj7Yt28fUlNTq03qHB0dMWXKFEydOhV79uzB9evXoVarER8fX3cTJSIiIiIiekKD335Z7v333680gXJzc4MgCJDL5XB2dsaAAQMQFBQEpVKp1a5nz57SVsguXbpI9d26dUNpaSlMTEzQo0ePamP49NNPERISgjlz5iAzMxP29vYICQnReS5BHlawsLDQuR8RERERETU9glh+agjVO41GA4VCgZycHCZ1RERERERNmC65QaNZqWtMPk7OhLG8qL7DICL6W1vS2bq+QyAiIvpbaBTP1P0dODo6Yt26dfUdBhERERERNTENLqkLCAiAIAhYvXq1Vv2ePXuk986p1WoIggBBEKCnpweFQoHOnTtj0aJF0gvGAWD//v0QBAEZGRlaYymVygovAr958yYEQcCBAwcAPHph+bvvvvsMZkhERERERFRzDS6pAwBjY2NERkYiKyur2naXLl3CrVu3kJiYiMWLF+PgwYPo0KEDzp8/DwDo3bs3DAwMoFarpT4XL17Ew4cPodFocPXqVak+ISEBhoaG6NWr1zOZExERERERUW00yKSuX79+UCqViIiIqLadra0tlEolXF1d4e/vj+PHj8PGxgazZ88GAMjlcnTr1k0rqVOr1ejduzd69+5dob579+4wMzOr8nq5ubkYP3485HI5WrVqVekrFoiIiIiIiOpSg0zq9PX1sWrVKkRFReHmzZs17mdiYoJZs2bh+PHjuHPnDoBH76dLSEiQ2iQkJMDX1xc+Pj4V6qt7Tx0AfPDBB+jUqRPOnj2L4OBgzJs3Dz/++GOV7QsLC6HRaLQKERERERGRLhpkUgcAI0eOhKenJ5YvX65TP3d3dwBAamoqgEfPxl2+fFl61u7IkSPw8fGBj4+PtFKXlpaG69evPzWp69WrF5YsWQJXV1fMnTsXo0ePxtq1a6tsHxERAYVCIZUnn+MjIiIiIiJ6mgab1AFAZGQk4uLikJKSUuM+5a/lKz9UpVevXjAyMoJarUZKSgoKCgrw0ksvoUuXLtBoNLhy5QoSEhIgk8ng5eVV7dg9e/as8PnixYtVtg8ODkZOTo5U0tLSajwPIiIiIiIioIG/p87b2xt+fn4ICQlBQEBAjfqUJ1mOjo4AAFNTU3Tv3h0JCQm4f/8+evfuDX19fQCAl5cXEhIScPLkSfTs2RPGxsY6x1iePFZGJpNBJpPpPCYREREREVG5Bp3UAcDq1avh6ekJV1fXp7YtKCjA5s2b4e3tDRsbG6lepVJhx44dyMrKgq+vr1RfvgXz5MmTCAwMfOr4p06dqvC5fLsnERERERHRs9Cgt18CQMeOHTFhwoRKT5q8c+cOMjIycOXKFezYsQO9evXCvXv38Omnn2q1U6lUuHLlCvbv3w8fHx+p3sfHB/v27UNqaupTn6cDgOPHj2PNmjW4fPkyNmzYgK+//hrvvPPOX58kERERERFRFRr8Sh0AvP/++4iPj69Q7+bmBkEQIJfL4ezsjAEDBiAoKAhKpVKrXc+ePaVtkF26dJHqu3XrhtLSUpiYmKBHjx5PjWP+/Pn45ZdfEBYWBnNzc3z00Ufw8/PTeT5BHlawsLDQuR8RERERETU9glh+cgjVO41GA4VCgZycHCZ1RERERERNmC65QaNYqfs7CAgIQHZ2Nvbs2fOXx/o4ORPG8qK/HhQRUQO0pLN1fYdARETUoDTYZ+o2bdoEc3NzlJSUSHUPHjyAoaEhXnnlFa22x44dgyAIuHz5MgDgxIkT0NfXx8CBAyuMm5qaCkEQpGJkZAQXFxesXLkSjy9qhoaGwtPT89lMjoiIiIiIqIYabFKnUqnw4MEDnDlzRqo7duwYlEolEhMTkZ+fL9Wr1Wq0atVKOiEzOjoac+fOxU8//YQbN25UOv7BgweRnp6OK1euICwsDOHh4YiOjn62kyIiIiIiItJRg03q3Nzc0KpVK6jVaqlOrVZj+PDhaNOmDU6cOKFVX356ZV5eHuLj4zF79mwMHToUsbGxlY5vZWUFpVIJBwcHTJgwAV5eXjh79uxT4woLC4OtrS0sLCzwxhtvoKiI2yiJiIiIiOjZabBJHQD4+voiISFB+pyQkABfX1/4+PhI9UVFRTh58qSU1O3cuRNubm5wc3PDxIkTERMTg6edFXPmzBmcPXv2qSdgHjp0CBcvXkRCQgK2b9+Ob775BmFhYVW2LywshEaj0SpERERERES6aPBJ3fHjx1FSUoLc3FycO3cO3t7e0kvDgUcvAC8oKJCSuq1bt2LixIkAgIEDB+LBgwc4dOhQhbG9vLwgl8thZGSEbt26YcyYMZg8eXK18RgZGSE6Ohrt27fHkCFDsGLFCqxfvx5lZWWVto+IiIBCoZCKnZ3dX7gbRERERETUFDXopE6lUiEvLw+JiYk4duwYXF1dYWtrCx8fHyQmJiIvLw9qtRr29vZwdnbGpUuXcPr0afj7+wMADAwMMHbs2Eqfldu5cyeSkpKQnJyMnTt34j//+Q+WLFlSbTweHh4wNTWVPvfs2RMPHjxAWlpape2Dg4ORk5MjlaraERERERERVaVBv9LAxcUFrVu3RkJCArKysuDj4wMAUCqVcHJywvHjx5GQkIA+ffoAeLRKV1JSghdeeEEaQxRFGBoaIisrC5aWllK9nZ0dXFxcAADt2rXDtWvX8N577yE0NBTGxsY6xSkIQqX1MplMeuk5ERERERFRbTTolTrg0WqdWq2GWq2Gr6+vVO/j44MffvgBp06dgkqlQklJCbZt24aPPvoISUlJUklOToaDgwO+/PLLaq+jr6+PkpKSag8+SU5ORkFBgfT51KlTkMvlaN269V+eJxERERERUWUa9Eod8Cipe/PNN1FcXCyt1AGPkrrZs2fj4cOHUKlU2LdvH7KysjBt2jQoFAqtMUaPHo2tW7firbfekuoyMzORkZGBkpISnD9/Hp988glUKlW1b3MvKirCtGnTsHTpUvzxxx9Yvnw53nrrLejpNfjcmYiIiIiI/qYaRVJXUFAAd3d3tGjRQqr38fFBbm4u2rRpAzs7O8yZMwf9+vWrkNABwKhRo7Bq1SqcPXsWzZs3BwD069cPwKMVupYtW2Lw4MEIDw+vNpa+ffuibdu28Pb2RmFhIfz9/REaGqrznII8rKpNHomIiIiIiMoJ4tPO86fnRqPRQKFQICcnh0kdEREREVETpktuwH2BREREREREDViD337ZGH2cnAljedUHshARNTZLOlvXdwhEREQNFlfqAKSmpkIQBNja2iI3N1frO09PT63n4nx9fSEIAgRBgEwmwwsvvIBhw4Zh9+7dFcYVBAF79ux5xtETEREREVFTxqTuMbm5ufjwww+f2m7GjBlIT0/H1atXsWvXLrz44ovw9/fHzJkzn0OURERERERE/6dRJnW+vr6YO3cu3n33XVhaWqJFixbYvHkz8vLyEBgYCHNzc7Rp0wbff/+9Vr+5c+fi448/xp07d6od39TUFEqlEnZ2dnj55ZcRGRmJzz77DJ9//jkOHjz4LKdGRERERESkpc6Suuzs7Loaqk7ExcXB2toap0+fxty5czF79my8/vrr8PLywtmzZ+Hn54dJkyYhPz9f6jNu3Di4uLhgxYoVOl9vypQpsLS0rHQbZlUKCwuh0Wi0ChERERERkS5qldRFRkZi586d0ucxY8bAysoKL7zwApKTk+ssuL/Cw8MDS5cuRdu2bREcHAwTExNYW1tjxowZaNu2LZYtW4bMzEz8+uuvUh9BELB69Wps3rwZv//+u07X09PTg6urK1JTU2vcJyIiAgqFQip2dnY6XZOIiIiIiKhWSd1nn30mJSA//vgjfvzxR3z//fcYNGgQFi5cWKcB1lanTp2kP+vr68PKygodO3aU6spfVP7kVks/Pz/07t0b7733ns7XFEURgiDUuH1wcDBycnKkkpaWpvM1iYiIiIioaavVKw3S09OlpG7fvn0YM2YMBgwYAEdHR/To0aNOA6wtQ0NDrc+CIGjVlSdfZWVlFfquXr0aPXv21ClBLS0txZUrV9CtW7ca95HJZJDJZDVuT0RERERE9KRardRZWlpKq0r79+9Hv379ADxaqSotLa276OpJ9+7d8dprr2HJkiU17hMXF4esrCyMGjXqGUZGRERERESkrVYrda+99hrGjx+Ptm3bIjMzE4MGDQIAJCUlwcXFpU4DrC/h4eFo3749DAwq3qL8/HxkZGSgpKQEf/75J3bv3o21a9di9uzZUKlU9RAtERERERE1VbVK6tauXQtHR0ekpaVhzZo1kMvlAB5ty5wzZ06dBlhfXF1dMXXqVGzevLnCd59//jk+//xzGBkZwcrKCl26dMHOnTsxcuTIOrl2kIcVLCws6mQsIiIiIiJq3ARRFMX6DoIe0Wg0UCgUyMnJYVJHRERERNSE6ZIb1Po9dV988QV69+6NVq1a4Y8//gAArFu3Dv/5z39qOyQRERERERHpqFbbLz/99FMsW7YM7777LsLDw6XDUZo1a4Z169Zh+PDhdRpkU/NxciaM5UX1HQYR0TOzpLN1fYdARETUaNRqpS4qKgqff/45/vGPf0BfX1+q79q1K86fP19nwT1vAQEBEAQBs2bNqvDdnDlzIAgCAgICADx6v90bb7wBe3t7yGQyKJVK+Pn54eTJk1IfR0dHrFu37jlFT0RERERETVGtkrrr16+jc+fOFeplMhny8vL+clD1yc7ODjt27EBBQYFU9/DhQ2zfvh329vZS3ahRo5CcnIy4uDhcvnwZ3377LXx9fXH//v36CJuIiIiIiJqoWm2/dHJyQlJSEhwcHLTqv//+e7z44ot1Elh9eemll3Dt2jXs3r0bEyZMAADs3r0bdnZ2cHZ2BgBkZ2fjp59+glqtho+PDwDAwcEB3bt3r7e4iYiIiIioaarVSt3ChQvx5ptvYufOnRBFEadPn0Z4eDhCQkKwcOHCuo7xuQsMDERMTIz0OTo6GlOnTpU+y+VyyOVy7NmzB4WFhbW+TmFhITQajVYhIiIiIiLSRa2SusDAQCxfvhyLFi1Cfn4+xo8fj02bNuGTTz6Bv79/Xcf43E2aNAk//fQTUlNT8ccff+D48eOYOHGi9L2BgQFiY2MRFxeHZs2aoVevXggJCcGvv/6q03UiIiKgUCikYmdnV9dTISIiIiKiRk7npK6kpARxcXEYNmwY/vjjD9y5cwcZGRlIS0vDtGnTnkWMz521tTWGDBmCuLg4xMTEYMiQIbC21j6pbdSoUbh16xa+/fZb+Pn5Qa1W46WXXkJsbGyNrxMcHIycnByppKWl1fFMiIiIiIiosdM5qTMwMMDs2bOlbYfW1tawtbWt88Dq29SpU6XVuMe3Xj7O2NgY/fv3x7Jly3DixAkEBARg+fLlNb6GTCaDhYWFViEiIiIiItJFrbZf9ujRA+fOnavrWP5WBg4ciKKiIhQVFcHPz69GfV588cUGf/onERERERE1LLU6/XLOnDmYP38+bt68iS5dusDMzEzr+06dOtVJcPVJX18fFy9elP78uMzMTLz++uuYOnUqOnXqBHNzc5w5cwZr1qzhi9eJiIiIiOi5qlVSN3bsWADA22+/LdUJggBRFCEIAkpLS+smunpW1XZIuVyOHj16YO3atfj9999RXFwMOzs7zJgxAyEhIX/5ukEeVtyKSURERERENSKIoijq2umPP/6o9vsn319HNaPRaKBQKJCTk8OkjoiIiIioCdMlN6jVSh2TNiIiIiIior+HWiV127Ztq/b7yZMn1yoYeuTj5EwYy4vqOwwiohpb0tn66Y2IiIjomahVUvfOO+9ofS4uLkZ+fj6MjIxgamr6t07qMjIyEB4eju+++w5//vknbG1t4enpiXfffRd9+/aV2q1atQrvvfcewsPDsWTJEq0xYmNjERgYKH22tbVF9+7dsXr1arRv316qDwgIQHZ2Nvbs2fPM50VERERERE1TrV5pkJWVpVUePHiAS5cuoXfv3ti+fXtdx1hnUlNT0aVLFxw+fBhr1qzB+fPnsX//fqhUKrz55ptabWNiYrBo0SJER0dXOpaFhQXS09Nx69YtfPfdd8jLy8OQIUNQVMQVNiIiIiIien5qldRVpm3btli9enWFVby/kzlz5kAQBJw+fRqjR4+Gq6sr2rdvj6CgIJw6dUpqd+TIERQUFGDFihXIy8vD0aNHK4wlCAKUSiVatmyJrl27Yt68efjjjz9w6dKl5zklIiIiIiJq4uosqQMevc/t1q1bdTlknbl//z7279+PN998s8J79QCgWbNm0p+3bt2KcePGwdDQEOPGjcPWrVurHTs7OxtfffUVAMDQ0LDGMRUWFkKj0WgVIiIiIiIiXdTqmbpvv/1W67MoikhPT8c///lP9OrVq04Cq2tXr16FKIpwd3evtp1Go8GuXbtw4sQJAMDEiRPRq1cvREVFaR0lmpOTA7lcDlEUkZ+fDwB49dVXnzr+4yIiIhAWFlaL2RARERERET1Sq6RuxIgRWp8FQYCNjQ369OmDjz76qC7iqnPlr+MTBKHadl999RWcnZ3h4eEBAPD09ISzszN27NiBmTNnSu3Mzc1x9uxZlJSU4MiRI/jggw+wadMmnWIKDg5GUFCQ9Fmj0cDOzk6nMYiIiIiIqGmrVVJXVlZW13E8c23btoUgCLh48WKFpPRx0dHR+O2332Bg8H+3pqysDFu3btVK6vT09ODi4gIAcHd3R0ZGBsaOHVvp83dVkclkkMlkuk+GiIiIiIjof2r1TN2KFSukLYePKz9c5O+oefPm8PPzw4YNG5CXl1fh++zsbJw/fx5nzpyBWq1GUlKSVI4ePYrExERcuHChyvHnzZuH5ORkfPPNN89yGkRERERERFpqldSFhYXhwYMHFerz8/P/1s+Ibdy4EaWlpejevTt27dqFK1eu4OLFi1i/fj169uyJrVu3onv37vD29kaHDh2k0rt3b+n7qlhYWGD69OlYvny5tNWTiIiIiIjoWavV9ktRFCt9Ni05ORnNmzf/y0E9K05OTjh79izCw8Mxf/58pKenw8bGBl26dMEnn3yC8ePHY/HixZX2HTVqFCIiIhAZGVnl+O+88w7Wr1+Pr7/+GmPGjKl1nEEeVlqHshAREREREVVFEHVYVrK0tIQgCMjJyYGFhYVWYldaWooHDx5g1qxZ2LBhwzMJtrHTaDRQKBTS/SUiIiIioqZJl9xAp5W6devWQRRFTJ06FWFhYVAoFNJ3RkZGcHR0RM+ePWsXNUk+Ts6EsbyovsMgIqrSks7W9R0CERER/Y9OSd2UKVMAPNrG6OXlpdOLtomIiIiIiKju1eqgFB8fHymhKygogEaj0SrPW0BAAARBwOrVq7Xq9+zZI20RVavVEAQBgiBAT08PCoUCnTt3xqJFi5Ceni716dixI6ZPn17pdbZv3w5DQ0Pcvn1bGi87O/uZzYuIiIiIiOhpapXU5efn46233oKtrS3kcjksLS21Sn0wNjZGZGQksrKyqm136dIl3Lp1C4mJiVi8eDEOHjyIDh064Pz58wCAadOmIT4+vtJXNkRHR2Po0KFo0aLFM5kDERERERGRrmqV1C1cuBCHDx/Gxo0bIZPJsGXLFoSFhaFVq1bYtm1bXcdYI/369YNSqURERES17WxtbaFUKuHq6gp/f38cP34cNjY2mD17NgBg0qRJKCwsxNdff63V78aNGzh8+DCmTZtW6biZmZkYN24cWrduDVNTU3Ts2BHbt2+vm8kRERERERFVoVZJ3d69e7Fx40aMHj0aBgYGeOWVV7B06VKsWrUKX375ZV3HWCP6+vpYtWoVoqKicPPmzRr3MzExwaxZs3D8+HHcuXMHVlZWGD58OGJiYrTaxcTEoEWLFhg0aFCl4zx8+BBdunTBvn37cOHCBcycOROTJk3Czz//XOW1CwsL633rKhERERERNWy1Suru378PJycnAI9eun3//n0AQO/evXH06NG6i05HI0eOhKenJ5YvX65TP3d3dwBAamoqAGDq1Kk4evQorl27BuDRe/liY2MREBAAfX39Ssd44YUXsGDBAnh6esLZ2Rlz586Fn59fhRW/x0VEREChUEjFzs5Op7iJiIiIiIhqldQ5OztLCdCLL76I+Ph4AI9W8Jo1a1ZXsdVKZGQk4uLikJKSUuM+5a/qKz9UZcCAAWjdurW0Wnf48GGkpqYiMDCwyjFKS0sRHh6OTp06wcrKCnK5HAcOHMCNGzeq7BMcHIycnByppKWl1ThmIiIiIiIioJZJXWBgIJKTkwE8SkzKn62bN28eFi5cWKcB6srb2xt+fn4ICQmpcZ+LFy8CABwdHQEAenp6CAgIQFxcHMrKyhATEwNvb2+0bdu2yjE++ugjrF27FosWLcLhw4eRlJQEPz8/FBVV/b45mUwGCwsLrUJERERERKQLnd5TV27evHnSn1UqFf773//izJkzaNOmDTw8POosuNpavXo1PD094erq+tS2BQUF2Lx5M7y9vWFjYyPVBwYGYuXKldi9ezd2796NTZs2VTvOsWPHMHz4cEycOBEAUFZWhitXrqBdu3Z/bTJERERERETVqFVS97iHDx/C3t4e9vb2dRFPnejYsSMmTJiAqKioCt/duXMHDx8+RG5uLn755ResWbMG9+7dw+7du7XaOTk5oU+fPpg5cyYMDQ0xevToaq/p4uKCXbt24cSJE7C0tMTHH3+MjIwMJnVERERERPRM1SqpKy0txapVq7Bp0ybcvn0bly9fhrOzM9577z04OjpWeez/8/T+++9Lz/o9zs3NDYIgQC6Xw9nZGQMGDEBQUBCUSmWFttOmTcOhQ4cwc+ZMmJqaVnu99957D9evX4efnx9MTU0xc+ZMjBgxAjk5OTrHHuRhxa2YRERERERUI4JYfkqIDlasWIG4uDisWLECM2bMwIULF+Ds7Iz4+HisXbsWJ0+efBaxNnoajQYKhQI5OTlM6oiIiIiImjBdcoNardRt27YNmzdvRt++fTFr1iypvlOnTvjvf/9bmyHpMR8nZ8JYXvUBK0REz8qSztb1HQIRERHpqFanX/75559wcXGpUF9WVobi4uK/HFRNbNq0Cebm5igpKZHqHjx4AENDQ7zyyitabY8dOwZBEHD58mUAwIkTJ6Cvr4+BAwdWGDc1NRWCIEjFyMgILi4uWLlyJR5f1AwNDYWnp+ezmRwREREREVEN1Sqpa9++PY4dO1ah/uuvv0bnzp3/clA1oVKp8ODBA5w5c0aqO3bsGJRKJRITE5Gfny/Vq9VqtGrVSjoNMzo6GnPnzsVPP/1U5XvkDh48iPT0dFy5cgVhYWEIDw9HdHT0s50UERERERGRjmqV1C1fvhxvvfUWIiMjUVZWht27d2PGjBlYtWoVli1bVtcxVsrNzQ2tWrWCWq2W6tRqNYYPH442bdrgxIkTWvUqlQoAkJeXh/j4eMyePRtDhw5FbGxspeNbWVlBqVTCwcEBEyZMgJeXF86ePVtlPImJiejfvz+sra2hUCjg4+NTbXsiIiIiIqK6oFNSd+3aNYiiiGHDhmHnzp34f//v/0EQBCxbtgwXL17E3r170b9//2cVawW+vr5ISEiQPickJMDX1xc+Pj5SfVFREU6ePCkldTt37oSbmxvc3NwwceJExMTE4GlnxZw5cwZnz55Fjx49qmyTm5uLKVOm4NixYzh16hTatm2LwYMHIzc3t8o+hYWF0Gg0WoWIiIiIiEgXOiV1bdu2xd27dwEAfn5+UCqVuHr1KvLz8/HTTz9hwIABzyTIqvj6+uL48eMoKSlBbm4uzp07B29vb/j4+EgreKdOnUJBQYGU1G3dulV6QfjAgQPx4MEDHDp0qMLYXl5ekMvlMDIyQrdu3TBmzBhMnjy5ylj69OmDiRMnol27dmjXrh0+++wz5Ofn48iRI1X2iYiIgEKhkIqdnd1fuBtERERERNQU6ZTUPbmi9f3332s9u/a8qVQq5OXlITExEceOHYOrqytsbW3h4+ODxMRE5OXlQa1Ww97eHs7Ozrh06RJOnz4Nf39/AICBgQHGjh1b6bNyO3fuRFJSEpKTk7Fz50785z//wZIlS6qM5c6dO5g1axZcXV2lJO3BgwdVPrMHAMHBwcjJyZFKWlraX78pRERERETUpNTqlQblavGKuzrl4uKC1q1bIyEhAVlZWfDx8QEAKJVKODk54fjx40hISECfPn0APFqlKykpwQsvvCCNIYoiDA0NkZWVBUtLS6nezs5OOuGzXbt2uHbtGt577z2EhobC2Ni4QiwBAQG4e/cu1q1bBwcHB8hkMvTs2RNFRVW/mkAmk0Emk9XJvSAiIiIioqZJp5W68mP+n6yrTyqVCmq1Gmq1Gr6+vlK9j48PfvjhB5w6dQoqlQolJSXYtm0bPvroIyQlJUklOTkZDg4O+PLLL6u9jr6+PkpKSqpM0o4dO4a3334bgwcPRvv27SGTyXDv3r26nCoREREREVEFOq3UiaKIgIAAaXXp4cOHmDVrFszMzLTa7d69u+4ifAqVSoU333wTxcXF0kod8Cipmz17Nh4+fAiVSoV9+/YhKysL06ZNg0Kh0Bpj9OjR2Lp1K9566y2pLjMzExkZGSgpKcH58+fxySefQKVSVfk2dxcXF3zxxRfo2rUrNBoNFi5cCBMTk2czaSIiIiIiov/RKambMmWK1ufyA0fqk0qlQkFBAdzd3dGiRQup3sfHB7m5uWjTpg3s7OwwZ84c9OvXr0JCBwCjRo3CqlWrcPbsWTRv3hwA0K9fPwCPVuhatmyJwYMHIzw8vMo4oqOjMXPmTHTu3Bn29vZYtWoVFixYUKs5BXlYVZk8EhERERERPU4Q6/vBOJJoNBooFArk5OQwqSMiIiIiasJ0yQ1q9fJxIiIiIiIi+nv4S6df0rPxcXImjOVVn5pJRPS4JZ2t6zsEIiIiqkeNeqUuICAAgiBg9erVWvV79uyRTu1Uq9XSqZ56enpQKBTo3LkzFi1ahPT0dK1+oaGhEAQBAwcOrHCtNWvWQBAErRM4Q0ND4enpWefzIiIiIiIiKteokzoAMDY2RmRkJLKysqptd+nSJdy6dQuJiYlYvHgxDh48iA4dOuD8+fNa7Vq2bImEhATcvHlTqz4mJgb29vZ1Hj8REREREVF1Gn1S169fPyiVSkRERFTbztbWFkqlEq6urvD398fx48dhY2OD2bNnV2g3YMAAxMXFSXUnTpzAvXv3MGTIkGcyByIiIiIioqo0+qROX18fq1atQlRUVIXVteqYmJhg1qxZOH78OO7cuaP13dSpUxEbGyt9jo6OxoQJE2BkZKRTbIWFhdBoNFqFiIiIiIhIF40+qQOAkSNHwtPTE8uXL9epn7u7OwAgNTVVq37o0KHQaDQ4evQo8vLyEB8fj6lTp+ocV0REBBQKhVTs7Ox0HoOIiIiIiJq2JpHUAUBkZCTi4uKQkpJS4z7lr/ArP1SlnKGhISZOnIiYmBh8/fXXcHV1RadOnXSOKTg4GDk5OVJJS0vTeQwiIiIiImramswrDby9veHn54eQkBAEBATUqM/FixcBAI6OjhW+mzp1Knr06IELFy7UapUOAGQyGWQyWa36EhERERERAU0oqQOA1atXw9PTE66urk9tW1BQgM2bN8Pb2xs2NjYVvm/fvj3at2+PX3/9FePHj38W4RIRERERET1Vk0rqOnbsiAkTJiAqKqrCd3fu3MHDhw+Rm5uLX375BWvWrMG9e/ewe/fuKsc7fPgwiouL0axZs2cYNRERERERUdWaVFIHAO+//z7i4+Mr1Lu5uUEQBMjlcjg7O2PAgAEICgqCUqmsciwzM7NnEmOQhxUsLCyeydhERERERNS4CGL5aSBU7zQaDRQKBXJycpjUERERERE1YbrkBk3m9EsiIiIiIqLGqMltv2wIPk7OhLG8qL7DIKJ6tqSzdX2HQERERA1Ag1ypCwgIgCAIEAQBhoaGcHZ2xoIFC5CXlwcA2LVrF3r06AGFQgFzc3O0b98e8+fPl/rHxsZCEAQMHDhQa9zs7GwIggC1Wi3VlV9HEASYmZmhbdu2CAgIwC+//PJc5kpERERERFSdBpnUAcDAgQORnp6Oa9euYeXKldi4cSMWLFiAgwcPwt/fH6NHj8bp06fxyy+/IDw8HEVF2itfBgYGOHToEBISEp56rZiYGKSnp+O3337Dhg0b8ODBA/To0QPbtm17VtMjIiIiIiKqkQa7/VImk0knU44fPx4JCQnYs2cPZDIZevfujYULF0ptXV1dMWLECK3+ZmZmGDNmDJYsWYKff/652ms1a9ZMupajoyMGDBiAKVOm4K233sKwYcNgaWmJzMxMvPXWWzh27Bju37+PNm3aICQkBOPGjavbiRMRERERET2mwa7UPcnExATFxcVQKpX47bffcOHChaf2CQ0Nxfnz5/Hvf/9b5+vNmzcPubm5+PHHHwEADx8+RJcuXbBv3z5cuHABM2fOxKRJk6pNGAsLC6HRaLQKERERERGRLhpFUnf69Gl89dVX6Nu3L+bOnYtu3bqhY8eOcHR0hL+/P6Kjo1FYWFihX6tWrfDOO+/gH//4B0pKSnS6pru7OwAgNTUVAPDCCy9gwYIF8PT0hLOzM+bOnQs/Pz98/fXXVY4REREBhUIhFTs7O51iICIiIiIiarBJ3b59+yCXy2FsbIyePXvC29sbUVFRMDMzw3fffYerV69i6dKlkMvlmD9/Prp37478/PwK4yxevBh3795FdHS0Ttcvf72fIAgAgNLSUoSHh6NTp06wsrKCXC7HgQMHcOPGjSrHCA4ORk5OjlTS0tJ0ioGIiIiIiKjBJnUqlQpJSUm4dOkSHj58iN27d8PW1lb6vk2bNpg+fTq2bNmCs2fPIiUlBTt37qwwTrNmzRAcHIywsLBKk76qXLx4EQDg5OQEAPjoo4+wdu1aLFq0CIcPH0ZSUhL8/PwqHNDyOJlMBgsLC61CRERERESkiwab1JmZmcHFxQUODg4wNDSstq2joyNMTU2lVx48ae7cudDT08Mnn3xS4+uvW7cOFhYW6NevHwDg2LFjGD58OCZOnAgPDw84OzvjypUrNZ8QERERERFRLTTY0y+rEhoaivz8fAwePBgODg7Izs7G+vXrUVxcjP79+1fax9jYGGFhYXjzzTcr/T47OxsZGRkoLCzE5cuX8dlnn2HPnj3Ytm0bmjVrBgBwcXHBrl27cOLECVhaWuLjjz9GRkYG2rVr96ymSkRERERE1PiSOh8fH2zYsAGTJ0/G7du3YWlpic6dO+PAgQNwc3Orst+UKVPw0UcfISUlpcJ3gYGBAB4lfy+88AJ69+6N06dP46WXXpLavPfee7h+/Tr8/PxgamqKmTNnYsSIEcjJydF5DkEeVtyKSURERERENSKI5Sd+UL3TaDRQKBTIyclhUkdERERE1ITpkhs02GfqiIiIiIiIqBFuv2wMPk7OhLG86lMziajhWtLZur5DICIiokamwa/UBQQEQBAECIIAQ0NDODs7Y8GCBdJJl7t27UKPHj2gUChgbm6O9u3bY/78+VL/0tJSREREwN3dHSYmJmjevDlefvllxMTEVHoNAwMD2NvbY/bs2cjKynru8yUiIiIiInpco1ipGzhwIGJiYlBcXIxjx45h+vTpyMvLw6hRo+Dv749Vq1bh1VdfhSAISElJwaFDh6S+oaGh2Lx5M/75z3+ia9eu0Gg0OHPmTIWErfwaJSUlSElJwdSpU5GdnY3t27c/7+kSERERERFJGkVSJ5PJoFQqAQDjx49HQkIC9uzZA5lMht69e2PhwoVSW1dXV4wYMUL6vHfvXsyZMwevv/66VOfh4VHtNVq3bo2xY8ciNjZW+r60tBQzZ87E4cOHkZGRAXt7e8yZMwfvvPNOHc+WiIiIiIjo/zT47ZeVMTExQXFxMZRKJX777TdcuHChyrZKpRKHDx/G3bt3azz+tWvXsH//fq2XnpeVlaF169aIj49HSkoKli1bhpCQEMTHx1c5TmFhITQajVYhIiIiIiLSRaNL6k6fPo2vvvoKffv2xdy5c9GtWzd07NgRjo6O8Pf3R3R0NAoLC6X2H3/8Me7evQulUolOnTph1qxZ+P777yuMu2/fPsjlcpiYmKBNmzZISUnB4sWLpe8NDQ0RFhaGbt26wcnJCRMmTEBAQEC1SV1ERAQUCoVU7Ozs6vZmEBERERFRo9cokrryhMvY2Bg9e/aEt7c3oqKiYGZmhu+++w5Xr17F0qVLIZfLMX/+fHTv3h35+fkAgBdffBEXLlzAqVOnEBgYiNu3b2PYsGGYPn261jVUKhWSkpLw888/Y+7cufDz88PcuXO12mzatAldu3aFjY0N5HI5Pv/8c9y4caPKuIODg5GTkyOVtLS0ur85RERERETUqDX4l48HBATgzz//xKeffgpDQ0O0atVKa1vkk65fvw5XV1ds3rwZgYGBlbb517/+hUmTJuHatWtwcnJCQEAAsrOzsWfPHqmNSqVC79698f777wMA4uPjMWXKFHz00Ufo2bMnzM3N8cEHH+Dnn39GUlJSjeZS/oLB5UevwVhuXuN7QEQNB19pQERERDWhy8vHG8VBKWZmZnBxcalRW0dHR5iamkqvPKjMiy++CADVtlm+fDkGDRqE2bNno1WrVjh27Bi8vLwwZ84cqc3vv/9ewxkQERERERHVTqNI6qoSGhqK/Px8DB48GA4ODsjOzsb69etRXFyM/v37AwBGjx6NXr16wcvLC0qlEtevX0dwcDBcXV3h7u5e5di+vr5o3749Vq1ahX/+859wcXHBtm3b8MMPP8DJyQlffPEFEhMT4eTk9LymS0RERERETVCjTup8fHywYcMGTJ48Gbdv34alpSU6d+6MAwcOwM3NDQDg5+eH7du3IyIiAjk5OVAqlejTpw9CQ0NhYFD97QkKCkJgYCAWL16MWbNmISkpCWPHjoUgCBg3bhzmzJlT6aErTxPkYfXUJVYiIiIiIiKgETxT15josm+WiIiIiIgaryb3TF1j83FyJozlRfUdBhHVMR6SQkRERM9Co3ilARERERERUVPFpO4xd+7cwRtvvAF7e3vIZDIolUr4+fnh5MmTAB6dnLlu3TqpvaOjIwRBgCAIMDU1RYcOHfDZZ59J38fGxqJZs2bPeRZERERERNSUcPvlY0aNGoXi4mLExcXB2dkZt2/fxqFDh3D//v0q+6xYsQIzZszAgwcPEBsbi1mzZqFZs2YYO3bsc4yciIiIiIiaKiZ1/5OdnY2ffvoJarUaPj4+AAAHBwd079692n7m5uZQKpUAgJUrVyI+Ph579uxhUkdERERERM8Ft1/+j1wuh1wux549e1BYWFjrcYyNjVFcXFyjtoWFhdBoNFqFiIiIiIhIF0zq/sfAwACxsbGIi4tDs2bN0KtXL4SEhODXX3+tUf+SkhLExsbi/Pnz6Nu3b436REREQKFQSMXOzu6vTIGIiIiIiJogJnWPGTVqFG7duoVvv/0Wfn5+UKvVeOmllxAbG1tln8WLF0Mul8PExARvvvkmFi5ciDfeeKNG1wsODkZOTo5U0tLS6mgmRERERETUVPCZuicYGxujf//+6N+/P5YtW4bp06dj+fLlCAgIqLT9woULERAQAFNTU7Rs2RKCINT4WjKZDDKZrI4iJyIiIiKipogrdU/x4osvIi8vr8rvra2t4eLiglatWumU0BEREREREdUFrtT9T2ZmJl5//XVMnToVnTp1grm5Oc6cOYM1a9Zg+PDh9R0eERERERFRpZjU/Y9cLkePHj2wdu1a/P777yguLoadnR1mzJiBkJCQ5xpLkIcVLCwsnus1iYiIiIioYRJEURTrOwh6RKPRQKFQICcnh0kdEREREVETpktuwJW6v6GPkzNhLC+q7zCIGr0lna3rOwQiIiKiv6xeD0oJCAiAIAhYvXq1Vv2ePXukQ0fUajUEQYAgCNDT04NCoUDnzp2xaNEipKenS306duyI6dOnV3qd7du3w9DQELdv35bGy87OBgCEhoZK4z9ezMzMtMY4cuQIunTpAmNjYzg7O2PTpk1a38fGxlY6zsOHD//qbSIiIiIiIqpSvZ9+aWxsjMjISGRlZVXb7tKlS7h16xYSExOxePFiHDx4EB06dMD58+cBANOmTUN8fDzy8/Mr9I2OjsbQoUPRokWLCt8tWLAA6enpWuXFF1/E66+/LrW5fv06Bg8ejFdeeQXnzp1DSEgI3n77bezatUtrLAsLiwpjGRsb1+a2EBERERER1Ui9J3X9+vWDUqlEREREte1sbW2hVCrh6uoKf39/HD9+HDY2Npg9ezYAYNKkSSgsLMTXX3+t1e/GjRs4fPgwpk2bVum4crkcSqVSKrdv30ZKSopW+02bNsHe3h7r1q1Du3btMH36dEydOhUffvih1liCIGiNpVQqa3NLiIiIiIiIaqzekzp9fX2sWrUKUVFRuHnzZo37mZiYYNasWTh+/Dju3LkDKysrDB8+HDExMVrtYmJi0KJFCwwaNKhG427ZsgWurq545ZVXpLqTJ09iwIABWu38/Pxw5swZFBcXS3UPHjyAg4MDWrdujaFDh+LcuXPVXquwsBAajUarEBERERER6aLekzoAGDlyJDw9PbF8+XKd+rm7uwMAUlNTAQBTp07F0aNHce3aNQCAKIqIjY1FQEAA9PX1nzpeYWEhvvzyywqrehkZGRW2brZo0QIlJSW4d++eFEtsbCy+/fZbbN++HcbGxujVqxeuXLlS5fUiIiKgUCikYmdnV+O5ExERERERAX+TpA4AIiMjERcXh5SUlBr3KX8bQ/mhKgMGDEDr1q2l1brDhw8jNTUVgYGBNRpv9+7dyM3NxeTJkyt8V36Nqq798ssvY+LEifDw8MArr7yC+Ph4uLq6IioqqsrrBQcHIycnRyppaWk1ipOIiIiIiKjc3yap8/b2hp+fn04v+r548SIAwNHREQCgp6eHgIAAxMXFoaysDDExMfD29kbbtm1rNN6WLVswdOjQCs/CKZVKZGRkaNXduXMHBgYGsLKyqnQsPT09dOvWrdqVOplMBgsLC61CRERERESki79NUgcAq1evxt69e3HixImnti0oKMDmzZvh7e0NGxsbqT4wMBA3b97E7t27sXv37ioPSHnS9evXkZCQUGn7nj174scff9SqO3DgALp27QpDQ8NKxxNFEUlJSWjZsmWNrk9ERERERFQbf6uXj3fs2BETJkyodMvinTt38PDhQ+Tm5uKXX37BmjVrcO/ePezevVurnZOTE/r06YOZM2fC0NAQo0ePrtG1o6Oj0bJly0oPVJk1axb++c9/IigoCDNmzMDJkyexdetWbN++XWoTFhaGl19+GW3btoVGo8H69euRlJSEDRs26HgXiIiIiIiIau5vldQBwPvvv4/4+PgK9W5ubhAEAXK5HM7OzhgwYACCgoIqfW3AtGnTcOjQIcycOROmpqZPvWZZWVm1B6o4OTnh//2//4d58+Zhw4YNaNWqFdavX49Ro0ZJbbKzszFz5kxkZGRIL0g/evQounfvruMdAII8rLgVk4iIiIiIakQQy0/8oHqn0WigUCiQk5PDpI6IiIiIqAnTJTf4Wz1TR0RERERERLr5222/JODj5EwYy4vqOwyiRmdJZ+v6DoGIiIioznGlrpZEUUS/fv3g5+dX4buNGzdCoVBg27ZtEAQB2dnZzz9AIiIiIiJqEpjU1ZIgCIiJicHPP/+Mzz77TKq/fv06Fi9ejE8++QT29vb1GCERERERETUFTOr+Ajs7O3zyySdYsGABrl+/DlEUMW3aNPTt2xcBAQH1HR4RERERETUBfKbuL5oyZQq++eYbBAYGYtSoUbhw4QIuXLhQo76FhYUoLCyUPms0mmcVJhERERERNVJM6urA5s2b0aFDBxw7dgz//ve/YWtrW6N+ERERCAsLe8bRERERERFRY8btl3XA1tYWM2fORLt27TBy5Mga9wsODkZOTo5U0tLSnmGURERERETUGHGlro4YGBjAwEC32ymTySCTyZ5RRERERERE1BRwpY6IiIiIiKgBY1JHRERERETUgHH75d9QkIcVLCws6jsMIiIiIiJqAARRFMX6DoIe0Wg0UCgUyMnJYVJHRERERNSE6ZIbcPslERERERFRA8btl3XI19cXnp6eWLdu3V8a5+PkTBjLi+omKKImbkln6/oOgYiIiOiZajQrdYIgVFsCAgIqtDMwMIC9vT2CgoJQWFgojRUbG6vVrkWLFhg2bBh+++03rWsGBARgxIgRz3GWRERERERE2hrNSl16err05507d2LZsmW4dOmSVGdiYiL9OSYmBgMHDkRxcTGSk5MRGBgIMzMzvP/++1IbCwsLXLp0CaIo4s8//8SiRYswZMgQXL58GUZGRs9nUkRERERERE/RaFbqlEqlVBQKBQRBqFBXrlmzZlAqlbCzs8PQoUPx6quv4uzZs1rjlfdv2bIlunbtinnz5uGPP/7QShQrU1JSgrfeegvNmjWDlZUVli5dCp5FQ0REREREz0qjSepq6/Lly0hISECPHj2qbJOdnY2vvvoKAGBoaFjteHFxcTAwMMDPP/+M9evXY+3atdiyZUulbQsLC6HRaLQKERERERGRLhrN9ktdjBs3Dvr6+igpKUFhYSGGDh2K4OBgrTY5OTmQy+UQRRH5+fkAgFdffRXu7u7Vjm1nZ4e1a9dCEAS4ubnh/PnzWLt2LWbMmFGhbUREBMLCwupuYkRERERE1OQ0yZW6tWvXIikpCcnJydi3bx8uX76MSZMmabUxNzdHUlISfvnlF2zatAlt2rTBpk2bnjr2yy+/DEEQpM89e/bElStXUFpaWqFtcHAwcnJypJKWlvbXJ0dERERERE1Kk1ypUyqVcHFxAQC4ubkhNzcX48aNw8qVK6V6PT096c/u7u7IyMjA2LFjcfTo0TqLQyaTQSaT1dl4RERERETU9DTJlbon6evrAwAKCgqqbDNv3jwkJyfjm2++qXasU6dOVfjctm1b6RpERERERER1qUkmddnZ2cjIyMCtW7dw5MgRrFixAq6urmjXrl2VfSwsLDB9+nQsX7682tMs09LSEBQUhEuXLmH79u2IiorCO++88yymQURERERE1DS3XwYGBgL4v9cWeHt7Y9WqVTAwqP52vPPOO1i/fj2+/vprjBkzptI2kydPRkFBAbp37w59fX3MnTsXM2fO1Cm+IA8rWFhY6NSHiIiIiIiaJkHkS9T+NjQaDRQKBXJycpjUERERERE1YbrkBk1y+yUREREREVFj0SS3X/7dfZycCWN5UX2HQdSgLelsXd8hEBERET0XXKmrQkBAAARBgCAIMDQ0RIsWLdC/f39ER0ejrKxMaufo6Ci1MzExgaOjI8aMGYPDhw/XY/RERERERNRUMKmrxsCBA5Geno7U1FR8//33UKlUeOeddzB06FCUlJRI7VasWIH09HRcunQJ27ZtQ7NmzdCvXz+Eh4fXY/RERERERNQUcPtlNWQyGZRKJQDghRdewEsvvYSXX34Zffv2RWxsLKZPnw4AMDc3l9rZ29vD29sbLVu2xLJlyzB69Gi4ubnV2xyIiIiIiKhx40qdjvr06QMPDw/s3r272nbvvPMORFHEf/7znyrbFBYWQqPRaBUiIiIiIiJdMKmrBXd3d6Smplbbpnnz5rC1ta22XUREBBQKhVTs7OzqNlAiIiIiImr0mNTVgiiKEAThL7cLDg5GTk6OVNLS0uoyTCIiIiIiagL4TF0tXLx4EU5OTtW2yczMxN27d6ttJ5PJIJPJ6jo8IiIiIiJqQv5/e/cdFtWZ9g/8O8AwlIER6xhFCCCgCDZEUaISC9bIxjYaVIjsro21gCJRI8YgxhpRU1RasqsYRU3UjS+xZY2orAVXypLYor5iiZcwKhEBn98feZmfE4pOnAGH+X6u61zJec5znnM/574meuc0XqnT0eHDh3HhwgWMHDmy1n7r1q2DmZkZgoOD6yYwIiIiIiIySbxSV4vS0lLcunULFRUVuH37Ng4cOID4+HgMGzYMEydO1PR78OABbt26hbKyMly5cgV///vfsWXLFsTHx8PNza0eZ0BERERERA2dRAgh6juIV1FoaChSU1MBABYWFnBwcEDHjh0xfvx4TJo0CWZmv13kdHZ2xs8//wwAsLS0hFKpRI8ePTBlyhQEBgbqdEy1Wg2FQoHi4mLY29vrd0JERERERGQ0dKkNWNS9QljUERERERERoFttwNsvX0Frzt+DlfxJfYdB9Eqb37lpfYdARERE9Ergi1KIiIiIiIiMWIMo6kJDQyGRSCCRSCCVSuHi4oKoqCg8evQIAJCeno7u3btDoVDAzs4OXl5eiIyM1OxfUVGB+Ph4eHp6wtraGo0bN0aPHj2QnJxc7TEsLCzQpk0bTJ06Fffv36/z+RIREREREVVqMLdfDho0CMnJySgrK8OxY8cQHh6OR48eYeTIkVCpVFi2bBneeustSCQS5OXl4dChQ5p9Y2NjsWnTJmzYsAG+vr5Qq9U4ffp0lYKt8hjl5eXIy8vDu+++i6KiImzbtq2up0tERERERASgARV1MpkMSqUSADB+/HgcOXIEe/bsgUwmQ0BAAObOnavp6+7urvX9uL1792LatGkYPXq0pq1jx461HqN169YYO3YsUlJStPoUFRVh3rx5+Prrr1FcXAw3NzcsX74cw4YN0+NsiYiIiIiIftMgbr+sjrW1NcrKyqBUKpGbm4ucnJwa+yqVShw+fBh379594fEvX76MAwcOQCqVatqePn2KwYMHIzMzE3//+9+Rl5eH5cuXw9zcvNoxSktLoVartRYiIiIiIiJdNJgrdc/KysrC1q1b0a9fP0RERODYsWPw9vaGk5MTevTogYEDB+Kdd96BTCYDAKxZswajRo2CUqmEl5cXevbsiREjRmDw4MFa4+7btw9yuRwVFRV4/PixZt9KBw8eRFZWFvLz8+Hu7g4AcHFxqTHO+Ph4LFmyRN/TJyIiIiIiE9JgrtRVFlxWVlbw9/dH7969sX79etja2mL//v24ePEiFi5cCLlcjsjISPj5+aGkpAQA0L59e+Tk5ODkyZMICwvD7du3MXz4cISHh2sdIzAwENnZ2Th16hQiIiIQFBSEiIgIzfbs7Gy0bt1aU9A9T0xMDIqLizXL9evX9XdCiIiIiIjIJDSYoq6y4CooKMDjx4+xa9cuNG/eXLPd1dUV4eHh2LJlC86ePYu8vDxs375ds93MzAzdunXD7NmzsXv3bqSkpCAxMRFXrlzR9LG1tYWbmxt8fHyQkJCA0tJSrStt1tbWOsUsk8lgb2+vtRAREREREemiwRR1lQWXk5OT1nNu1XF2doaNjY3mkwfVad++PQDU2mfx4sVYtWoVbt68CQDw8fHBjRs38OOPP/6BGRAREREREemuQT5T96zY2FiUlJRgyJAhcHJyQlFRERISElBWVoYBAwYAAEaNGoVevXqhZ8+eUCqVuHLlCmJiYuDu7g5PT88ax+7bty+8vLywbNkybNiwAX369EHv3r0xcuRIrFmzBm5ubvjvf/8LiUSCQYMG1dWUiYiIiIjIhDT4oq5Pnz7YuHEjJk6ciNu3b8PBwQGdO3dGRkYGPDw8AABBQUHYtm0b4uPjUVxcDKVSiTfffBOxsbGwsKj9FM2ZMwdhYWGIjo6Go6Mj0tPTERUVhXHjxuHRo0eaTxroYk7HJrwVk4iIiIiIXohECCHqOwj6jVqthkKhQHFxMYs6IiIiIiITpktt0OCv1NWVlJQUzJo1C0VFRS891prz92Alf/LyQRE1EPM7N63vEIiIiIheWQ3iRSmhoaGQSCRVbnPcs2cPJBIJAODo0aOQSCSQSCQwMzODQqFA586dMW/ePBQWFmr28fb2rvIpg0rbtm2DVCrF7du3NePpo4gjIiIiIiL6oxpEUQcAVlZW+Oijj3D//v1a+xUUFODmzZv497//jejoaBw8eBAdOnTAhQsXAACTJ0/GV199pfmG3bOSkpIwbNgwtGjRwiBzICIiIiIi0lWDKer69+8PpVKJ+Pj4Wvs1b94cSqUS7u7uUKlUOH78OJo1a4apU6cCACZMmIDS0lLs2LFDa79r167h8OHDmDx5cq3j79mzB+7u7rCyssKAAQP4QXEiIiIiIjKoBlPUmZubY9myZVi/fj1u3LjxwvtZW1tjypQpOH78OO7cuYMmTZpgxIgRSE5O1uqXnJyMFi1aYPDgwTWOVVJSgri4OKSmpuL48eNQq9VQqVQ19i8tLYVardZaiIiIiIiIdNFgijoA+NOf/oROnTph8eLFOu1X+S26q1evAgDeffdd/Otf/8Lly5cBAEIIpKSkIDQ0FObm5jWOU1ZWhg0bNsDf3x9du3ZFamoqMjMzkZWVVW3/+Ph4KBQKzeLo6KhT3ERERERERA2qqAOAjz76CKmpqcjLy3vhfSq/6lD5UpWBAweidevWmqt1hw8fxtWrVxEWFlbrOBYWFvD19dWse3p6olGjRsjPz6+2f0xMDIqLizULb9UkIiIiIiJdNbiirnfv3ggKCsJ77733wvtUFl3Ozs4AADMzM4SGhiI1NRVPnz5FcnIyevfujbZt2z53rMrC8HltACCTyWBvb6+1EBERERER6aLBFXUAsHz5cuzduxeZmZnP7fvrr79i06ZN6N27N5o1a6ZpDwsLw40bN7Br1y7s2rXruS9IAYDy8nKcPn1as15QUICioiLN7Z1ERERERET61iA/Pu7t7Y133nkH69evr7Ltzp07ePz4MR48eIAzZ85gxYoV+OWXX7Br1y6tfq+//jrefPNN/OUvf4FUKsWoUaOee1ypVIqIiAgkJCRAKpVixowZ6NGjB/z8/PQ2NyIiIiIiomc1yCt1ALB06VLNs3LP8vDwwGuvvYauXbti+fLl6N+/P3JyctC+ffsqfSdPnoz79+9DpVLBxsbmuce0sbFBdHQ0xo8fD39/f1hbWyMtLU0v8yEiIiIiIqqORFRX+VC9UKvVUCgUKC4u5vN1REREREQmTJfaoMFeqSMiIiIiIjIFDfKZOmO35vw9WMmf1HcYRDWa37lpfYdARERERP/HqK/UhYaGQiKRQCKRwMLCAm3atMHUqVNx//59rX6//vorHBwc0LhxY/z6669VxnF2dtaMY21tDU9PT6xcubLKM3np6eno3r07FAoF7Ozs4OXlhcjISIPOkYiIiIiIqDZGXdQBwKBBg1BYWIirV69iy5Yt2Lt3L6ZNm6bVJz09HR06dED79u2rvOWy0gcffIDCwkLk5+cjKioK7733HjZt2qTZfvDgQahUKowaNQpZWVk4c+YM4uLi8OQJr6gREREREVH9MfqiTiaTQalUonXr1hg4cCDGjh2LjIwMrT6JiYkICQlBSEgIEhMTqx3Hzs4OSqUSzs7OCA8Ph4+Pj9Y4+/btQ0BAAObOnQsPDw+4u7sjODi4ymcTvvnmG/j6+sLKygpNmzbF22+/rf9JExERERER/R+jL+qedfnyZRw4cABSqVTTdunSJZw4cQJjxozBmDFjkJmZicuXL9c4hhACR48eRX5+vtY4SqUSubm5yMnJqXHf/fv34+2338bQoUNx7tw5HDp0CL6+vjX2Ly0thVqt1lqIiIiIiIh0YfRF3b59+yCXy2FtbQ1XV1fk5eUhOjpasz0pKQmDBw/WPFM3aNAgJCUlVRknOjoacrkcMpkMgYGBEELgb3/7m2Z7REQEunXrBm9vbzg7O0OlUiEpKQmlpaWaPnFxcVCpVFiyZAnatWuHjh074r333qsx9vj4eCgUCs3i6Oiop7NCRERERESmwuiLusDAQGRnZ+PUqVOIiIhAUFAQIiIiAAAVFRVITU1FSEiIpn9ISAhSU1NRUVGhNc7cuXORnZ2N77//HoGBgViwYAF69uyp2W5ra4v9+/fj4sWLWLhwIeRyOSIjI+Hn54eSkhIAQHZ2Nvr16/fCscfExKC4uFizXL9+/WVOBRERERERmSCjL+psbW3h5uYGHx8fJCQkoLS0FEuWLAEA/M///A/+93//F2PHjoWFhQUsLCygUqlw48aNKs/dNW3aFG5ubvD390d6ejrWrl2LgwcPVjmeq6srwsPDsWXLFpw9exZ5eXnYvn07AMDa2lqn2GUyGezt7bUWIiIiIiIiXRh9Ufd7ixcvxqpVq3Dz5k0kJiZCpVIhOztba3nnnXdqfGEKADg4OCAiIgJRUVFVPmvwLGdnZ9jY2ODRo0cAAB8fHxw6dEjvcyIiIiIiIqpJg/v4eN++feHl5YW4uDjs3bsX33zzDTp06KDVZ9KkSRg6dCju3r2LZs2aVTvO9OnT8dFHHyE9PR2jRo1CbGwsSkpKMGTIEDg5OaGoqAgJCQkoKyvDgAEDAPxWUPbr1w+urq5QqVQoLy/Ht99+i3nz5hl83kREREREZJoaXFEHAHPmzMGkSZNQXl5e7TNugYGBsLOzw5dffok5c+ZUO0azZs0wYcIExMbG4u2330afPn2wceNGTJw4Ebdv34aDgwM6d+6MjIwMeHh4APitoNyxYweWLl2K5cuXw97eHr1799Y9/o5NeCsmERERERG9EImo7f5CqlNqtRoKhQLFxcUs6oiIiIiITJgutUGDe6aOiIiIiIjIlDTI2y+N3Zrz92Alf1LfYVADM79z0/oOgYiIiIgMgFfqXkB6ejq6d+8OhUIBOzs7eHl5ITIyUrM9JSUFEolEs7Ro0QLDhw9Hbm5uPUZNRERERESmgEXdcxw8eBAqlQqjRo1CVlYWzpw5g7i4ODx5on0lzd7eHoWFhbh58yb279+PR48eYejQoVX6ERERERER6ZPJFXV9+/ZFREQEZs2aBQcHB7Ro0QKbNm3Co0ePEBYWBjs7O7i6uuLbb78FAOzbtw8BAQGYO3cuPDw84O7ujuDgYKxfv15rXIlEAqVSiZYtW8LX1xezZ8/Gzz//jIKCgvqYJhERERERmQiTK+oAIDU1FU2bNkVWVhYiIiIwdepUjB49Gj179sTZs2cRFBSECRMmoKSkBEqlErm5ucjJyXnh8YuKirB161YAgFQqrbFfaWkp1Gq11kJERERERKQLkyzqOnbsiIULF6Jt27aIiYmBtbU1mjZtij//+c9o27Yt3n//fdy7dw//+c9/EBERgW7dusHb2xvOzs5QqVRISkpCaWmp1pjFxcWQy+WwtbWFg4MD0tLS8NZbb8HT07PGOOLj46FQKDSLo6OjoadOREREREQNjEkWdT4+Ppp/Nzc3R5MmTeDt7a1pa9GiBQDgzp07sLW1xf79+3Hx4kUsXLgQcrkckZGR8PPzQ0lJiWYfOzs7ZGdn48yZM/jss8/g6uqKzz77rNY4YmJiUFxcrFmuX7+u55kSEREREVFDZ5KfNPj9LZESiUSrTSKRAACePn2qaXN1dYWrqyvCw8OxYMECuLu7Y/v27QgLCwMAmJmZwc3NDQDg6emJW7duYezYsfjXv/5VYxwymQwymUxv8yIiIiIiItNjklfqXpazszNsbGzw6NGjGvvMnj0b58+fx+7du+swMiIiIiIiMjUmeaVOF7GxsSgpKcGQIUPg5OSEoqIiJCQkoKysDAMGDKhxP3t7e4SHh2Px4sUIDg7WXP0jIiIiIiLSJxZ1z9GnTx9s3LgREydOxO3bt+Hg4IDOnTsjIyMDHh4ete47c+ZMJCQkYMeOHRgzZswLH3NOxyawt7d/2dCJiIiIiMgESIQQor6DoN+o1WooFAoUFxezqCMiIiIiMmG61AZ8po6IiIiIiMiI8fZLPZFIJNi9ezeCg4Nfeqw15+/BSv7k5YMikzW/c9P6DoGIiIiI6ohRX6kLDQ2FRCLRfJLAxcUFUVFRmrdSpqeno3v37lAoFLCzs4OXlxciIyM1+1dUVCA+Ph6enp6wtrZG48aN0aNHDyQnJ1d7DAsLC7Rp0wZTp07F/fv363y+REREREREv2f0V+oGDRqE5ORklJWV4dixYwgPD8ejR48wcuRIqFQqLFu2DG+99RYkEgny8vJw6NAhzb6xsbHYtGkTNmzYAF9fX6jVapw+fbpKwVZ5jPLycuTl5eHdd99FUVERtm3bVtfTJSIiIiIi0mL0RZ1MJoNSqQQAjB8/HkeOHMGePXsgk8kQEBCAuXPnavq6u7tr3R65d+9eTJs2DaNHj9a0dezYsdZjtG7dGmPHjkVKSkqVfoWFhRg8eDCOHj0KpVKJFStWaI1NRERERESkb0Z9+2V1rK2tUVZWBqVSidzcXOTk5NTYV6lU4vDhw7h79+4Lj3/58mUcOHAAUqm0yrZFixZh5MiROH/+PEJCQjBu3Djk5+fXOFZpaSnUarXWQkREREREpIsGVdRlZWVh69at6NevHyIiItCtWzd4e3vD2dkZKpUKSUlJKC0t1fRfs2YN7t69C6VSCR8fH0yZMgXffvttlXH37dsHuVwOa2truLq6Ii8vD9HR0VX6jR49GuHh4XB3d8fSpUvh6+uL9evX1xhvfHw8FAqFZnF0dNTPiSAiIiIiIpNh9EVdZcFlZWUFf39/9O7dG+vXr4etrS3279+PixcvYuHChZDL5YiMjISfnx9KSkoAAO3bt0dOTg5OnjyJsLAw3L59G8OHD0d4eLjWMQIDA5GdnY1Tp04hIiICQUFBiIiIqBKLv79/lfXartTFxMSguLhYs1y/fl0PZ4SIiIiIiEyJ0Rd1lQVXQUEBHj9+jF27dqF58+aa7a6urggPD8eWLVtw9uxZ5OXlYfv27ZrtZmZm6NatG2bPno3du3cjJSUFiYmJuHLliqaPra0t3Nzc4OPjg4SEBJSWlmLJkiUvFJ9EIqlxm0wmg729vdZCRERERESkC6Mv6ioLLicnp2qfc3uWs7MzbGxsNJ88qE779u0BoNY+ixcvxqpVq3Dz5k2t9pMnT1ZZ9/T0fN4UiIiIiIiI/jCjf/tlTWJjY1FSUoIhQ4bAyckJRUVFSEhIQFlZGQYMGAAAGDVqFHr16oWePXtCqVTiypUriImJgbu7e63FWN++feHl5YVly5Zhw4YNmvYdO3bA19cXAQEB+Mc//oGsrCwkJiYafK5ERERERGS6GmxR16dPH2zcuBETJ07E7du34eDggM6dOyMjIwMeHh4AgKCgIGzbtg3x8fEoLi6GUqnEm2++idjYWFhY1H5q5syZg7CwMERHR2tecLJkyRKkpaVh2rRpUCqV+Mc//qG58qeLOR2b8FZMIiIiIiJ6IRIhhKjvIOg3arUaCoUCxcXFLOqIiIiIiEyYLrVBg71SZ8zWnL8HK/mT+g6D6sD8zk3rOwQiIiIiMnJG/6KUV0VKSgoaNWpU32EQEREREZGJMcqiLjQ0FBKJBBKJBFKpFC4uLoiKitK8sTI9PR3du3eHQqGAnZ0dvLy8EBkZqdk/JSUFEokEgwYN0hq3qKgIEokER48e1bRVHkcikcDW1hZt27ZFaGgozpw5UydzJSIiIiIiqo1RFnUAMGjQIBQWFuLy5cv48MMP8cknnyAqKgoHDx6ESqXCqFGjkJWVhTNnziAuLg5PnmjfzmhhYYFDhw7hyJEjzz1WcnIyCgsLkZubi40bN+Lhw4fo3r07vvjiC0NNj4iIiIiI6IUY7TN1MpkMSqUSADB+/HgcOXIEe/bsgUwmQ0BAAObOnavp6+7ujuDgYK39bW1tMWbMGMyfPx+nTp2q9ViNGjXSHMvZ2RkDBw7EpEmTMGPGDAwfPhwODg6avnv27MG8efNw7do1vPHGG0hKStK8HZOIiIiIiEjfjPZK3e9ZW1ujrKwMSqUSubm5yMnJee4+sbGxuHDhAnbu3Knz8WbPno0HDx7gu+++07SVlJQgLi4OqampOH78ONRqNVQqVY1jlJaWQq1Way1ERERERES6aBBFXVZWFrZu3Yp+/fohIiIC3bp1g7e3N5ydnaFSqZCUlITS0tIq+7322muYOXMmFixYgPLycp2OWflx8qtXr2raysrKsGHDBvj7+6Nr165ITU1FZmYmsrKyqh0jPj4eCoVCs/CKHhERERER6cpoi7p9+/ZBLpfDysoK/v7+6N27N9avXw9bW1vs378fFy9exMKFCyGXyxEZGQk/Pz+UlJRUGSc6Ohp3795FUlKSTsev/LyfRCLRtFlYWMDX11ez7unpiUaNGiE/P7/aMWJiYlBcXKxZrl+/rlMMRERERERERlvUBQYGIjs7GwUFBXj8+DF27dqF5s2ba7a7uroiPDwcW7ZswdmzZ5GXl4ft27dXGadRo0aIiYnBkiVLqi36alJZqL3++uta7c8WebW1Ab89F2hvb6+1EBERERER6cJoizpbW1u4ubnByckJUqm01r7Ozs6wsbHRfPLg9yIiImBmZoZ169a98PE//vhj2Nvbo3///pq28vJynD59WrNeUFCAoqIiza2aRERERERE+ma0b7+sSWxsLEpKSjBkyBA4OTmhqKgICQkJKCsrw4ABA6rdx8rKCkuWLMH06dOr3V5UVIRbt26htLQUP/74Iz7//HPs2bMHX3zxhdYHx6VSKSIiIpCQkACpVIoZM2agR48e8PPzM8RUiYiIiIiIGl5R16dPH2zcuBETJ07E7du34eDggM6dOyMjIwMeHh417jdp0iSsXr0aeXl5VbaFhYUB+K34a9WqFQICApCVlYUuXbpo9bOxsUF0dDTGjx+PGzduICAgQOdn9QBgTscmvBWTiIiIiIheiERUvvGD6p1arYZCoUBxcTGLOiIiIiIiE6ZLbWC0z9QRERERERERizoiIiIiIiKjxqKOiIiIiIjIiLGoIyIiIiIiMmIs6oiIiIiIiIwYizoiIiIiIiIjxqKOiIiIiIjIiLGoIyIiIiIiMmIs6oiIiIiIiIwYizoiIiIiIiIjxqKOiIiIiIjIiLGoIyIiIiIiMmIs6oiIiIiIiIwYizoiIiIiIiIjxqKOiIiIiIjIiLGoIyIiIiIiMmIs6oiIiIiIiIwYizoiIiIiIiIjZlHfAdD/J4QAAKjV6nqOhIiIiIiI6lNlTVBZI9SGRd0r5N69ewAAR0fHeo6EiIiIiIheBQ8ePIBCoai1D4u6V0jjxo0BANeuXXtu4ujVoFar4ejoiOvXr8Pe3r6+w6HnYL6MD3NmXJgv48OcGRfmy7i8bL6EEHjw4AFee+215/ZlUfcKMTP77RFHhULBH6qRsbe3Z86MCPNlfJgz48J8GR/mzLgwX8blZfL1ohd6+KIUIiIiIiIiI8aijoiIiIiIyIixqHuFyGQyLF68GDKZrL5DoRfEnBkX5sv4MGfGhfkyPsyZcWG+jEtd5ksiXuQdmURERERERPRK4pU6IiIiIiIiI8aijoiIiIiIyIixqCMiIiIiIjJiLOqIiIiIiIiMGIs6A/vkk0/w+uuvw8rKCl27dsWxY8dq7f/999+ja9eusLKygouLCz777LMqfdLT09G+fXvIZDK0b98eu3fvNlT4Jkff+crNzcXIkSPh7OwMiUSCjz/+2IDRmyZ952zz5s1444034ODgAAcHB/Tv3x9ZWVmGnIJJ0Xe+du3aBV9fXzRq1Ai2trbo1KkTvvzyS0NOwaQY4s+wSmlpaZBIJAgODtZz1KZN3zlLSUmBRCKpsjx+/NiQ0zAZhviNFRUVYfr06WjZsiWsrKzQrl07/POf/zTUFEyOvnPWt2/fan9jQ4cO1S0wQQaTlpYmpFKp2Lx5s8jLyxMzZ84Utra24ueff662/+XLl4WNjY2YOXOmyMvLE5s3bxZSqVTs3LlT0yczM1OYm5uLZcuWifz8fLFs2TJhYWEhTp48WVfTarAMka+srCwRFRUltm3bJpRKpVi7dm0dzcY0GCJn48ePFxs3bhTnzp0T+fn5IiwsTCgUCnHjxo26mlaDZYh8HTlyROzatUvk5eWJixcvio8//liYm5uLAwcO1NW0GixD5KvS1atXRatWrcQbb7whRowYYeCZmA5D5Cw5OVnY29uLwsJCrYVeniHyVVpaKnx9fcWQIUPEDz/8IK5evSqOHTsmsrOz62paDZohcnbv3j2t31ZOTo4wNzcXycnJOsXGos6A/Pz8xJQpU7TaPD09xfz586vtP2/ePOHp6anV9te//lX06NFDsz5mzBgxaNAgrT5BQUFCpVLpKWrTZYh8PcvJyYlFnZ4ZOmdCCFFeXi7s7OxEamrqywds4uoiX0II0blzZ7Fw4cKXC5YMlq/y8nLRq1cvsWXLFjFp0iQWdXpkiJwlJycLhUKh91jJMPn69NNPhYuLi3jy5In+A6Y6+XNs7dq1ws7OTjx8+FCn2Hj7pYE8efIEZ86cwcCBA7XaBw4ciMzMzGr3OXHiRJX+QUFBOH36NMrKymrtU9OY9GIMlS8ynLrKWUlJCcrKytC4cWP9BG6i6iJfQggcOnQIBQUF6N27t/6CN0GGzNcHH3yAZs2aYfLkyfoP3IQZMmcPHz6Ek5MTWrdujWHDhuHcuXP6n4CJMVS+vvnmG/j7+2P69Olo0aIFOnTogGXLlqGiosIwEzEhdfX3jsTERKhUKtja2uoUH4s6A/nll19QUVGBFi1aaLW3aNECt27dqnafW7duVdu/vLwcv/zyS619ahqTXoyh8kWGU1c5mz9/Plq1aoX+/fvrJ3ATZch8FRcXQy6Xw9LSEkOHDsX69esxYMAA/U/ChBgqX8ePH0diYiI2b95smMBNmKFy5unpiZSUFHzzzTfYtm0brKys0KtXL/z000+GmYiJMFS+Ll++jJ07d6KiogL//Oc/sXDhQqxevRpxcXGGmYgJqYu/d2RlZSEnJwfh4eE6x2eh8x6kE4lEorUuhKjS9rz+v2/XdUx6cYbIFxmWIXO2YsUKbNu2DUePHoWVlZUeoiVD5MvOzg7Z2dl4+PAhDh06hDlz5sDFxQV9+/bVX+AmSp/5evDgAUJCQrB582Y0bdpU/8ESAP3/xnr06IEePXpotvfq1QtdunTB+vXrkZCQoK+wTZa+8/X06VM0b94cmzZtgrm5Obp27YqbN29i5cqVeP/99/UcvWky5N87EhMT0aFDB/j5+ekcF4s6A2natCnMzc2rVO537typUrFXUiqV1fa3sLBAkyZNau1T05j0YgyVLzIcQ+ds1apVWLZsGQ4ePAgfHx/9Bm+CDJkvMzMzuLm5AQA6deqE/Px8xMfHs6h7CYbIV25uLq5evYrhw4drtj99+hQAYGFhgYKCAri6uup5Jqajrv4cMzMzQ7du3Xil7iUZKl8tW7aEVCqFubm5pk+7du1w69YtPHnyBJaWlnqeiekw9G+spKQEaWlp+OCDD/5QfLz90kAsLS3RtWtXfPfdd1rt3333HXr27FntPv7+/lX6Z2RkwNfXF1KptNY+NY1JL8ZQ+SLDMWTOVq5ciaVLl+LAgQPw9fXVf/AmqC5/Y0IIlJaWvnzQJswQ+fL09MSFCxeQnZ2tWd566y0EBgYiOzsbjo6OBpuPKair35gQAtnZ2WjZsqV+AjdRhspXr169cPHiRc3/MAGAH3/8ES1btmRB95IM/Rv76quvUFpaipCQkD8WoE6vVSGdVL72NDExUeTl5YlZs2YJW1tbcfXqVSGEEPPnzxcTJkzQ9K987ens2bNFXl6eSExMrPLa0+PHjwtzc3OxfPlykZ+fL5YvX85PGuiJIfJVWloqzp07J86dOydatmwpoqKixLlz58RPP/1U5/NriAyRs48++khYWlqKnTt3ar1i+MGDB3U+v4bGEPlatmyZyMjIEJcuXRL5+fli9erVwsLCQmzevLnO59fQGCJfv8e3X+qXIXIWGxsrDhw4IC5duiTOnTsnwsLChIWFhTh16lSdz6+hMUS+rl27JuRyuZgxY4YoKCgQ+/btE82bNxcffvhhnc+vITLkfxcDAgLE2LFj/3BsLOoMbOPGjcLJyUlYWlqKLl26iO+//16zbdKkSaJPnz5a/Y8ePSo6d+4sLC0thbOzs/j000+rjLljxw7h4eEhpFKp8PT0FOnp6YaehsnQd76uXLkiAFRZfj8O/XH6zpmTk1O1OVu8eHEdzKbh03e+FixYINzc3ISVlZVwcHAQ/v7+Ii0trS6mYhIM8WfYs1jU6Z++czZr1izRpk0bYWlpKZo1ayYGDhwoMjMz62IqJsEQv7HMzEzRvXt3IZPJhIuLi4iLixPl5eWGnorJMETOCgoKBACRkZHxh+OSCPF/T+sRERERERGR0eEzdUREREREREaMRR0REREREZERY1FHRERERERkxFjUERERERERGTEWdUREREREREaMRR0REREREZERY1FHRERERERkxFjUERERERERGTEWdURE1KBJJBLs2bPnhfvHxsaiU6dOtfYJDQ1FcHDwS8VFRESkLyzqiIioXg0fPhz9+/evdtuJEycgkUhw9uzZPzx+YWEhBg8e/If3N5S+ffti1qxZ9R1GjY4ePQqJRIKioqL6DoWIiJ6DRR0REdWryZMn4/Dhw/j555+rbEtKSkKnTp3QpUsXncd98uQJAECpVEImk710nKakrKysvkMgIiIdsKgjIqJ6NWzYMDRv3hwpKSla7SUlJdi+fTsmT56Me/fuYdy4cWjdujVsbGzg7e2Nbdu2afXv27cvZsyYgTlz5qBp06YYMGAAgKq3X0ZHR8Pd3R02NjZwcXHBokWLqi1iPv/8czg6OsLGxgajR4+u9YqVEAIrVqyAi4sLrK2t0bFjR+zcuVOn8+Ds7IwPP/wQEydOhFwuh5OTE77++mvcvXsXI0aMgFwuh7e3N06fPq3ZJyUlBY0aNcKePXvg7u4OKysrDBgwANevX9ca+9NPP4WrqyssLS3h4eGBL7/8Umu7RCLBZ599hhEjRsDW1hbh4eEIDAwEADg4OEAikSA0NBQAcODAAQQEBKBRo0Zo0qQJhg0bhkuXLmnGunr1KiQSCXbt2oXAwEDY2NigY8eOOHHihNYxjx8/jj59+sDGxgYODg4ICgrC/fv39XY+iYhMCYs6IiKqVxYWFpg4cSJSUlIghNC079ixA0+ePME777yDx48fo2vXrti3bx9ycnLwl7/8BRMmTMCpU6e0xkpNTYWFhQWOHz+Ozz//vNrj2dnZISUlBXl5eVi3bh02b96MtWvXavW5ePEivvrqK+zduxcHDhxAdnY2pk+fXuMcFi5ciOTkZHz66afIzc3F7NmzERISgu+//16nc7F27Vr06tUL586dw9ChQzFhwgRMnDgRISEhOHv2LNzc3DBx4kSt81RSUoK4uDikpqbi+PHjUKvVUKlUmu27d+/GzJkzERkZiZycHPz1r39FWFgYjhw5onXsxYsXY8SIEbhw4QI++OADpKenAwAKCgpQWFiIdevWAQAePXqEOXPm4N///jcOHToEMzMz/OlPf8LTp0+1xluwYAGioqKQnZ0Nd3d3jBs3DuXl5QCA7Oxs9OvXD15eXjhx4gR++OEHDB8+HBUVFXo9n0REJkMQERHVs/z8fAFAHD58WNPWu3dvMW7cuBr3GTJkiIiMjNSs9+nTR3Tq1KlKPwBi9+7dNY6zYsUK0bVrV8364sWLhbm5ubh+/bqm7dtvvxVmZmaisLBQCCHEpEmTxIgRI4QQQjx8+FBYWVmJzMxMrXEnT55ca/x9+vQRM2fO1Kw7OTmJkJAQzXphYaEAIBYtWqRpO3HihACgiSM5OVkAECdPntT0qTyXp06dEkII0bNnT/HnP/9Z69ijR48WQ4YM0awDELNmzdLqc+TIEQFA3L9/v8Y5CCHEnTt3BABx4cIFIYQQV65cEQDEli1bNH1yc3MFAJGfny+EEGLcuHGiV69e1Y73R88nEZEp45U6IiKqd56enujZsyeSkpIAAJcuXcKxY8fw7rvvAgAqKioQFxcHHx8fNGnSBHK5HBkZGbh27ZrWOL6+vs891s6dOxEQEAClUgm5XI5FixZVGadNmzZo3bq1Zt3f3x9Pnz5FQUFBlfHy8vLw+PFjDBgwAHK5XLN88cUXWrclvggfHx/Nv7do0QIA4O3tXaXtzp07mjYLCwuteXt6eqJRo0bIz88HAOTn56NXr15ax+nVq5dme6UXOXfAb7kZP348XFxcYG9vj9dffx0AqpzDZ+fSsmVLrbgrr9RVR5/nk4jIVFjUdwBERETAby9MmTFjBjZu3Ijk5GQ4OTlp/uK/evVqrF27Fh9//DG8vb1ha2uLWbNmaV6GUsnW1rbWY5w8eRIqlQpLlixBUFAQFAoF0tLSsHr16lr3k0gkWv98VuVth/v370erVq20tun6ghapVFrlmNW1/f5Wx+rierbt99uFEFXannfuKg0fPhyOjo7YvHkzXnvtNTx9+hQdOnSokova4ra2tq5xfH2eTyIiU8ErdURE9EoYM2YMzM3NsXXrVqSmpiIsLExTDBw7dgwjRoxASEgIOnbsCBcXF/z00086H+P48eNwcnLCggUL4Ovri7Zt21b71s1r167h5s2bmvUTJ07AzMwM7u7uVfq2b98eMpkM165dg5ubm9bi6Oioc4y6Ki8v13p5SkFBAYqKiuDp6QkAaNeuHX744QetfTIzM9GuXbtax7W0tAQAzXNuAHDv3j3k5+dj4cKF6NevH9q1a6d5uYkufHx8cOjQoWq31ff5JCIyRrxSR0RErwS5XI6xY8fivffeQ3FxseZtiwDg5uaG9PR0ZGZmwsHBAWvWrMGtW7eeW5j8npubG65du4a0tDR069YN+/fvx+7du6v0s7KywqRJk7Bq1Sqo1Wr87W9/w5gxY6BUKqv0tbOzQ1RUFGbPno2nT58iICAAarUamZmZkMvlmDRpks7nQhdSqRQRERFISEiAVCrFjBkz0KNHD/j5+QEA5s6dizFjxqBLly7o168f9u7di127duHgwYO1juvk5ASJRIJ9+/ZhyJAhsLa2hoODA5o0aYJNmzahZcuWuHbtGubPn69zzDExMfD29sa0adMwZcoUWFpa4siRIxg9ejSaNm1ar+eTiMgY8UodERG9MiZPnoz79++jf//+aNOmjaZ90aJF6NKlC4KCgtC3b18olUoEBwfrPP6IESMwe/ZszJgxA506dUJmZiYWLVpUpZ+bmxvefvttDBkyBAMHDkSHDh3wySef1Dju0qVL8f777yM+Ph7t2rVDUFAQ9u7dq3nezJBsbGwQHR2N8ePHw9/fH9bW1khLS9NsDw4Oxrp167By5Up4eXnh888/R3JyMvr27VvruK1atcKSJUswf/58tGjRAjNmzICZmRnS0tJw5swZdOjQAbNnz8bKlSt1jtnd3R0ZGRk4f/48/Pz84O/vj6+//hoWFr/9v+b6PJ9ERMZIIsQz70UmIiIio5GSkoJZs2bV+g09IiJq+HiljoiIiIiIyIixqCMiIiIiIjJivP2SiIiIiIjIiPFKHRERERERkRFjUUdERERERGTEWNQREREREREZMRZ1RERERERERoxFHRERERERkRFjUUdERERERGTEWNQREREREREZMRZ1RERERERERuz/AcJlyU2UKPf2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.70      0.78      0.74         9\n",
      "      Barley       0.62      0.50      0.56        10\n",
      "       ECHCG       0.91      1.00      0.95        10\n",
      "         Oat       0.80      0.44      0.57         9\n",
      "       PAPRH       1.00      0.90      0.95        10\n",
      "       POLAV       1.00      1.00      1.00         9\n",
      "       Wheat       0.74      0.86      0.79        29\n",
      "\n",
      "    accuracy                           0.80        86\n",
      "   macro avg       0.82      0.78      0.79        86\n",
      "weighted avg       0.80      0.80      0.79        86\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVEFA</th>\n",
       "      <th>Barley</th>\n",
       "      <th>ECHCG</th>\n",
       "      <th>Oat</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>POLAV</th>\n",
       "      <th>Wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVEFA</th>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barley</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHCG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLAV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wheat</th>\n",
       "      <td>6.896552</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.206897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AVEFA     Barley       ECHCG        Oat  PAPRH  POLAV      Wheat\n",
       "AVEFA   77.777778   0.000000    0.000000   0.000000    0.0    0.0  22.222222\n",
       "Barley   0.000000  50.000000    0.000000  10.000000    0.0    0.0  40.000000\n",
       "ECHCG    0.000000   0.000000  100.000000   0.000000    0.0    0.0   0.000000\n",
       "Oat      0.000000  22.222222    0.000000  44.444444    0.0    0.0  33.333333\n",
       "PAPRH   10.000000   0.000000    0.000000   0.000000   90.0    0.0   0.000000\n",
       "POLAV    0.000000   0.000000    0.000000   0.000000    0.0  100.0   0.000000\n",
       "Wheat    6.896552   3.448276    3.448276   0.000000    0.0    0.0  86.206897"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'target' is the name of your target column:\n",
    "X = df.drop(\"species\", axis=1)  # Features\n",
    "y = df[\"species\"]               # Target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and train the random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Variable Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances from Random Forest')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()\n",
    "\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04ea9118-8256-40ff-a898-3f54e18770ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping dicotâ†’crop model: no samples in that group.\n",
      "Final Species-Level Accuracy: 0.9534883720930233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.89      0.89      0.89         9\n",
      "      Barley       1.00      1.00      1.00         7\n",
      "       ECHCG       1.00      0.88      0.93         8\n",
      "         Oat       1.00      1.00      1.00        11\n",
      "       PAPRH       0.85      1.00      0.92        11\n",
      "       POLAV       1.00      0.88      0.93         8\n",
      "       Wheat       0.97      0.97      0.97        32\n",
      "\n",
      "    accuracy                           0.95        86\n",
      "   macro avg       0.96      0.94      0.95        86\n",
      "weighted avg       0.96      0.95      0.95        86\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVEFA</th>\n",
       "      <th>Barley</th>\n",
       "      <th>ECHCG</th>\n",
       "      <th>Oat</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>POLAV</th>\n",
       "      <th>Wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVEFA</th>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barley</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHCG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLAV</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wheat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AVEFA  Barley  ECHCG    Oat    PAPRH  POLAV      Wheat\n",
       "AVEFA   88.888889     0.0    0.0    0.0    0.000    0.0  11.111111\n",
       "Barley   0.000000   100.0    0.0    0.0    0.000    0.0   0.000000\n",
       "ECHCG    0.000000     0.0   87.5    0.0   12.500    0.0   0.000000\n",
       "Oat      0.000000     0.0    0.0  100.0    0.000    0.0   0.000000\n",
       "PAPRH    0.000000     0.0    0.0    0.0  100.000    0.0   0.000000\n",
       "POLAV   12.500000     0.0    0.0    0.0    0.000   87.5   0.000000\n",
       "Wheat    0.000000     0.0    0.0    0.0    3.125    0.0  96.875000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example lists of species for each category\n",
    "monocot_species = [\"Barley\",\"Wheat\",\"Oat\",\"AVEFA\",\"ECHCG\"]  # example species\n",
    "dicot_species   = [\"PAPRH\",\"POLAV\"]\n",
    "weed_species    = [\"AVEFA\",\"PAPRH\",\"POLAV\",\"ECHCG\"]  # example of some species labeled as weeds\n",
    "crop_species    = [\"Barley\",\"Wheat\",\"Oat\"]\n",
    "\n",
    "# Third-level species groups (adjust these depending on your actual data):\n",
    "monocot_weed_species = [\"AVEFA\"]\n",
    "monocot_crop_species = [ \"Barley\",\"Wheat\",\"Oat\"]\n",
    "dicot_weed_species   = [\"PAPRH\",\"POLAV\"]\n",
    "\n",
    "# Assume df is your main dataframe with features and species\n",
    "# Example:\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# Create first-level category\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "# Create second-level category\n",
    "df['category2'] = df['species'].apply(lambda s: 'weed' if s in weed_species else 'crop')\n",
    "\n",
    "\n",
    "y_cat1 = df[\"category1\"]  # Level 1 target \n",
    "\n",
    "# Level 1: Monocot vs Dicot\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1)\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "y_pred_cat1 = clf_cat1.predict(X_test_cat1)\n",
    "\n",
    "# Split test data by predicted category1\n",
    "X_test_monocot = X_test_cat1[y_pred_cat1 == 'monocot']\n",
    "X_test_dicot   = X_test_cat1[y_pred_cat1 == 'dicot']\n",
    "\n",
    "y_test_monocot = df.loc[X_test_monocot.index, 'category2']\n",
    "y_test_dicot   = df.loc[X_test_dicot.index, 'category2']\n",
    "\n",
    "# Level 2: Weed vs Crop (for monocot)\n",
    "monocot_mask = df['category1'] == 'monocot'\n",
    "X_monocot = X[monocot_mask]\n",
    "y_monocot = df['category2'][monocot_mask]\n",
    "\n",
    "X_train_mono, X_val_mono, y_train_mono, y_val_mono = train_test_split(X_monocot, y_monocot, test_size=0.2, random_state=42, stratify=y_monocot)\n",
    "clf_cat2_monocot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_monocot.fit(X_train_mono, y_train_mono)\n",
    "\n",
    "y_pred_cat2_monocot = clf_cat2_monocot.predict(X_test_monocot)\n",
    "\n",
    "# Level 2: Weed vs Crop (for dicot)\n",
    "dicot_mask = df['category1'] == 'dicot'\n",
    "X_dicot = X[dicot_mask]\n",
    "y_dicot = df['category2'][dicot_mask]\n",
    "\n",
    "X_train_di, X_val_di, y_train_di, y_val_di = train_test_split(X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot)\n",
    "clf_cat2_dicot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_dicot.fit(X_train_di, y_train_di)\n",
    "\n",
    "y_pred_cat2_dicot = clf_cat2_dicot.predict(X_test_dicot)\n",
    "\n",
    "# Now we have predictions for category1 and category2. Next: species level.\n",
    "\n",
    "# For the third level, we train separate models for each final group:\n",
    "# Monocot-Weed, Monocot-Crop, Dicot-Weed, Dicot-Crop.\n",
    "\n",
    "# Example: Monocot-Weed model (if multiple species in that group)\n",
    "mono_weed_mask = (df['category1'] == 'monocot') & (df['category2'] == 'weed')\n",
    "X_mono_weed = X[mono_weed_mask]\n",
    "y_mono_weed = df['species'][mono_weed_mask]\n",
    "\n",
    "clf_mono_weed = RandomForestClassifier(random_state=42)\n",
    "clf_mono_weed.fit(X_mono_weed, y_mono_weed)\n",
    "\n",
    "# Monocot-Crop model\n",
    "mono_crop_mask = (df['category1'] == 'monocot') & (df['category2'] == 'crop')\n",
    "X_mono_crop = X[mono_crop_mask]\n",
    "y_mono_crop = df['species'][mono_crop_mask]\n",
    "\n",
    "clf_mono_crop = RandomForestClassifier(random_state=42)\n",
    "clf_mono_crop.fit(X_mono_crop, y_mono_crop)\n",
    "\n",
    "# Dicot-Weed model\n",
    "dicot_weed_mask = (df['category1'] == 'dicot') & (df['category2'] == 'weed')\n",
    "X_dicot_weed = X[dicot_weed_mask]\n",
    "y_dicot_weed = df['species'][dicot_weed_mask]\n",
    "\n",
    "clf_dicot_weed = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_weed.fit(X_dicot_weed, y_dicot_weed)\n",
    "\n",
    "# Dicot-Crop model\n",
    "# Dicotâ€‘Crop model\n",
    "dicot_crop_mask = (df['category1'] == 'dicot') & (df['category2'] == 'crop')\n",
    "X_dicot_crop = X[dicot_crop_mask]\n",
    "y_dicot_crop = df['species'][dicot_crop_mask]\n",
    "\n",
    "if len(y_dicot_crop) > 0:\n",
    "    clf_dicot_crop = RandomForestClassifier(random_state=42)\n",
    "    clf_dicot_crop.fit(X_dicot_crop, y_dicot_crop)\n",
    "else:\n",
    "    clf_dicot_crop = None\n",
    "    print(\"Skipping dicotâ†’crop model: no samples in that group.\")\n",
    "\n",
    "\n",
    "# instead of unconditionally fitting, do it in one line:\n",
    "clf_dicot_crop = RandomForestClassifier(random_state=42).fit(\n",
    "    X_dicot_crop, y_dicot_crop\n",
    ") if len(y_dicot_crop)>0 else None\n",
    "\n",
    "\n",
    "# Predict species level on the test set:\n",
    "# For each test sample, use the predicted category1 and category2 to decide which classifier to use at level 3.\n",
    "\n",
    "final_species_preds = []\n",
    "\n",
    "for idx in X_test_cat1.index:\n",
    "    cat1_pred = clf_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if cat1_pred == 'monocot':\n",
    "        cat2_pred = clf_cat2_monocot.predict(X_test_cat1.loc[[idx]])[0]  # use monocot model for cat2\n",
    "        if cat2_pred == 'weed':\n",
    "            sp_pred = clf_mono_weed.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        else:  # crop\n",
    "            sp_pred = clf_mono_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    else:  # dicot\n",
    "        cat2_pred = clf_cat2_dicot.predict(X_test_cat1.loc[[idx]])[0]  # use dicot model for cat2\n",
    "        if cat2_pred == 'weed':\n",
    "            sp_pred = clf_dicot_weed.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        else:  # crop\n",
    "            sp_pred = clf_dicot_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate accuracy of final species predictions:\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test_species,final_species_preds)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test_species)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test_species, final_species_preds)\n",
    "print(report)\n",
    "\n",
    "cm_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "031b62dc-3904-4e26-9dc8-06a2386a0b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping dicotâ†’crop model: no samples in that group.\n",
      "Final Species-Level Accuracy: 0.9186046511627907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.70      0.78      0.74         9\n",
      "      Barley       1.00      0.86      0.92         7\n",
      "       ECHCG       1.00      0.88      0.93         8\n",
      "         Oat       1.00      1.00      1.00        11\n",
      "       PAPRH       0.85      1.00      0.92        11\n",
      "       POLAV       1.00      0.88      0.93         8\n",
      "       Wheat       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.92        86\n",
      "   macro avg       0.93      0.90      0.91        86\n",
      "weighted avg       0.93      0.92      0.92        86\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVEFA</th>\n",
       "      <th>Barley</th>\n",
       "      <th>ECHCG</th>\n",
       "      <th>Oat</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>POLAV</th>\n",
       "      <th>Wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVEFA</th>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barley</th>\n",
       "      <td>14.285714</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHCG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLAV</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wheat</th>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AVEFA     Barley  ECHCG    Oat    PAPRH  POLAV      Wheat\n",
       "AVEFA   77.777778   0.000000    0.0    0.0    0.000    0.0  22.222222\n",
       "Barley  14.285714  85.714286    0.0    0.0    0.000    0.0   0.000000\n",
       "ECHCG    0.000000   0.000000   87.5    0.0   12.500    0.0   0.000000\n",
       "Oat      0.000000   0.000000    0.0  100.0    0.000    0.0   0.000000\n",
       "PAPRH    0.000000   0.000000    0.0    0.0  100.000    0.0   0.000000\n",
       "POLAV   12.500000   0.000000    0.0    0.0    0.000   87.5   0.000000\n",
       "Wheat    3.125000   0.000000    0.0    0.0    3.125    0.0  93.750000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example lists of species for each category\n",
    "monocot_species = [\"Barley\",\"Wheat\",\"Oat\",\"AVEFA\",\"ECHCG\"]  # example species\n",
    "dicot_species   = [\"PAPRH\",\"POLAV\"]\n",
    "weed_species    = [\"AVEFA\",\"PAPRH\",\"POLAV\",\"ECHCG\"]  # example of some species labeled as weeds\n",
    "crop_species    = [\"Barley\",\"Wheat\",\"Oat\"]\n",
    "\n",
    "# Third-level species groups (adjust these depending on your actual data):\n",
    "monocot_weed_species = [\"AVEFA\"]\n",
    "monocot_crop_species = [ \"Barley\",\"Wheat\",\"Oat\"]\n",
    "dicot_weed_species   = [\"PAPRH\",\"POLAV\"]\n",
    "\n",
    "# Assume df is your main dataframe with features and species\n",
    "# Example:\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# Create first-level category\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "# Create second-level category\n",
    "df['category2'] = df['species'].apply(lambda s: 'weed' if s in weed_species else 'crop')\n",
    "\n",
    "\n",
    "y_cat1 = df[\"category1\"]  # Level 1 target \n",
    "\n",
    "# Level 1: Monocot vs Dicot\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1)\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "y_pred_cat1 = clf_cat1.predict(X_test_cat1)\n",
    "\n",
    "# Split test data by predicted category1\n",
    "X_test_monocot = X_test_cat1[y_pred_cat1 == 'monocot']\n",
    "X_test_dicot   = X_test_cat1[y_pred_cat1 == 'dicot']\n",
    "\n",
    "y_test_monocot = df.loc[X_test_monocot.index, 'category2']\n",
    "y_test_dicot   = df.loc[X_test_dicot.index, 'category2']\n",
    "\n",
    "# â€” right after you train clf_cat1 (monocot/dicot) â€” \n",
    "\n",
    "# Train a global weed vs. crop classifier on the same split:\n",
    "# ----------------------------------------------------------\n",
    "y_cat2 = df.loc[X_train_cat1.index, 'category2']\n",
    "clf_cat2 = RandomForestClassifier(random_state=42)\n",
    "clf_cat2.fit(X_train_cat1, y_cat2)\n",
    "\n",
    "# Level 2: Weed vs Crop (for monocot)\n",
    "monocot_mask = df['category1'] == 'monocot'\n",
    "X_monocot = X[monocot_mask]\n",
    "y_monocot = df['category2'][monocot_mask]\n",
    "\n",
    "X_train_mono, X_val_mono, y_train_mono, y_val_mono = train_test_split(X_monocot, y_monocot, test_size=0.2, random_state=42, stratify=y_monocot)\n",
    "clf_cat2_monocot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_monocot.fit(X_train_mono, y_train_mono)\n",
    "\n",
    "y_pred_cat2_monocot = clf_cat2_monocot.predict(X_test_monocot)\n",
    "\n",
    "# Level 2: Weed vs Crop (for dicot)\n",
    "dicot_mask = df['category1'] == 'dicot'\n",
    "X_dicot = X[dicot_mask]\n",
    "y_dicot = df['category2'][dicot_mask]\n",
    "\n",
    "X_train_di, X_val_di, y_train_di, y_val_di = train_test_split(X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot)\n",
    "clf_cat2_dicot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_dicot.fit(X_train_di, y_train_di)\n",
    "\n",
    "y_pred_cat2_dicot = clf_cat2_dicot.predict(X_test_dicot)\n",
    "\n",
    "# Now we have predictions for category1 and category2. Next: species level.\n",
    "\n",
    "# For the third level, we train separate models for each final group:\n",
    "# Monocot-Weed, Monocot-Crop, Dicot-Weed, Dicot-Crop.\n",
    "\n",
    "# Example: Monocot-Weed model (if multiple species in that group)\n",
    "mono_weed_mask = (df['category1'] == 'monocot') & (df['category2'] == 'weed')\n",
    "X_mono_weed = X[mono_weed_mask]\n",
    "y_mono_weed = df['species'][mono_weed_mask]\n",
    "\n",
    "clf_mono_weed = RandomForestClassifier(random_state=42)\n",
    "clf_mono_weed.fit(X_mono_weed, y_mono_weed)\n",
    "\n",
    "# Monocot-Crop model\n",
    "mono_crop_mask = (df['category1'] == 'monocot') & (df['category2'] == 'crop')\n",
    "X_mono_crop = X[mono_crop_mask]\n",
    "y_mono_crop = df['species'][mono_crop_mask]\n",
    "\n",
    "clf_mono_crop = RandomForestClassifier(random_state=42)\n",
    "clf_mono_crop.fit(X_mono_crop, y_mono_crop)\n",
    "\n",
    "# Dicot-Weed model\n",
    "dicot_weed_mask = (df['category1'] == 'dicot') & (df['category2'] == 'weed')\n",
    "X_dicot_weed = X[dicot_weed_mask]\n",
    "y_dicot_weed = df['species'][dicot_weed_mask]\n",
    "\n",
    "clf_dicot_weed = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_weed.fit(X_dicot_weed, y_dicot_weed)\n",
    "\n",
    "# Dicot-Crop model\n",
    "# Dicotâ€‘Crop model\n",
    "dicot_crop_mask = (df['category1'] == 'dicot') & (df['category2'] == 'crop')\n",
    "X_dicot_crop = X[dicot_crop_mask]\n",
    "y_dicot_crop = df['species'][dicot_crop_mask]\n",
    "\n",
    "if len(y_dicot_crop) > 0:\n",
    "    clf_dicot_crop = RandomForestClassifier(random_state=42)\n",
    "    clf_dicot_crop.fit(X_dicot_crop, y_dicot_crop)\n",
    "else:\n",
    "    clf_dicot_crop = None\n",
    "    print(\"Skipping dicotâ†’crop model: no samples in that group.\")\n",
    "\n",
    "\n",
    "# instead of unconditionally fitting, do it in one line:\n",
    "clf_dicot_crop = RandomForestClassifier(random_state=42).fit(\n",
    "    X_dicot_crop, y_dicot_crop\n",
    ") if len(y_dicot_crop)>0 else None\n",
    "\n",
    "\n",
    "# Predict species level on the test set:\n",
    "# For each test sample, use the predicted category1 and category2 to decide which classifier to use at level 3.\n",
    "\n",
    "final_species_preds = []\n",
    "\n",
    "for idx in X_test_cat1.index:\n",
    "    x = X_test_cat1.loc[[idx]]\n",
    "\n",
    "    # 1) weed vs crop first\n",
    "    cat2_pred = clf_cat2.predict(x)[0]\n",
    "\n",
    "    # 2) monocot vs dicot next\n",
    "    cat1_pred = clf_cat1.predict(x)[0]\n",
    "\n",
    "    # 3) dispatch to the right speciesâ€model\n",
    "    if cat2_pred == 'weed':\n",
    "        if cat1_pred == 'monocot':\n",
    "            sp_pred = clf_mono_weed.predict(x)[0]\n",
    "        else:\n",
    "            sp_pred = clf_dicot_weed.predict(x)[0]\n",
    "    else:  # crop\n",
    "        if cat1_pred == 'monocot':\n",
    "            sp_pred = clf_mono_crop.predict(x)[0]\n",
    "        else:\n",
    "            sp_pred = clf_dicot_crop.predict(x)[0]\n",
    "\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate accuracy of final species predictions:\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test_species,final_species_preds)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test_species)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test_species, final_species_preds)\n",
    "print(report)\n",
    "\n",
    "cm_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6911a3b-6d23-4324-8ffd-c0a2629d9a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Species-Level Accuracy: 0.8372093023255814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.75      0.67      0.71         9\n",
      "      Barley       1.00      0.71      0.83         7\n",
      "       ECHCG       1.00      0.75      0.86         8\n",
      "         Oat       1.00      0.82      0.90        11\n",
      "       PAPRH       0.71      0.91      0.80        11\n",
      "       POLAV       0.83      0.62      0.71         8\n",
      "       Wheat       0.82      0.97      0.89        32\n",
      "\n",
      "    accuracy                           0.84        86\n",
      "   macro avg       0.87      0.78      0.81        86\n",
      "weighted avg       0.85      0.84      0.83        86\n",
      "\n",
      "            AVEFA     Barley  ECHCG        Oat      PAPRH      POLAV  \\\n",
      "AVEFA   66.666667   0.000000    0.0   0.000000   0.000000   0.000000   \n",
      "Barley   0.000000  71.428571    0.0   0.000000   0.000000   0.000000   \n",
      "ECHCG   12.500000   0.000000   75.0   0.000000  12.500000   0.000000   \n",
      "Oat      9.090909   0.000000    0.0  81.818182   0.000000   0.000000   \n",
      "PAPRH    0.000000   0.000000    0.0   0.000000  90.909091   9.090909   \n",
      "POLAV    0.000000   0.000000    0.0   0.000000  25.000000  62.500000   \n",
      "Wheat    0.000000   0.000000    0.0   0.000000   3.125000   0.000000   \n",
      "\n",
      "            Wheat  \n",
      "AVEFA   33.333333  \n",
      "Barley  28.571429  \n",
      "ECHCG    0.000000  \n",
      "Oat      9.090909  \n",
      "PAPRH    0.000000  \n",
      "POLAV   12.500000  \n",
      "Wheat   96.875000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVEFA</th>\n",
       "      <th>Barley</th>\n",
       "      <th>ECHCG</th>\n",
       "      <th>Oat</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>POLAV</th>\n",
       "      <th>Wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVEFA</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barley</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHCG</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oat</th>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLAV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wheat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AVEFA     Barley  ECHCG        Oat      PAPRH      POLAV  \\\n",
       "AVEFA   66.666667   0.000000    0.0   0.000000   0.000000   0.000000   \n",
       "Barley   0.000000  71.428571    0.0   0.000000   0.000000   0.000000   \n",
       "ECHCG   12.500000   0.000000   75.0   0.000000  12.500000   0.000000   \n",
       "Oat      9.090909   0.000000    0.0  81.818182   0.000000   0.000000   \n",
       "PAPRH    0.000000   0.000000    0.0   0.000000  90.909091   9.090909   \n",
       "POLAV    0.000000   0.000000    0.0   0.000000  25.000000  62.500000   \n",
       "Wheat    0.000000   0.000000    0.0   0.000000   3.125000   0.000000   \n",
       "\n",
       "            Wheat  \n",
       "AVEFA   33.333333  \n",
       "Barley  28.571429  \n",
       "ECHCG    0.000000  \n",
       "Oat      9.090909  \n",
       "PAPRH    0.000000  \n",
       "POLAV   12.500000  \n",
       "Wheat   96.875000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1) Define your highâ€level category\n",
    "monocot_species = [\"Barley\",\"Wheat\",\"Oat\",\"AVEFA\",\"ECHCG\"]  \n",
    "# everything else is dicot in your toy example\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "\n",
    "# 2) Pick only your numeric features automatically\n",
    "X = df.select_dtypes(include=[np.number])\n",
    "y_cat1 = df['category1']\n",
    "\n",
    "# 3) Split & train levelâ€‘1\n",
    "X1_tr, X1_te, y1_tr, y1_te = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X1_tr, y1_tr)\n",
    "\n",
    "# 4) Train one speciesâ€classifier per category1 (on your existing train split)\n",
    "mono_idx = X_train_cat1[y_train_cat1=='monocot'].index\n",
    "dicot_idx = X_train_cat1[y_train_cat1=='dicot'].index\n",
    "\n",
    "clf_mono_species = RandomForestClassifier(random_state=42)\n",
    "clf_mono_species.fit(\n",
    "    X_train_cat1.loc[mono_idx],\n",
    "    df.loc[mono_idx, 'species']\n",
    ")\n",
    "\n",
    "clf_dicot_species = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_species.fit(\n",
    "    X_train_cat1.loc[dicot_idx],\n",
    "    df.loc[dicot_idx, 'species']\n",
    ")\n",
    "\n",
    "# 5) Twoâ€stage prediction on X_test_cat1\n",
    "final_species_preds = []\n",
    "for idx in X_test_cat1.index:\n",
    "    cat1_pred = clf_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if cat1_pred == 'monocot':\n",
    "        sp_pred = clf_mono_species.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    else:  # dicot\n",
    "        sp_pred = clf_dicot_species.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "print(classification_report(y_test_species, final_species_preds))\n",
    "\n",
    "cm = confusion_matrix(y_test_species, final_species_preds)\n",
    "cm_percentage = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "class_labels = np.unique(y_test_species)\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "cm_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1eb121d-573a-4f85-8cbe-0cd68de57f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Species-Level Accuracy: 0.7674418604651163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.44      0.67      0.53         6\n",
      "      Barley       1.00      0.40      0.57        10\n",
      "       ECHCG       0.86      0.40      0.55        15\n",
      "         Oat       0.78      1.00      0.88         7\n",
      "       PAPRH       0.89      0.89      0.89         9\n",
      "       POLAV       0.73      1.00      0.84         8\n",
      "       Wheat       0.78      0.94      0.85        31\n",
      "\n",
      "    accuracy                           0.77        86\n",
      "   macro avg       0.78      0.76      0.73        86\n",
      "weighted avg       0.80      0.77      0.75        86\n",
      "\n",
      "            AVEFA  Barley      ECHCG         Oat      PAPRH  POLAV      Wheat\n",
      "AVEFA   66.666667     0.0   0.000000    0.000000   0.000000    0.0  33.333333\n",
      "Barley   0.000000    40.0   0.000000   10.000000   0.000000    0.0  50.000000\n",
      "ECHCG   33.333333     0.0  40.000000    0.000000   6.666667   20.0   0.000000\n",
      "Oat      0.000000     0.0   0.000000  100.000000   0.000000    0.0   0.000000\n",
      "PAPRH    0.000000     0.0   0.000000    0.000000  88.888889    0.0  11.111111\n",
      "POLAV    0.000000     0.0   0.000000    0.000000   0.000000  100.0   0.000000\n",
      "Wheat    0.000000     0.0   3.225806    3.225806   0.000000    0.0  93.548387\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# 1) Define your high-level category: weed vs crop\n",
    "weed_species = [\"AVEFA\", \"PAPRH\", \"POLAV\", \"ECHCG\"]  # adjust to your actual weed list\n",
    "# everything else is crop\n",
    "df['category1'] = df['species'].apply(lambda s: 'weed' if s in weed_species else 'crop')\n",
    "\n",
    "# 2) Pick only your numeric features\n",
    "X = df.select_dtypes(include=[np.number])\n",
    "y_cat1 = df['category1']\n",
    "\n",
    "# 3) Split & train level-1 (weed vs crop)\n",
    "X1_tr, X1_te, y1_tr, y1_te = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X1_tr, y1_tr)\n",
    "\n",
    "# 4) Train one speciesâ€classifier per category1 on the train split\n",
    "weed_idx = y1_tr[y1_tr == 'weed'].index\n",
    "crop_idx = y1_tr[y1_tr == 'crop'].index\n",
    "\n",
    "clf_weed_species = RandomForestClassifier(random_state=42)\n",
    "clf_weed_species.fit(\n",
    "    X1_tr.loc[weed_idx],\n",
    "    df.loc[weed_idx, 'species']\n",
    ")\n",
    "\n",
    "clf_crop_species = RandomForestClassifier(random_state=42)\n",
    "clf_crop_species.fit(\n",
    "    X1_tr.loc[crop_idx],\n",
    "    df.loc[crop_idx, 'species']\n",
    ")\n",
    "\n",
    "# 5) Twoâ€stage prediction on X1_te\n",
    "final_species_preds = []\n",
    "for idx in X1_te.index:\n",
    "    # predict weed vs crop\n",
    "    cat1_pred = clf_cat1.predict(X1_te.loc[[idx]])[0]\n",
    "    # then species within that subset\n",
    "    if cat1_pred == 'weed':\n",
    "        sp_pred = clf_weed_species.predict(X1_te.loc[[idx]])[0]\n",
    "    else:  # crop\n",
    "        sp_pred = clf_crop_species.predict(X1_te.loc[[idx]])[0]\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X1_te.index, 'species']\n",
    "\n",
    "# Evaluate\n",
    "print(\"Final Species-Level Accuracy:\", accuracy_score(y_test_species, final_species_preds))\n",
    "print(classification_report(y_test_species, final_species_preds))\n",
    "\n",
    "# Confusion matrix (percent)\n",
    "cm = confusion_matrix(y_test_species, final_species_preds)\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "labels = np.unique(y_test_species)\n",
    "cm_df = pd.DataFrame(cm_pct, index=labels, columns=labels)\n",
    "print(cm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b5dd92e-a222-4633-92a5-178ce7a8661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7906976744186046\n",
      "            AVEFA     Barley  ECHCG        Oat  PAPRH      POLAV      Wheat\n",
      "AVEFA   77.777778   0.000000    0.0   0.000000    0.0   0.000000  22.222222\n",
      "Barley  10.000000  60.000000    0.0  10.000000    0.0   0.000000  20.000000\n",
      "ECHCG   10.000000   0.000000   90.0   0.000000    0.0   0.000000   0.000000\n",
      "Oat      0.000000  11.111111    0.0  55.555556    0.0   0.000000  33.333333\n",
      "PAPRH   10.000000   0.000000    0.0   0.000000   90.0   0.000000   0.000000\n",
      "POLAV    0.000000  11.111111    0.0   0.000000    0.0  88.888889   0.000000\n",
      "Wheat    3.448276  10.344828    0.0   3.448276    0.0   0.000000  82.758621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.64      0.78      0.70         9\n",
      "      Barley       0.55      0.60      0.57        10\n",
      "       ECHCG       1.00      0.90      0.95        10\n",
      "         Oat       0.71      0.56      0.62         9\n",
      "       PAPRH       1.00      0.90      0.95        10\n",
      "       POLAV       1.00      0.89      0.94         9\n",
      "       Wheat       0.77      0.83      0.80        29\n",
      "\n",
      "    accuracy                           0.79        86\n",
      "   macro avg       0.81      0.78      0.79        86\n",
      "weighted avg       0.80      0.79      0.79        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepare data\n",
    "\n",
    "y = df[\"species\"]\n",
    "\n",
    "# 2) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3) Build a pipeline: scaling + KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\",    KNeighborsClassifier(n_neighbors=5))  # you can tune n_neighbors\n",
    "])\n",
    "\n",
    "# 4) Train\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate accuracy\n",
    "accuracy = knn_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 6) Confusion matrix\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 7) Confusion matrix as percentages\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "class_labels = np.unique(y_test)\n",
    "cm_df = pd.DataFrame(cm_pct, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "# 8) Classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d5293d9-49ba-4f32-bac0-a307ddd72ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN final accuracy: 0.8023255813953488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.64      0.78      0.70         9\n",
      "      Barley       0.67      0.86      0.75         7\n",
      "       ECHCG       1.00      0.75      0.86         8\n",
      "         Oat       1.00      0.55      0.71        11\n",
      "       PAPRH       0.85      1.00      0.92        11\n",
      "       POLAV       0.71      0.62      0.67         8\n",
      "       Wheat       0.82      0.88      0.85        32\n",
      "\n",
      "    accuracy                           0.80        86\n",
      "   macro avg       0.81      0.78      0.78        86\n",
      "weighted avg       0.82      0.80      0.80        86\n",
      "\n",
      "            AVEFA     Barley  ECHCG        Oat    PAPRH   POLAV      Wheat\n",
      "AVEFA   77.777778   0.000000    0.0   0.000000    0.000   0.000  22.222222\n",
      "Barley  14.285714  85.714286    0.0   0.000000    0.000   0.000   0.000000\n",
      "ECHCG   12.500000   0.000000   75.0   0.000000    0.000  12.500   0.000000\n",
      "Oat      9.090909   0.000000    0.0  54.545455    0.000   0.000  36.363636\n",
      "PAPRH    0.000000   0.000000    0.0   0.000000  100.000   0.000   0.000000\n",
      "POLAV   12.500000  12.500000    0.0   0.000000   12.500  62.500   0.000000\n",
      "Wheat    0.000000   6.250000    0.0   0.000000    3.125   3.125  87.500000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1) First split & train Levelâ€‰1 (Monocot vs Dicot) with KNN\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "knn_cat1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "# 2) Train Levelâ€‰2 KNNs\n",
    "knn_cat2_monocot = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat2_monocot.fit(X_monocot, y_monocot)\n",
    "\n",
    "knn_cat2_dicot = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat2_dicot.fit(X_dicot, y_dicot)\n",
    "\n",
    "# 3) Train Levelâ€‰3 speciesâ€‘models\n",
    "knn_mono_weed = KNeighborsClassifier(n_neighbors=5).fit(X_mono_weed, y_mono_weed)\n",
    "knn_mono_crop = (KNeighborsClassifier(n_neighbors=5).fit(X_mono_crop, y_mono_crop)\n",
    "                 if len(y_mono_crop)>0 else None)\n",
    "knn_dicot_weed = KNeighborsClassifier(n_neighbors=5).fit(X_dicot_weed, y_dicot_weed)\n",
    "knn_dicot_crop = (KNeighborsClassifier(n_neighbors=5).fit(X_dicot_crop, y_dicot_crop)\n",
    "                  if len(y_dicot_crop)>0 else None)\n",
    "\n",
    "# 4) Threeâ€‘stage prediction loop\n",
    "final_preds_knn = []\n",
    "for idx in X_test_cat1.index:\n",
    "    c1 = knn_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if c1=='monocot':\n",
    "        c2 = knn_cat2_monocot.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        if c2=='weed':\n",
    "            final_preds_knn.append(knn_mono_weed.predict(X_test_cat1.loc[[idx]])[0])\n",
    "        else:\n",
    "            final_preds_knn.append(\n",
    "                knn_mono_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "                if knn_mono_crop else \"unknown\"\n",
    "            )\n",
    "    else:\n",
    "        c2 = knn_cat2_dicot.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        if c2=='weed':\n",
    "            final_preds_knn.append(knn_dicot_weed.predict(X_test_cat1.loc[[idx]])[0])\n",
    "        else:\n",
    "            final_preds_knn.append(\n",
    "                knn_dicot_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "                if knn_dicot_crop else \"unknown\"\n",
    "            )\n",
    "\n",
    "# 5) Evaluate\n",
    "print(\"KNN final accuracy:\", accuracy_score(y_test_species, final_preds_knn))\n",
    "print(classification_report(y_test_species, final_preds_knn))\n",
    "\n",
    "cm_knn = confusion_matrix(y_test_species, final_preds_knn)\n",
    "cm_pct_knn = cm_knn.astype(float)/cm_knn.sum(axis=1)[:,None]*100\n",
    "cm_knn_df = pd.DataFrame(cm_pct_knn, index=np.unique(y_test_species), columns=np.unique(y_test_species))\n",
    "print(cm_knn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "455b8626-2d6d-49ee-aece-111d0a25f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.813953488372093\n",
      "            AVEFA  Barley  ECHCG        Oat  PAPRH  POLAV      Wheat\n",
      "AVEFA   44.444444     0.0    0.0   0.000000    0.0    0.0  55.555556\n",
      "Barley   0.000000    40.0    0.0   0.000000    0.0    0.0  60.000000\n",
      "ECHCG    0.000000     0.0  100.0   0.000000    0.0    0.0   0.000000\n",
      "Oat      0.000000     0.0    0.0  66.666667    0.0    0.0  33.333333\n",
      "PAPRH    0.000000     0.0    0.0   0.000000   90.0    0.0  10.000000\n",
      "POLAV    0.000000     0.0    0.0   0.000000    0.0  100.0   0.000000\n",
      "Wheat    3.448276     0.0    0.0   0.000000    0.0    0.0  96.551724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.80      0.44      0.57         9\n",
      "      Barley       1.00      0.40      0.57        10\n",
      "       ECHCG       1.00      1.00      1.00        10\n",
      "         Oat       1.00      0.67      0.80         9\n",
      "       PAPRH       1.00      0.90      0.95        10\n",
      "       POLAV       1.00      1.00      1.00         9\n",
      "       Wheat       0.65      0.97      0.78        29\n",
      "\n",
      "    accuracy                           0.81        86\n",
      "   macro avg       0.92      0.77      0.81        86\n",
      "weighted avg       0.86      0.81      0.80        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepare data\n",
    "\n",
    "y = df[\"species\"]\n",
    "\n",
    "# 2) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3) Build a pipeline: scaling + SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(\n",
    "        kernel=\"rbf\",       # try \"linear\" if you want coefficients\n",
    "        C=1.0,              # regularization parameter\n",
    "        probability=False,  # set True if you need predict_proba\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4) Train\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate accuracy\n",
    "accuracy = svm_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 6) Confusion matrix\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 7) Confusion matrix as percentages\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "class_labels = np.unique(y_test)\n",
    "cm_df = pd.DataFrame(cm_pct, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "# 8) Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 9) (Optional) Feature â€œimportanceâ€ for a linear SVM:\n",
    "# If you switch to kernel=\"linear\", you can inspect svm_pipeline.named_steps['svc'].coef_\n",
    "# to see per-class feature weights:\n",
    "#\n",
    "# linear_svc = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"svc\",    SVC(kernel=\"linear\", C=1.0, random_state=42))\n",
    "# ])\n",
    "# linear_svc.fit(X_train, y_train)\n",
    "# coefs = linear_svc.named_steps['svc'].coef_\n",
    "# feature_names = X.columns\n",
    "# # coefs is shape (n_classes, n_features) for multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9092ce0-36fc-42fb-a4b0-cf84996b0711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Levelâ€‘2 dicot model: only one class present: ['weed']\n",
      "Accuracy: 0.8837209302325582\n",
      "            AVEFA     Barley  ECHCG        Oat    PAPRH  POLAV      Wheat\n",
      "AVEFA   77.777778   0.000000    0.0   0.000000    0.000    0.0  22.222222\n",
      "Barley   0.000000  71.428571    0.0   0.000000    0.000    0.0  28.571429\n",
      "ECHCG   12.500000   0.000000   87.5   0.000000    0.000    0.0   0.000000\n",
      "Oat      0.000000   0.000000    0.0  90.909091    0.000    0.0   9.090909\n",
      "PAPRH    0.000000   0.000000    0.0   0.000000  100.000    0.0   0.000000\n",
      "POLAV    0.000000   0.000000    0.0   0.000000   25.000   62.5  12.500000\n",
      "Wheat    0.000000   0.000000    0.0   0.000000    3.125    0.0  96.875000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.88      0.78      0.82         9\n",
      "      Barley       1.00      0.71      0.83         7\n",
      "       ECHCG       1.00      0.88      0.93         8\n",
      "         Oat       1.00      0.91      0.95        11\n",
      "       PAPRH       0.79      1.00      0.88        11\n",
      "       POLAV       1.00      0.62      0.77         8\n",
      "       Wheat       0.84      0.97      0.90        32\n",
      "\n",
      "    accuracy                           0.88        86\n",
      "   macro avg       0.93      0.84      0.87        86\n",
      "weighted avg       0.90      0.88      0.88        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# --- 1) Define your species groups ---\n",
    "monocot_species     = [\"Barley\", \"Wheat\", \"Oat\", \"AVEFA\",\"ECHCG\"]\n",
    "dicot_species       = [\"PAPRH\", \"POLAV\"]\n",
    "weed_species        = [\"AVEFA\", \"PAPRH\", \"POLAV\",\"ECHCG\"]\n",
    "crop_species        = [\"Barley\", \"Wheat\", \"Oat\"]\n",
    "\n",
    "# --- 2) Prepare your DataFrame ---\n",
    "# assume df is already loaded, with numeric features + a \"species\" column\n",
    "X = df.select_dtypes(include=[np.number])\n",
    "df[\"species\"] = df[\"species\"].astype(str)  # ensure no weird types\n",
    "\n",
    "# create hierarchical labels\n",
    "df[\"category1\"] = df[\"species\"].map(lambda s: \"monocot\" if s in monocot_species else \"dicot\")\n",
    "df[\"category2\"] = df[\"species\"].map(lambda s: \"weed\"    if s in weed_species    else \"crop\")\n",
    "\n",
    "# --- 3) Levelâ€‘1: monocot vs dicot ---\n",
    "X_train_l1, X_test_l1, y_train_l1, y_test_l1 = train_test_split(\n",
    "    X, df[\"category1\"], test_size=0.2, random_state=42, stratify=df[\"category1\"]\n",
    ")\n",
    "clf_l1 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_l1.fit(X_train_l1, y_train_l1)\n",
    "y_pred_l1 = clf_l1.predict(X_test_l1)\n",
    "\n",
    "# split test by predicted levelâ€‘1\n",
    "X_test_mono = X_test_l1[y_pred_l1 == \"monocot\"]\n",
    "X_test_dico = X_test_l1[y_pred_l1 == \"dicot\"]\n",
    "\n",
    "# --- 4) Levelâ€‘2 for monocot ---\n",
    "mono_mask = df[\"category1\"] == \"monocot\"\n",
    "X_mono    = X[mono_mask]\n",
    "y_mono    = df.loc[mono_mask, \"category2\"]\n",
    "X_tr_mono, X_val_mono, y_tr_mono, y_val_mono = train_test_split(\n",
    "    X_mono, y_mono, test_size=0.2, random_state=42, stratify=y_mono\n",
    ")\n",
    "clf_l2_mono = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_l2_mono.fit(X_tr_mono, y_tr_mono)\n",
    "\n",
    "# --- 5) Levelâ€‘2 for dicot (guarded) ---\n",
    "dicot_mask = df[\"category1\"] == \"dicot\"\n",
    "X_dicot    = X[dicot_mask]\n",
    "y_dicot    = df.loc[dicot_mask, \"category2\"]\n",
    "\n",
    "if len(y_dicot.unique()) > 1:\n",
    "    X_tr_dico, X_val_dico, y_tr_dico, y_val_dico = train_test_split(\n",
    "        X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot\n",
    "    )\n",
    "    clf_l2_dico = RandomForestClassifier(random_state=42)\n",
    "    clf_l2_dico.fit(X_tr_dico, y_tr_dico)\n",
    "else:\n",
    "    clf_l2_dico = None\n",
    "    print(\"Skipping Levelâ€‘2 dicot model: only one class present:\", y_dicot.unique())\n",
    "\n",
    "# --- 6) Levelâ€‘3 species models (each guarded if needed) ---\n",
    "# Monocotâ€‘Weed\n",
    "mask = (df[\"category1\"]==\"monocot\") & (df[\"category2\"]==\"weed\")\n",
    "clf_mono_weed = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_mono_weed.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# Monocotâ€‘Crop\n",
    "mask = (df[\"category1\"]==\"monocot\") & (df[\"category2\"]==\"crop\")\n",
    "clf_mono_crop = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_mono_crop.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# Dicotâ€‘Weed\n",
    "mask = (df[\"category1\"]==\"dicot\") & (df[\"category2\"]==\"weed\")\n",
    "clf_dico_weed = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_dico_weed.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# Dicotâ€‘Crop\n",
    "mask = (df[\"category1\"]==\"dicot\") & (df[\"category2\"]==\"crop\")\n",
    "if mask.sum() > 0:\n",
    "    clf_dico_crop = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "    ])\n",
    "    clf_dico_crop.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "else:\n",
    "    clf_dico_crop = None\n",
    "\n",
    "# --- 7) Final speciesâ€‘level prediction (with guard) ---\n",
    "final_preds = []\n",
    "for idx in X_test_l1.index:\n",
    "    cat1 = clf_l1.predict(X_test_l1.loc[[idx]])[0]\n",
    "\n",
    "    if cat1 == \"monocot\":\n",
    "        cat2 = clf_l2_mono.predict(X_test_l1.loc[[idx]])[0]\n",
    "        sp   = (clf_mono_weed if cat2==\"weed\" else clf_mono_crop).predict(X_test_l1.loc[[idx]])[0]\n",
    "\n",
    "    else:  # dicot\n",
    "        if clf_l2_dico is not None:\n",
    "            cat2 = clf_l2_dico.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            # only one possible dicot class\n",
    "            cat2 = y_dicot.unique()[0]\n",
    "\n",
    "        sp = (clf_dico_weed if cat2==\"weed\" else clf_dico_crop).predict(X_test_l1.loc[[idx]])[0]\n",
    "\n",
    "    final_preds.append(sp)\n",
    "\n",
    "final_preds = np.array(final_preds)\n",
    "y_true = df.loc[X_test_l1.index, \"species\"]\n",
    "\n",
    "# --- 8) Evaluate ---\n",
    "print(\"Accuracy:\", accuracy_score(y_true, final_preds))\n",
    "cm      = confusion_matrix(y_true, final_preds)\n",
    "cm_pct  = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "print(pd.DataFrame(cm_pct, index=np.unique(y_true), columns=np.unique(y_true)))\n",
    "print(classification_report(y_true, final_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
