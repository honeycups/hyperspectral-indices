{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864b57f9-1f2d-4ccc-b126-4285f78e6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Indices weed-crop.xlsx\", sheet_name=\"PCA-T\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70be28f3-b7da-4851-9ddb-16b9822e31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 427 entries, 0 to 426\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   species  427 non-null    object \n",
      " 1   PSSRa    427 non-null    float64\n",
      " 2   PSSRb    427 non-null    float64\n",
      " 3   RARSc    427 non-null    float64\n",
      " 4   PSSRc    427 non-null    float64\n",
      " 5   CARI     427 non-null    float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 20.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSSRa</th>\n",
       "      <th>PSSRb</th>\n",
       "      <th>RARSc</th>\n",
       "      <th>PSSRc</th>\n",
       "      <th>CARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.304836</td>\n",
       "      <td>5.481765</td>\n",
       "      <td>5.095169</td>\n",
       "      <td>5.107747</td>\n",
       "      <td>1.483079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.556932</td>\n",
       "      <td>1.269091</td>\n",
       "      <td>1.093370</td>\n",
       "      <td>1.106283</td>\n",
       "      <td>0.368094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.244437</td>\n",
       "      <td>2.828939</td>\n",
       "      <td>2.486733</td>\n",
       "      <td>2.472114</td>\n",
       "      <td>0.508824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.229335</td>\n",
       "      <td>4.574821</td>\n",
       "      <td>4.337286</td>\n",
       "      <td>4.345457</td>\n",
       "      <td>1.246511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.995831</td>\n",
       "      <td>5.265335</td>\n",
       "      <td>4.926355</td>\n",
       "      <td>4.949786</td>\n",
       "      <td>1.457512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.043973</td>\n",
       "      <td>6.168050</td>\n",
       "      <td>5.718132</td>\n",
       "      <td>5.752167</td>\n",
       "      <td>1.683727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.239014</td>\n",
       "      <td>10.427906</td>\n",
       "      <td>9.524077</td>\n",
       "      <td>9.581117</td>\n",
       "      <td>2.758396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PSSRa       PSSRb       RARSc       PSSRc        CARI\n",
       "count  427.000000  427.000000  427.000000  427.000000  427.000000\n",
       "mean     6.304836    5.481765    5.095169    5.107747    1.483079\n",
       "std      1.556932    1.269091    1.093370    1.106283    0.368094\n",
       "min      3.244437    2.828939    2.486733    2.472114    0.508824\n",
       "25%      5.229335    4.574821    4.337286    4.345457    1.246511\n",
       "50%      5.995831    5.265335    4.926355    4.949786    1.457512\n",
       "75%      7.043973    6.168050    5.718132    5.752167    1.683727\n",
       "max     12.239014   10.427906    9.524077    9.581117    2.758396"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()       # Shows the first five rows\n",
    "df.info()       # Gives an overview of columns, data types, and non-null counts\n",
    "df.describe()   # Provides summary statistics for numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b07fbca-40f0-48f4-997d-599221148bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5930232558139535\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.86      0.67      0.75         9\n",
      "      Barley       0.15      0.20      0.17        10\n",
      "       ECHCG       0.50      0.50      0.50        10\n",
      "         Oat       0.50      0.22      0.31         9\n",
      "       PAPRH       0.82      0.90      0.86        10\n",
      "       POLAV       0.50      0.33      0.40         9\n",
      "       Wheat       0.69      0.83      0.75        29\n",
      "\n",
      "    accuracy                           0.59        86\n",
      "   macro avg       0.57      0.52      0.53        86\n",
      "weighted avg       0.60      0.59      0.58        86\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVEFA</th>\n",
       "      <th>Barley</th>\n",
       "      <th>ECHCG</th>\n",
       "      <th>Oat</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>POLAV</th>\n",
       "      <th>Wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVEFA</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barley</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHCG</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLAV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wheat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>82.758621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AVEFA     Barley      ECHCG        Oat      PAPRH      POLAV  \\\n",
       "AVEFA   66.666667  11.111111  11.111111   0.000000   0.000000   0.000000   \n",
       "Barley   0.000000  20.000000  10.000000  10.000000   0.000000  10.000000   \n",
       "ECHCG   10.000000  10.000000  50.000000   0.000000   0.000000  10.000000   \n",
       "Oat      0.000000  55.555556  11.111111  22.222222   0.000000   0.000000   \n",
       "PAPRH    0.000000   0.000000   0.000000   0.000000  90.000000   0.000000   \n",
       "POLAV    0.000000  11.111111  22.222222   0.000000  22.222222  33.333333   \n",
       "Wheat    0.000000  10.344828   0.000000   3.448276   0.000000   3.448276   \n",
       "\n",
       "            Wheat  \n",
       "AVEFA   11.111111  \n",
       "Barley  50.000000  \n",
       "ECHCG   20.000000  \n",
       "Oat     11.111111  \n",
       "PAPRH   10.000000  \n",
       "POLAV   11.111111  \n",
       "Wheat   82.758621  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'target' is the name of your target column:\n",
    "X = df.drop(\"species\", axis=1)  # Features\n",
    "y = df[\"species\"]               # Target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and train the random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Variable Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances from Random Forest')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()\n",
    "\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53f3eae-6d5e-4d1b-a9b9-081aacfe09e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Species-Level Accuracy: 0.6744186046511628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.75      0.67      0.71         9\n",
      "      Barley       0.40      0.29      0.33         7\n",
      "       ECHCG       0.60      0.75      0.67         8\n",
      "         Oat       0.57      0.36      0.44        11\n",
      "       PAPRH       0.71      0.91      0.80        11\n",
      "       POLAV       0.75      0.38      0.50         8\n",
      "       Wheat       0.71      0.84      0.77        32\n",
      "\n",
      "    accuracy                           0.67        86\n",
      "   macro avg       0.64      0.60      0.60        86\n",
      "weighted avg       0.67      0.67      0.66        86\n",
      "\n",
      "            AVEFA     Barley      ECHCG        Oat      PAPRH   POLAV  \\\n",
      "AVEFA   66.666667   0.000000  11.111111   0.000000   0.000000   0.000   \n",
      "Barley  14.285714  28.571429   0.000000  14.285714   0.000000   0.000   \n",
      "ECHCG   12.500000  12.500000  75.000000   0.000000   0.000000   0.000   \n",
      "Oat      0.000000   9.090909   9.090909  36.363636   0.000000   0.000   \n",
      "PAPRH    0.000000   0.000000   0.000000   9.090909  90.909091   0.000   \n",
      "POLAV    0.000000  12.500000  12.500000   0.000000  25.000000  37.500   \n",
      "Wheat    0.000000   0.000000   3.125000   3.125000   6.250000   3.125   \n",
      "\n",
      "            Wheat  \n",
      "AVEFA   22.222222  \n",
      "Barley  42.857143  \n",
      "ECHCG    0.000000  \n",
      "Oat     45.454545  \n",
      "PAPRH    0.000000  \n",
      "POLAV   12.500000  \n",
      "Wheat   84.375000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVEFA</th>\n",
       "      <th>Barley</th>\n",
       "      <th>ECHCG</th>\n",
       "      <th>Oat</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>POLAV</th>\n",
       "      <th>Wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVEFA</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barley</th>\n",
       "      <td>14.285714</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHCG</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLAV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>37.500</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wheat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.125</td>\n",
       "      <td>84.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AVEFA     Barley      ECHCG        Oat      PAPRH   POLAV  \\\n",
       "AVEFA   66.666667   0.000000  11.111111   0.000000   0.000000   0.000   \n",
       "Barley  14.285714  28.571429   0.000000  14.285714   0.000000   0.000   \n",
       "ECHCG   12.500000  12.500000  75.000000   0.000000   0.000000   0.000   \n",
       "Oat      0.000000   9.090909   9.090909  36.363636   0.000000   0.000   \n",
       "PAPRH    0.000000   0.000000   0.000000   9.090909  90.909091   0.000   \n",
       "POLAV    0.000000  12.500000  12.500000   0.000000  25.000000  37.500   \n",
       "Wheat    0.000000   0.000000   3.125000   3.125000   6.250000   3.125   \n",
       "\n",
       "            Wheat  \n",
       "AVEFA   22.222222  \n",
       "Barley  42.857143  \n",
       "ECHCG    0.000000  \n",
       "Oat     45.454545  \n",
       "PAPRH    0.000000  \n",
       "POLAV   12.500000  \n",
       "Wheat   84.375000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1) Define your high‐level category\n",
    "monocot_species = [\"Barley\",\"Wheat\",\"Oat\",\"AVEFA\",\"ECHCG\"]  \n",
    "# everything else is dicot in your toy example\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "\n",
    "# 2) Pick only your numeric features automatically\n",
    "X = df[[\"PSSRa\",\"PSSRb\",\"PSSRc\",\"RARSc\",\"CARI\"]]  # Features\n",
    "y_cat1 = df['category1']\n",
    "\n",
    "# 3) Split & train level‑1\n",
    "X1_tr, X1_te, y1_tr, y1_te = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X1_tr, y1_tr)\n",
    "\n",
    "# 4) Train one species‐classifier per category1 (on your existing train split)\n",
    "mono_idx = X_train_cat1[y_train_cat1=='monocot'].index\n",
    "dicot_idx = X_train_cat1[y_train_cat1=='dicot'].index\n",
    "\n",
    "clf_mono_species = RandomForestClassifier(random_state=42)\n",
    "clf_mono_species.fit(\n",
    "    X_train_cat1.loc[mono_idx],\n",
    "    df.loc[mono_idx, 'species']\n",
    ")\n",
    "\n",
    "clf_dicot_species = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_species.fit(\n",
    "    X_train_cat1.loc[dicot_idx],\n",
    "    df.loc[dicot_idx, 'species']\n",
    ")\n",
    "\n",
    "# 5) Two‐stage prediction on X_test_cat1\n",
    "final_species_preds = []\n",
    "for idx in X_test_cat1.index:\n",
    "    cat1_pred = clf_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if cat1_pred == 'monocot':\n",
    "        sp_pred = clf_mono_species.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    else:  # dicot\n",
    "        sp_pred = clf_dicot_species.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "print(classification_report(y_test_species, final_species_preds))\n",
    "\n",
    "cm = confusion_matrix(y_test_species, final_species_preds)\n",
    "cm_percentage = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "class_labels = np.unique(y_test_species)\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "cm_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ea9118-8256-40ff-a898-3f54e18770ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Species-Level Accuracy: 0.9069767441860465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       1.00      0.89      0.94         9\n",
      "      Barley       0.88      1.00      0.93         7\n",
      "       ECHCG       0.89      1.00      0.94         8\n",
      "         Oat       0.92      1.00      0.96        11\n",
      "       PAPRH       0.83      0.91      0.87        11\n",
      "       POLAV       0.83      0.62      0.71         8\n",
      "       Wheat       0.94      0.91      0.92        32\n",
      "\n",
      "    accuracy                           0.91        86\n",
      "   macro avg       0.90      0.90      0.90        86\n",
      "weighted avg       0.91      0.91      0.90        86\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVEFA</th>\n",
       "      <th>Barley</th>\n",
       "      <th>ECHCG</th>\n",
       "      <th>Oat</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>POLAV</th>\n",
       "      <th>Wheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVEFA</th>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barley</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECHCG</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POLAV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.500</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wheat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.125</td>\n",
       "      <td>90.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AVEFA  Barley  ECHCG         Oat      PAPRH   POLAV      Wheat\n",
       "AVEFA   88.888889     0.0    0.0    0.000000   0.000000   0.000  11.111111\n",
       "Barley   0.000000   100.0    0.0    0.000000   0.000000   0.000   0.000000\n",
       "ECHCG    0.000000     0.0  100.0    0.000000   0.000000   0.000   0.000000\n",
       "Oat      0.000000     0.0    0.0  100.000000   0.000000   0.000   0.000000\n",
       "PAPRH    0.000000     0.0    0.0    9.090909  90.909091   0.000   0.000000\n",
       "POLAV    0.000000    12.5   12.5    0.000000   0.000000  62.500  12.500000\n",
       "Wheat    0.000000     0.0    0.0    0.000000   6.250000   3.125  90.625000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example lists of species for each category\n",
    "monocot_species = [\"Barley\",\"Wheat\",\"Oat\",\"AVEFA\",\"ECHCG\"]  # example species\n",
    "dicot_species   = [\"PAPRO\",\"POLAV\"]\n",
    "weed_species    = [\"AVEFA\",\"PAPRO\",\"POLAV\",\"ECHCG\"]  # example of some species labeled as weeds\n",
    "crop_species    = [\"Barley\",\"Wheat\",\"Oat\"]\n",
    "\n",
    "# Third-level species groups (adjust these depending on your actual data):\n",
    "monocot_weed_species = [\"AVEFA\",\"ECHCG\"]\n",
    "monocot_crop_species = [ \"Barley\",\"Wheat\",\"Oat\"]\n",
    "dicot_weed_species   = [\"PAPRO\",\"POLAV\"]\n",
    "\n",
    "# Assume df is your main dataframe with features and species\n",
    "# Example:\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df[[\"PSSRa\",\"PSSRb\",\"PSSRc\",\"RARSc\",\"CARI\"]]  # Features\n",
    "\n",
    "\n",
    "# Create first-level category\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "# Create second-level category\n",
    "df['category2'] = df['species'].apply(lambda s: 'weed' if s in weed_species else 'crop')\n",
    "\n",
    "\n",
    "y_cat1 = df[\"category1\"]  # Level 1 target \n",
    "\n",
    "# Level 1: Monocot vs Dicot\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1)\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "y_pred_cat1 = clf_cat1.predict(X_test_cat1)\n",
    "\n",
    "# Split test data by predicted category1\n",
    "X_test_monocot = X_test_cat1[y_pred_cat1 == 'monocot']\n",
    "X_test_dicot   = X_test_cat1[y_pred_cat1 == 'dicot']\n",
    "\n",
    "y_test_monocot = df.loc[X_test_monocot.index, 'category2']\n",
    "y_test_dicot   = df.loc[X_test_dicot.index, 'category2']\n",
    "\n",
    "# Level 2: Weed vs Crop (for monocot)\n",
    "monocot_mask = df['category1'] == 'monocot'\n",
    "X_monocot = X[monocot_mask]\n",
    "y_monocot = df['category2'][monocot_mask]\n",
    "\n",
    "X_train_mono, X_val_mono, y_train_mono, y_val_mono = train_test_split(X_monocot, y_monocot, test_size=0.2, random_state=42, stratify=y_monocot)\n",
    "clf_cat2_monocot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_monocot.fit(X_train_mono, y_train_mono)\n",
    "\n",
    "y_pred_cat2_monocot = clf_cat2_monocot.predict(X_test_monocot)\n",
    "\n",
    "# Level 2: Weed vs Crop (for dicot)\n",
    "dicot_mask = df['category1'] == 'dicot'\n",
    "X_dicot = X[dicot_mask]\n",
    "y_dicot = df['category2'][dicot_mask]\n",
    "\n",
    "X_train_di, X_val_di, y_train_di, y_val_di = train_test_split(X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot)\n",
    "clf_cat2_dicot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_dicot.fit(X_train_di, y_train_di)\n",
    "\n",
    "y_pred_cat2_dicot = clf_cat2_dicot.predict(X_test_dicot)\n",
    "\n",
    "# Now we have predictions for category1 and category2. Next: species level.\n",
    "\n",
    "# For the third level, we train separate models for each final group:\n",
    "# Monocot-Weed, Monocot-Crop, Dicot-Weed, Dicot-Crop.\n",
    "\n",
    "# Example: Monocot-Weed model (if multiple species in that group)\n",
    "mono_weed_mask = (df['category1'] == 'monocot') & (df['category2'] == 'weed')\n",
    "X_mono_weed = X[mono_weed_mask]\n",
    "y_mono_weed = df['species'][mono_weed_mask]\n",
    "\n",
    "clf_mono_weed = RandomForestClassifier(random_state=42)\n",
    "clf_mono_weed.fit(X_mono_weed, y_mono_weed)\n",
    "\n",
    "# Monocot-Crop model\n",
    "mono_crop_mask = (df['category1'] == 'monocot') & (df['category2'] == 'crop')\n",
    "X_mono_crop = X[mono_crop_mask]\n",
    "y_mono_crop = df['species'][mono_crop_mask]\n",
    "\n",
    "clf_mono_crop = RandomForestClassifier(random_state=42)\n",
    "clf_mono_crop.fit(X_mono_crop, y_mono_crop)\n",
    "\n",
    "# Dicot-Weed model\n",
    "dicot_weed_mask = (df['category1'] == 'dicot') & (df['category2'] == 'weed')\n",
    "X_dicot_weed = X[dicot_weed_mask]\n",
    "y_dicot_weed = df['species'][dicot_weed_mask]\n",
    "\n",
    "clf_dicot_weed = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_weed.fit(X_dicot_weed, y_dicot_weed)\n",
    "\n",
    "# Dicot-Crop model\n",
    "dicot_crop_mask = (df['category1'] == 'dicot') & (df['category2'] == 'crop')\n",
    "X_dicot_crop = X[dicot_crop_mask]\n",
    "y_dicot_crop = df['species'][dicot_crop_mask]\n",
    "\n",
    "clf_dicot_crop = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_crop.fit(X_dicot_crop, y_dicot_crop)\n",
    "\n",
    "# instead of unconditionally fitting, do it in one line:\n",
    "clf_dicot_crop = RandomForestClassifier(random_state=42).fit(\n",
    "    X_dicot_crop, y_dicot_crop\n",
    ") if len(y_dicot_crop)>0 else None\n",
    "\n",
    "\n",
    "# Predict species level on the test set:\n",
    "# For each test sample, use the predicted category1 and category2 to decide which classifier to use at level 3.\n",
    "\n",
    "final_species_preds = []\n",
    "\n",
    "for idx in X_test_cat1.index:\n",
    "    cat1_pred = clf_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if cat1_pred == 'monocot':\n",
    "        cat2_pred = clf_cat2_monocot.predict(X_test_cat1.loc[[idx]])[0]  # use monocot model for cat2\n",
    "        if cat2_pred == 'weed':\n",
    "            sp_pred = clf_mono_weed.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        else:  # crop\n",
    "            sp_pred = clf_mono_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    else:  # dicot\n",
    "        cat2_pred = clf_cat2_dicot.predict(X_test_cat1.loc[[idx]])[0]  # use dicot model for cat2\n",
    "        if cat2_pred == 'weed':\n",
    "            sp_pred = clf_dicot_weed.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        else:  # crop\n",
    "            sp_pred = clf_dicot_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate accuracy of final species predictions:\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test_species,final_species_preds)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test_species)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test_species, final_species_preds)\n",
    "print(report)\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258416cb-9a80-419b-98b4-516132b9afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5813953488372093\n",
      "            AVEFA     Barley  ECHCG        Oat      PAPRH      POLAV  \\\n",
      "AVEFA   77.777778  11.111111    0.0   0.000000   0.000000   0.000000   \n",
      "Barley  10.000000  10.000000   20.0  10.000000   0.000000   0.000000   \n",
      "ECHCG   20.000000  20.000000   40.0   0.000000  10.000000   0.000000   \n",
      "Oat     11.111111  55.555556    0.0  11.111111   0.000000   0.000000   \n",
      "PAPRH    0.000000   0.000000   10.0   0.000000  90.000000   0.000000   \n",
      "POLAV    0.000000  33.333333    0.0   0.000000  22.222222  44.444444   \n",
      "Wheat    3.448276   6.896552    0.0   3.448276   0.000000   3.448276   \n",
      "\n",
      "            Wheat  \n",
      "AVEFA   11.111111  \n",
      "Barley  50.000000  \n",
      "ECHCG   10.000000  \n",
      "Oat     22.222222  \n",
      "PAPRH    0.000000  \n",
      "POLAV    0.000000  \n",
      "Wheat   82.758621  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.58      0.78      0.67         9\n",
      "      Barley       0.07      0.10      0.08        10\n",
      "       ECHCG       0.57      0.40      0.47        10\n",
      "         Oat       0.33      0.11      0.17         9\n",
      "       PAPRH       0.75      0.90      0.82        10\n",
      "       POLAV       0.80      0.44      0.57         9\n",
      "       Wheat       0.73      0.83      0.77        29\n",
      "\n",
      "    accuracy                           0.58        86\n",
      "   macro avg       0.55      0.51      0.51        86\n",
      "weighted avg       0.59      0.58      0.57        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepare data\n",
    "\n",
    "y = df[\"species\"]\n",
    "\n",
    "# 2) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3) Build a pipeline: scaling + KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\",    KNeighborsClassifier(n_neighbors=5))  # you can tune n_neighbors\n",
    "])\n",
    "\n",
    "# 4) Train\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate accuracy\n",
    "accuracy = knn_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 6) Confusion matrix\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 7) Confusion matrix as percentages\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "class_labels = np.unique(y_test)\n",
    "cm_df = pd.DataFrame(cm_pct, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "# 8) Classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b51764bb-cc85-4bd7-8071-2d19069306da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN final accuracy: 0.7441860465116279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.64      0.78      0.70         9\n",
      "      Barley       0.43      0.43      0.43         7\n",
      "       ECHCG       0.88      0.88      0.88         8\n",
      "         Oat       1.00      0.36      0.53        11\n",
      "       PAPRH       0.92      1.00      0.96        11\n",
      "       POLAV       0.71      0.62      0.67         8\n",
      "       Wheat       0.73      0.84      0.78        32\n",
      "\n",
      "    accuracy                           0.74        86\n",
      "   macro avg       0.76      0.70      0.71        86\n",
      "weighted avg       0.77      0.74      0.73        86\n",
      "\n",
      "            AVEFA     Barley   ECHCG        Oat  PAPRH  POLAV      Wheat\n",
      "AVEFA   77.777778   0.000000   0.000   0.000000    0.0   0.00  22.222222\n",
      "Barley  14.285714  42.857143   0.000   0.000000    0.0   0.00  42.857143\n",
      "ECHCG   12.500000   0.000000  87.500   0.000000    0.0   0.00   0.000000\n",
      "Oat      9.090909   9.090909   0.000  36.363636    0.0   0.00  45.454545\n",
      "PAPRH    0.000000   0.000000   0.000   0.000000  100.0   0.00   0.000000\n",
      "POLAV   12.500000  12.500000   0.000   0.000000   12.5  62.50   0.000000\n",
      "Wheat    0.000000   6.250000   3.125   0.000000    0.0   6.25  84.375000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1) First split & train Level 1 (Monocot vs Dicot) with KNN\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "knn_cat1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "# 2) Train Level 2 KNNs\n",
    "knn_cat2_monocot = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat2_monocot.fit(X_monocot, y_monocot)\n",
    "\n",
    "knn_cat2_dicot = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat2_dicot.fit(X_dicot, y_dicot)\n",
    "\n",
    "# 3) Train Level 3 species‑models\n",
    "knn_mono_weed = KNeighborsClassifier(n_neighbors=5).fit(X_mono_weed, y_mono_weed)\n",
    "knn_mono_crop = (KNeighborsClassifier(n_neighbors=5).fit(X_mono_crop, y_mono_crop)\n",
    "                 if len(y_mono_crop)>0 else None)\n",
    "knn_dicot_weed = KNeighborsClassifier(n_neighbors=5).fit(X_dicot_weed, y_dicot_weed)\n",
    "knn_dicot_crop = (KNeighborsClassifier(n_neighbors=5).fit(X_dicot_crop, y_dicot_crop)\n",
    "                  if len(y_dicot_crop)>0 else None)\n",
    "\n",
    "# 4) Three‑stage prediction loop\n",
    "final_preds_knn = []\n",
    "for idx in X_test_cat1.index:\n",
    "    c1 = knn_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if c1=='monocot':\n",
    "        c2 = knn_cat2_monocot.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        if c2=='weed':\n",
    "            final_preds_knn.append(knn_mono_weed.predict(X_test_cat1.loc[[idx]])[0])\n",
    "        else:\n",
    "            final_preds_knn.append(\n",
    "                knn_mono_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "                if knn_mono_crop else \"unknown\"\n",
    "            )\n",
    "    else:\n",
    "        c2 = knn_cat2_dicot.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        if c2=='weed':\n",
    "            final_preds_knn.append(knn_dicot_weed.predict(X_test_cat1.loc[[idx]])[0])\n",
    "        else:\n",
    "            final_preds_knn.append(\n",
    "                knn_dicot_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "                if knn_dicot_crop else \"unknown\"\n",
    "            )\n",
    "\n",
    "# 5) Evaluate\n",
    "print(\"KNN final accuracy:\", accuracy_score(y_test_species, final_preds_knn))\n",
    "print(classification_report(y_test_species, final_preds_knn))\n",
    "\n",
    "cm_knn = confusion_matrix(y_test_species, final_preds_knn)\n",
    "cm_pct_knn = cm_knn.astype(float)/cm_knn.sum(axis=1)[:,None]*100\n",
    "cm_knn_df = pd.DataFrame(cm_pct_knn, index=np.unique(y_test_species), columns=np.unique(y_test_species))\n",
    "print(cm_knn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07e0aeb1-ff63-469b-bce3-a241345c9002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47674418604651164\n",
      "            AVEFA     Barley  ECHCG        Oat      PAPRH      POLAV  \\\n",
      "AVEFA   88.888889   0.000000    0.0   0.000000   0.000000   0.000000   \n",
      "Barley  10.000000  10.000000   10.0  40.000000   0.000000   0.000000   \n",
      "ECHCG   30.000000  10.000000   30.0  20.000000   0.000000   0.000000   \n",
      "Oat     11.111111  22.222222    0.0  66.666667   0.000000   0.000000   \n",
      "PAPRH    0.000000   0.000000   10.0   0.000000  90.000000   0.000000   \n",
      "POLAV   11.111111  22.222222    0.0   0.000000  11.111111  55.555556   \n",
      "Wheat    6.896552  13.793103    0.0  41.379310   0.000000   6.896552   \n",
      "\n",
      "            Wheat  \n",
      "AVEFA   11.111111  \n",
      "Barley  30.000000  \n",
      "ECHCG   10.000000  \n",
      "Oat      0.000000  \n",
      "PAPRH    0.000000  \n",
      "POLAV    0.000000  \n",
      "Wheat   31.034483  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.50      0.89      0.64         9\n",
      "      Barley       0.10      0.10      0.10        10\n",
      "       ECHCG       0.60      0.30      0.40        10\n",
      "         Oat       0.25      0.67      0.36         9\n",
      "       PAPRH       0.90      0.90      0.90        10\n",
      "       POLAV       0.71      0.56      0.62         9\n",
      "       Wheat       0.64      0.31      0.42        29\n",
      "\n",
      "    accuracy                           0.48        86\n",
      "   macro avg       0.53      0.53      0.49        86\n",
      "weighted avg       0.56      0.48      0.47        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepare data\n",
    "X = df[[\"PSSRa\",\"PSSRb\",\"PSSRc\",\"RARSc\",\"CARI\"]]  # Features\n",
    "y = df[\"species\"]\n",
    "\n",
    "# 2) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3) Build a pipeline: scaling + SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(\n",
    "        kernel=\"rbf\",       # try \"linear\" if you want coefficients\n",
    "        C=1.0,              # regularization parameter\n",
    "        class_weight=\"balanced\",\n",
    "        probability=False,  # set True if you need predict_proba\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4) Train\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate accuracy\n",
    "accuracy = svm_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 6) Confusion matrix\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 7) Confusion matrix as percentages\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "class_labels = np.unique(y_test)\n",
    "cm_df = pd.DataFrame(cm_pct, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "# 8) Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# 9) (Optional) Feature “importance” for a linear SVM:\n",
    "# If you switch to kernel=\"linear\", you can inspect svm_pipeline.named_steps['svc'].coef_\n",
    "# to see per-class feature weights:\n",
    "#\n",
    "# linear_svc = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"svc\",    SVC(kernel=\"linear\", C=1.0, random_state=42))\n",
    "# ])\n",
    "# linear_svc.fit(X_train, y_train)\n",
    "# coefs = linear_svc.named_steps['svc'].coef_\n",
    "# feature_names = X.columns\n",
    "# # coefs is shape (n_classes, n_features) for multiclass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8db4b7d-c8a4-41f4-8801-e62af2727c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Level‑2 dicot model: only one class present: ['weed']\n",
      "Accuracy: 0.627906976744186\n",
      "            AVEFA     Barley  ECHCG        Oat    PAPRH   POLAV      Wheat\n",
      "AVEFA   88.888889   0.000000   0.00   0.000000    0.000   0.000  11.111111\n",
      "Barley  28.571429  28.571429   0.00  14.285714    0.000   0.000  28.571429\n",
      "ECHCG   25.000000   0.000000  75.00   0.000000    0.000   0.000   0.000000\n",
      "Oat      9.090909   9.090909   0.00  54.545455    0.000   0.000  27.272727\n",
      "PAPRH    0.000000   0.000000   0.00   0.000000  100.000   0.000   0.000000\n",
      "POLAV   12.500000  12.500000  25.00   0.000000   25.000  25.000   0.000000\n",
      "Wheat    9.375000  12.500000   6.25   6.250000    3.125   3.125  59.375000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AVEFA       0.47      0.89      0.62         9\n",
      "      Barley       0.25      0.29      0.27         7\n",
      "       ECHCG       0.60      0.75      0.67         8\n",
      "         Oat       0.67      0.55      0.60        11\n",
      "       PAPRH       0.79      1.00      0.88        11\n",
      "       POLAV       0.67      0.25      0.36         8\n",
      "       Wheat       0.76      0.59      0.67        32\n",
      "\n",
      "    accuracy                           0.63        86\n",
      "   macro avg       0.60      0.62      0.58        86\n",
      "weighted avg       0.66      0.63      0.62        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# --- 1) Define your species groups ---\n",
    "monocot_species     = [\"Barley\", \"Wheat\", \"Oat\", \"AVEFA\",\"ECHCG\"]\n",
    "dicot_species       = [\"PAPRH\", \"POLAV\"]\n",
    "weed_species        = [\"AVEFA\", \"PAPRH\", \"POLAV\",\"ECHCG\"]\n",
    "crop_species        = [\"Barley\", \"Wheat\", \"Oat\"]\n",
    "\n",
    "# --- 2) Prepare your DataFrame ---\n",
    "# assume df is already loaded, with numeric features + a \"species\" column\n",
    "X = df.select_dtypes(include=[np.number])\n",
    "df[\"species\"] = df[\"species\"].astype(str)  # ensure no weird types\n",
    "\n",
    "# create hierarchical labels\n",
    "df[\"category1\"] = df[\"species\"].map(lambda s: \"monocot\" if s in monocot_species else \"dicot\")\n",
    "df[\"category2\"] = df[\"species\"].map(lambda s: \"weed\"    if s in weed_species    else \"crop\")\n",
    "\n",
    "# --- 3) Level‑1: monocot vs dicot ---\n",
    "X_train_l1, X_test_l1, y_train_l1, y_test_l1 = train_test_split(\n",
    "    X, df[\"category1\"], test_size=0.2, random_state=42, stratify=df[\"category1\"]\n",
    ")\n",
    "clf_l1 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_l1.fit(X_train_l1, y_train_l1)\n",
    "y_pred_l1 = clf_l1.predict(X_test_l1)\n",
    "\n",
    "# split test by predicted level‑1\n",
    "X_test_mono = X_test_l1[y_pred_l1 == \"monocot\"]\n",
    "X_test_dico = X_test_l1[y_pred_l1 == \"dicot\"]\n",
    "\n",
    "# --- 4) Level‑2 for monocot ---\n",
    "mono_mask = df[\"category1\"] == \"monocot\"\n",
    "X_mono    = X[mono_mask]\n",
    "y_mono    = df.loc[mono_mask, \"category2\"]\n",
    "X_tr_mono, X_val_mono, y_tr_mono, y_val_mono = train_test_split(\n",
    "    X_mono, y_mono, test_size=0.2, random_state=42, stratify=y_mono\n",
    ")\n",
    "clf_l2_mono = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", class_weight=\"balanced\" , C=1.0, random_state=42))\n",
    "])\n",
    "clf_l2_mono.fit(X_tr_mono, y_tr_mono)\n",
    "\n",
    "# --- 5) Level‑2 for dicot (guarded) ---\n",
    "dicot_mask = df[\"category1\"] == \"dicot\"\n",
    "X_dicot    = X[dicot_mask]\n",
    "y_dicot    = df.loc[dicot_mask, \"category2\"]\n",
    "\n",
    "if len(y_dicot.unique()) > 1:\n",
    "    X_tr_dico, X_val_dico, y_tr_dico, y_val_dico = train_test_split(\n",
    "        X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot\n",
    "    )\n",
    "    clf_l2_dico = RandomForestClassifier(random_state=42)\n",
    "    clf_l2_dico.fit(X_tr_dico, y_tr_dico)\n",
    "else:\n",
    "    clf_l2_dico = None\n",
    "    print(\"Skipping Level‑2 dicot model: only one class present:\", y_dicot.unique())\n",
    "\n",
    "# --- 6) Level‑3 species models (each guarded if needed) ---\n",
    "# Monocot‑Weed\n",
    "mask = (df[\"category1\"]==\"monocot\") & (df[\"category2\"]==\"weed\")\n",
    "clf_mono_weed = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", class_weight=\"balanced\" , C=1.0, random_state=42))\n",
    "])\n",
    "clf_mono_weed.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# Monocot‑Crop\n",
    "mask = (df[\"category1\"]==\"monocot\") & (df[\"category2\"]==\"crop\")\n",
    "clf_mono_crop = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", class_weight=\"balanced\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_mono_crop.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# Dicot‑Weed\n",
    "mask = (df[\"category1\"]==\"dicot\") & (df[\"category2\"]==\"weed\")\n",
    "clf_dico_weed = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", class_weight=\"balanced\",  C=1.0, random_state=42))\n",
    "])\n",
    "clf_dico_weed.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# Dicot‑Crop\n",
    "mask = (df[\"category1\"]==\"dicot\") & (df[\"category2\"]==\"crop\")\n",
    "if mask.sum() > 0:\n",
    "    clf_dico_crop = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\",    SVC(kernel=\"rbf\", class_weight=\"balanced\" ,C=1.0, random_state=42))\n",
    "    ])\n",
    "    clf_dico_crop.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "else:\n",
    "    clf_dico_crop = None\n",
    "\n",
    "# --- 7) Final species‑level prediction (with guard) ---\n",
    "final_preds = []\n",
    "for idx in X_test_l1.index:\n",
    "    cat1 = clf_l1.predict(X_test_l1.loc[[idx]])[0]\n",
    "\n",
    "    if cat1 == \"monocot\":\n",
    "        cat2 = clf_l2_mono.predict(X_test_l1.loc[[idx]])[0]\n",
    "        sp   = (clf_mono_weed if cat2==\"weed\" else clf_mono_crop).predict(X_test_l1.loc[[idx]])[0]\n",
    "\n",
    "    else:  # dicot\n",
    "        if clf_l2_dico is not None:\n",
    "            cat2 = clf_l2_dico.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            # only one possible dicot class\n",
    "            cat2 = y_dicot.unique()[0]\n",
    "\n",
    "        sp = (clf_dico_weed if cat2==\"weed\" else clf_dico_crop).predict(X_test_l1.loc[[idx]])[0]\n",
    "\n",
    "    final_preds.append(sp)\n",
    "\n",
    "final_preds = np.array(final_preds)\n",
    "y_true = df.loc[X_test_l1.index, \"species\"]\n",
    "\n",
    "# --- 8) Evaluate ---\n",
    "print(\"Accuracy:\", accuracy_score(y_true, final_preds))\n",
    "cm      = confusion_matrix(y_true, final_preds)\n",
    "cm_pct  = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "print(pd.DataFrame(cm_pct, index=np.unique(y_true), columns=np.unique(y_true)))\n",
    "print(classification_report(y_true, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41d71146-4fad-4380-89c6-0878d8cea7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "Wheat     115\n",
      "PAPRH      38\n",
      "Oat        38\n",
      "ECHCG      38\n",
      "Barley     38\n",
      "AVEFA      38\n",
      "POLAV      36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9780763f-2612-4fda-9748-9eab7f843dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim whitespace and unify casing\n",
    "df[\"species\"] = df[\"species\"].str.strip().str.capitalize()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
