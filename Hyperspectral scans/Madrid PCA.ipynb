{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864b57f9-1f2d-4ccc-b126-4285f78e6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Indices weed-crop.xlsx\", sheet_name=\"PCA-P\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70be28f3-b7da-4851-9ddb-16b9822e31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 379 entries, 0 to 378\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   species  379 non-null    object \n",
      " 1   PSSRa    379 non-null    float64\n",
      " 2   PSSRb    379 non-null    float64\n",
      " 3   RARSc    379 non-null    float64\n",
      " 4   PSSRc    379 non-null    float64\n",
      " 5   CARI     379 non-null    float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 17.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSSRa</th>\n",
       "      <th>PSSRb</th>\n",
       "      <th>RARSc</th>\n",
       "      <th>PSSRc</th>\n",
       "      <th>CARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.300467</td>\n",
       "      <td>6.347584</td>\n",
       "      <td>6.122671</td>\n",
       "      <td>6.149898</td>\n",
       "      <td>1.919156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.517251</td>\n",
       "      <td>1.350003</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>1.371763</td>\n",
       "      <td>0.456210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.462164</td>\n",
       "      <td>3.649889</td>\n",
       "      <td>3.480319</td>\n",
       "      <td>3.464069</td>\n",
       "      <td>0.907283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.986514</td>\n",
       "      <td>5.210576</td>\n",
       "      <td>4.822342</td>\n",
       "      <td>4.833785</td>\n",
       "      <td>1.511847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.160828</td>\n",
       "      <td>6.267649</td>\n",
       "      <td>6.264662</td>\n",
       "      <td>6.300172</td>\n",
       "      <td>1.988189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.363482</td>\n",
       "      <td>7.322649</td>\n",
       "      <td>7.118963</td>\n",
       "      <td>7.168612</td>\n",
       "      <td>2.260592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.878288</td>\n",
       "      <td>9.811643</td>\n",
       "      <td>9.172213</td>\n",
       "      <td>9.222778</td>\n",
       "      <td>3.005503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PSSRa       PSSRb       RARSc       PSSRc        CARI\n",
       "count  379.000000  379.000000  379.000000  379.000000  379.000000\n",
       "mean     7.300467    6.347584    6.122671    6.149898    1.919156\n",
       "std      1.517251    1.350003    1.355932    1.371763    0.456210\n",
       "min      4.462164    3.649889    3.480319    3.464069    0.907283\n",
       "25%      5.986514    5.210576    4.822342    4.833785    1.511847\n",
       "50%      7.160828    6.267649    6.264662    6.300172    1.988189\n",
       "75%      8.363482    7.322649    7.118963    7.168612    2.260592\n",
       "max     10.878288    9.811643    9.172213    9.222778    3.005503"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()       # Shows the first five rows\n",
    "df.info()       # Gives an overview of columns, data types, and non-null counts\n",
    "df.describe()   # Provides summary statistics for numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b07fbca-40f0-48f4-997d-599221148bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6447368421052632\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.60      0.33      0.43         9\n",
      "       BROSS       0.56      0.50      0.53        10\n",
      "    Camelina       0.73      0.80      0.76        10\n",
      "      Canola       0.58      0.70      0.64        10\n",
      "       DIPMU       1.00      1.00      1.00         9\n",
      "       LOLMU       0.50      0.56      0.53         9\n",
      "       PAPRH       0.64      0.78      0.70         9\n",
      "      Salvia       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.64        76\n",
      "   macro avg       0.64      0.65      0.64        76\n",
      "weighted avg       0.64      0.64      0.64        76\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGPR</th>\n",
       "      <th>BROSS</th>\n",
       "      <th>Camelina</th>\n",
       "      <th>Canola</th>\n",
       "      <th>DIPMU</th>\n",
       "      <th>LOLMU</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>Salvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASGPR</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROSS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camelina</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canola</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIPMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOLMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvia</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ASGPR      BROSS   Camelina     Canola  DIPMU      LOLMU  \\\n",
       "ASGPR     33.333333   0.000000  11.111111  11.111111    0.0   0.000000   \n",
       "BROSS      0.000000  50.000000   0.000000  10.000000    0.0  40.000000   \n",
       "Camelina   0.000000   0.000000  80.000000   0.000000    0.0   0.000000   \n",
       "Canola    10.000000   0.000000   0.000000  70.000000    0.0  10.000000   \n",
       "DIPMU      0.000000   0.000000   0.000000   0.000000  100.0   0.000000   \n",
       "LOLMU      0.000000  44.444444   0.000000   0.000000    0.0  55.555556   \n",
       "PAPRH      0.000000   0.000000   0.000000  22.222222    0.0   0.000000   \n",
       "Salvia    10.000000   0.000000  20.000000  10.000000    0.0   0.000000   \n",
       "\n",
       "              PAPRH     Salvia  \n",
       "ASGPR     33.333333  11.111111  \n",
       "BROSS      0.000000   0.000000  \n",
       "Camelina   0.000000  20.000000  \n",
       "Canola     0.000000  10.000000  \n",
       "DIPMU      0.000000   0.000000  \n",
       "LOLMU      0.000000   0.000000  \n",
       "PAPRH     77.777778   0.000000  \n",
       "Salvia    10.000000  50.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'target' is the name of your target column:\n",
    "X = df.drop(\"species\", axis=1)  # Features\n",
    "y = df[\"species\"]               # Target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and train the random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Variable Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances from Random Forest')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()\n",
    "\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ea9118-8256-40ff-a898-3f54e18770ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Species-Level Accuracy: 0.9078947368421053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.92      0.86      0.89        14\n",
      "       BROSS       1.00      0.80      0.89        10\n",
      "    Camelina       1.00      1.00      1.00         7\n",
      "      Canola       0.90      1.00      0.95         9\n",
      "       DIPMU       0.79      1.00      0.88        11\n",
      "       LOLMU       0.89      0.89      0.89         9\n",
      "       PAPRH       1.00      1.00      1.00         9\n",
      "      Salvia       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.91        76\n",
      "   macro avg       0.92      0.91      0.91        76\n",
      "weighted avg       0.91      0.91      0.91        76\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGPR</th>\n",
       "      <th>BROSS</th>\n",
       "      <th>Camelina</th>\n",
       "      <th>Canola</th>\n",
       "      <th>DIPMU</th>\n",
       "      <th>LOLMU</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>Salvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASGPR</th>\n",
       "      <td>85.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROSS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camelina</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canola</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIPMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOLMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvia</th>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ASGPR  BROSS  Camelina      Canola       DIPMU      LOLMU  \\\n",
       "ASGPR     85.714286    0.0       0.0    7.142857    0.000000   0.000000   \n",
       "BROSS      0.000000   80.0       0.0    0.000000   20.000000   0.000000   \n",
       "Camelina   0.000000    0.0     100.0    0.000000    0.000000   0.000000   \n",
       "Canola     0.000000    0.0       0.0  100.000000    0.000000   0.000000   \n",
       "DIPMU      0.000000    0.0       0.0    0.000000  100.000000   0.000000   \n",
       "LOLMU      0.000000    0.0       0.0    0.000000   11.111111  88.888889   \n",
       "PAPRH      0.000000    0.0       0.0    0.000000    0.000000   0.000000   \n",
       "Salvia    14.285714    0.0       0.0    0.000000    0.000000  14.285714   \n",
       "\n",
       "          PAPRH     Salvia  \n",
       "ASGPR       0.0   7.142857  \n",
       "BROSS       0.0   0.000000  \n",
       "Camelina    0.0   0.000000  \n",
       "Canola      0.0   0.000000  \n",
       "DIPMU       0.0   0.000000  \n",
       "LOLMU       0.0   0.000000  \n",
       "PAPRH     100.0   0.000000  \n",
       "Salvia      0.0  71.428571  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example lists of species for each category\n",
    "monocot_species = [\"LOLMU\",\"BROSS\"]  # example species\n",
    "dicot_species   = [\"PAPRH\",\"ASGPR\",\"Camelina\",\"Canola\",\"DIPMU\",\"Salvia\" ]\n",
    "weed_species    = [\"LOLMU\",\"BROSS\",\"PAPRH\",\"ASGPR\",\"DIPMU\"]  # example of some species labeled as weeds\n",
    "crop_species    = [\"Camelina\",\"Canola\",\"Salvia\"]\n",
    "\n",
    "# Third-level species groups (adjust these depending on your actual data):\n",
    "monocot_weed_species = [\"LOLMU\",\"BROSS\"]\n",
    "dicot_weed_species   = [\"PAPRH\",\"ASGPR\",\"DIPMU\"]\n",
    "dicot_crop_species = [\"Camelina\",\"Canola\",\"Salvia\"]\n",
    "\n",
    "# Assume df is your main dataframe with features and species\n",
    "# Example:\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df[[\"PSSRa\",\"PSSRb\",\"PSSRc\",\"RARSc\",\"CARI\"]]  # Features\n",
    "\n",
    "\n",
    "# Create first-level category\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "# Create second-level category\n",
    "df['category2'] = df['species'].apply(lambda s: 'weed' if s in weed_species else 'crop')\n",
    "\n",
    "\n",
    "y_cat1 = df[\"category1\"]  # Level 1 target \n",
    "\n",
    "# Level 1: Monocot vs Dicot\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1)\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "y_pred_cat1 = clf_cat1.predict(X_test_cat1)\n",
    "\n",
    "# Split test data by predicted category1\n",
    "X_test_monocot = X_test_cat1[y_pred_cat1 == 'monocot']\n",
    "X_test_dicot   = X_test_cat1[y_pred_cat1 == 'dicot']\n",
    "\n",
    "y_test_monocot = df.loc[X_test_monocot.index, 'category2']\n",
    "y_test_dicot   = df.loc[X_test_dicot.index, 'category2']\n",
    "\n",
    "# Level 2: Weed vs Crop (for monocot)\n",
    "monocot_mask = df['category1'] == 'monocot'\n",
    "X_monocot = X[monocot_mask]\n",
    "y_monocot = df['category2'][monocot_mask]\n",
    "\n",
    "X_train_mono, X_val_mono, y_train_mono, y_val_mono = train_test_split(X_monocot, y_monocot, test_size=0.2, random_state=42, stratify=y_monocot)\n",
    "clf_cat2_monocot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_monocot.fit(X_train_mono, y_train_mono)\n",
    "\n",
    "y_pred_cat2_monocot = clf_cat2_monocot.predict(X_test_monocot)\n",
    "\n",
    "# Level 2: Weed vs Crop (for dicot)\n",
    "dicot_mask = df['category1'] == 'dicot'\n",
    "X_dicot = X[dicot_mask]\n",
    "y_dicot = df['category2'][dicot_mask]\n",
    "\n",
    "X_train_di, X_val_di, y_train_di, y_val_di = train_test_split(X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot)\n",
    "clf_cat2_dicot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_dicot.fit(X_train_di, y_train_di)\n",
    "\n",
    "y_pred_cat2_dicot = clf_cat2_dicot.predict(X_test_dicot)\n",
    "\n",
    "# Now we have predictions for category1 and category2. Next: species level.\n",
    "\n",
    "# For the third level, we train separate models for each final group:\n",
    "# Monocot-Weed, Monocot-Crop, Dicot-Weed, Dicot-Crop.\n",
    "\n",
    "# Example: Monocot-Weed model (if multiple species in that group)\n",
    "mono_weed_mask = (df['category1'] == 'monocot') & (df['category2'] == 'weed')\n",
    "X_mono_weed = X[mono_weed_mask]\n",
    "y_mono_weed = df['species'][mono_weed_mask]\n",
    "\n",
    "clf_mono_weed = RandomForestClassifier(random_state=42)\n",
    "clf_mono_weed.fit(X_mono_weed, y_mono_weed)\n",
    "\n",
    "# Monocot-Crop model\n",
    "mono_crop_mask = (df['category1'] == 'monocot') & (df['category2'] == 'crop')\n",
    "X_mono_crop = X[mono_crop_mask]\n",
    "y_mono_crop = df['species'][mono_crop_mask]\n",
    "\n",
    "clf_mono_crop = RandomForestClassifier(random_state=42).fit(\n",
    "    X_mono_crop, y_mono_crop\n",
    ") if len(y_mono_crop) > 0 else None\n",
    "\n",
    "\n",
    "# Dicot-Weed model\n",
    "dicot_weed_mask = (df['category1'] == 'dicot') & (df['category2'] == 'weed')\n",
    "X_dicot_weed = X[dicot_weed_mask]\n",
    "y_dicot_weed = df['species'][dicot_weed_mask]\n",
    "\n",
    "clf_dicot_weed = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_weed.fit(X_dicot_weed, y_dicot_weed)\n",
    "\n",
    "# Dicot-Crop model\n",
    "dicot_crop_mask = (df['category1'] == 'dicot') & (df['category2'] == 'crop')\n",
    "X_dicot_crop = X[dicot_crop_mask]\n",
    "y_dicot_crop = df['species'][dicot_crop_mask]\n",
    "\n",
    "clf_dicot_crop = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_crop.fit(X_dicot_crop, y_dicot_crop)\n",
    "\n",
    "\n",
    "# Predict species level on the test set:\n",
    "# For each test sample, use the predicted category1 and category2 to decide which classifier to use at level 3.\n",
    "\n",
    "final_species_preds = []\n",
    "\n",
    "for idx in X_test_cat1.index:\n",
    "    cat1_pred = clf_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if cat1_pred == 'monocot':\n",
    "        cat2_pred = clf_cat2_monocot.predict(X_test_cat1.loc[[idx]])[0]  # use monocot model for cat2\n",
    "        if cat2_pred == 'weed':\n",
    "            sp_pred = clf_mono_weed.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        else:  # crop\n",
    "            sp_pred = clf_mono_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    else:  # dicot\n",
    "        cat2_pred = clf_cat2_dicot.predict(X_test_cat1.loc[[idx]])[0]  # use dicot model for cat2\n",
    "        if cat2_pred == 'weed':\n",
    "            sp_pred = clf_dicot_weed.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        else:  # crop\n",
    "            sp_pred = clf_dicot_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate accuracy of final species predictions:\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test_species,final_species_preds)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test_species)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test_species, final_species_preds)\n",
    "print(report)\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8a76b9-4c42-421c-956f-4d7d198fd8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Species-Level Accuracy: 0.6578947368421053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.67      0.43      0.52        14\n",
      "       BROSS       1.00      0.30      0.46        10\n",
      "    Camelina       1.00      0.71      0.83         7\n",
      "      Canola       0.50      0.89      0.64         9\n",
      "       DIPMU       0.92      1.00      0.96        11\n",
      "       LOLMU       0.57      0.89      0.70         9\n",
      "       PAPRH       0.67      0.67      0.67         9\n",
      "      Salvia       0.38      0.43      0.40         7\n",
      "\n",
      "    accuracy                           0.66        76\n",
      "   macro avg       0.71      0.66      0.65        76\n",
      "weighted avg       0.72      0.66      0.65        76\n",
      "\n",
      "              ASGPR  BROSS   Camelina     Canola       DIPMU      LOLMU  \\\n",
      "ASGPR     42.857143    0.0   0.000000  21.428571    0.000000   0.000000   \n",
      "BROSS      0.000000   30.0   0.000000  20.000000    0.000000  50.000000   \n",
      "Camelina  28.571429    0.0  71.428571   0.000000    0.000000   0.000000   \n",
      "Canola     0.000000    0.0   0.000000  88.888889    0.000000   0.000000   \n",
      "DIPMU      0.000000    0.0   0.000000   0.000000  100.000000   0.000000   \n",
      "LOLMU      0.000000    0.0   0.000000   0.000000   11.111111  88.888889   \n",
      "PAPRH      0.000000    0.0   0.000000  22.222222    0.000000   0.000000   \n",
      "Salvia    14.285714    0.0   0.000000  14.285714    0.000000  14.285714   \n",
      "\n",
      "              PAPRH     Salvia  \n",
      "ASGPR     14.285714  21.428571  \n",
      "BROSS      0.000000   0.000000  \n",
      "Camelina   0.000000   0.000000  \n",
      "Canola     0.000000  11.111111  \n",
      "DIPMU      0.000000   0.000000  \n",
      "LOLMU      0.000000   0.000000  \n",
      "PAPRH     66.666667  11.111111  \n",
      "Salvia    14.285714  42.857143  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGPR</th>\n",
       "      <th>BROSS</th>\n",
       "      <th>Camelina</th>\n",
       "      <th>Canola</th>\n",
       "      <th>DIPMU</th>\n",
       "      <th>LOLMU</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>Salvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASGPR</th>\n",
       "      <td>42.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>21.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROSS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camelina</th>\n",
       "      <td>28.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canola</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIPMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOLMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvia</th>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ASGPR  BROSS   Camelina     Canola       DIPMU      LOLMU  \\\n",
       "ASGPR     42.857143    0.0   0.000000  21.428571    0.000000   0.000000   \n",
       "BROSS      0.000000   30.0   0.000000  20.000000    0.000000  50.000000   \n",
       "Camelina  28.571429    0.0  71.428571   0.000000    0.000000   0.000000   \n",
       "Canola     0.000000    0.0   0.000000  88.888889    0.000000   0.000000   \n",
       "DIPMU      0.000000    0.0   0.000000   0.000000  100.000000   0.000000   \n",
       "LOLMU      0.000000    0.0   0.000000   0.000000   11.111111  88.888889   \n",
       "PAPRH      0.000000    0.0   0.000000  22.222222    0.000000   0.000000   \n",
       "Salvia    14.285714    0.0   0.000000  14.285714    0.000000  14.285714   \n",
       "\n",
       "              PAPRH     Salvia  \n",
       "ASGPR     14.285714  21.428571  \n",
       "BROSS      0.000000   0.000000  \n",
       "Camelina   0.000000   0.000000  \n",
       "Canola     0.000000  11.111111  \n",
       "DIPMU      0.000000   0.000000  \n",
       "LOLMU      0.000000   0.000000  \n",
       "PAPRH     66.666667  11.111111  \n",
       "Salvia    14.285714  42.857143  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# Example lists of species for each category\n",
    "monocot_species = [\"LOLMU\",\"BROSS\"]  # example species\n",
    "\n",
    "\n",
    "# everything else is dicot in your toy example\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "\n",
    "# 2) Pick only your numeric features automatically\n",
    "X = df[[\"PSSRa\",\"PSSRb\",\"PSSRc\",\"RARSc\",\"CARI\"]]  # Features\n",
    "y_cat1 = df['category1']\n",
    "\n",
    "# 3) Split & train level‑1\n",
    "X1_tr, X1_te, y1_tr, y1_te = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X1_tr, y1_tr)\n",
    "\n",
    "# 4) Train one species‐classifier per category1 (on your existing train split)\n",
    "mono_idx = X_train_cat1[y_train_cat1=='monocot'].index\n",
    "dicot_idx = X_train_cat1[y_train_cat1=='dicot'].index\n",
    "\n",
    "clf_mono_species = RandomForestClassifier(random_state=42)\n",
    "clf_mono_species.fit(\n",
    "    X_train_cat1.loc[mono_idx],\n",
    "    df.loc[mono_idx, 'species']\n",
    ")\n",
    "\n",
    "clf_dicot_species = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_species.fit(\n",
    "    X_train_cat1.loc[dicot_idx],\n",
    "    df.loc[dicot_idx, 'species']\n",
    ")\n",
    "\n",
    "# 5) Two‐stage prediction on X_test_cat1\n",
    "final_species_preds = []\n",
    "for idx in X_test_cat1.index:\n",
    "    cat1_pred = clf_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if cat1_pred == 'monocot':\n",
    "        sp_pred = clf_mono_species.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    else:  # dicot\n",
    "        sp_pred = clf_dicot_species.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "print(classification_report(y_test_species, final_species_preds))\n",
    "\n",
    "cm = confusion_matrix(y_test_species, final_species_preds)\n",
    "cm_percentage = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "class_labels = np.unique(y_test_species)\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "cm_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a705f2b0-634b-43dc-a9ca-45b61b5c2da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6710526315789473\n",
      "              ASGPR      BROSS   Camelina     Canola  DIPMU      LOLMU  \\\n",
      "ASGPR     66.666667   0.000000  11.111111  11.111111    0.0   0.000000   \n",
      "BROSS      0.000000  60.000000   0.000000   0.000000    0.0  40.000000   \n",
      "Camelina   0.000000   0.000000  80.000000   0.000000    0.0   0.000000   \n",
      "Canola    20.000000   0.000000   0.000000  70.000000    0.0  10.000000   \n",
      "DIPMU      0.000000   0.000000   0.000000   0.000000  100.0   0.000000   \n",
      "LOLMU      0.000000  55.555556   0.000000   0.000000    0.0  44.444444   \n",
      "PAPRH     22.222222   0.000000   0.000000  11.111111    0.0   0.000000   \n",
      "Salvia    30.000000   0.000000  10.000000   0.000000    0.0   0.000000   \n",
      "\n",
      "              PAPRH  Salvia  \n",
      "ASGPR     11.111111     0.0  \n",
      "BROSS      0.000000     0.0  \n",
      "Camelina   0.000000    20.0  \n",
      "Canola     0.000000     0.0  \n",
      "DIPMU      0.000000     0.0  \n",
      "LOLMU      0.000000     0.0  \n",
      "PAPRH     66.666667     0.0  \n",
      "Salvia    10.000000    50.0  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.46      0.67      0.55         9\n",
      "       BROSS       0.55      0.60      0.57        10\n",
      "    Camelina       0.80      0.80      0.80        10\n",
      "      Canola       0.78      0.70      0.74        10\n",
      "       DIPMU       1.00      1.00      1.00         9\n",
      "       LOLMU       0.44      0.44      0.44         9\n",
      "       PAPRH       0.75      0.67      0.71         9\n",
      "      Salvia       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.67        76\n",
      "   macro avg       0.69      0.67      0.67        76\n",
      "weighted avg       0.69      0.67      0.67        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepare data\n",
    "\n",
    "y = df[\"species\"]\n",
    "\n",
    "# 2) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3) Build a pipeline: scaling + KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\",    KNeighborsClassifier(n_neighbors=5))  # you can tune n_neighbors\n",
    "])\n",
    "\n",
    "# 4) Train\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate accuracy\n",
    "accuracy = knn_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 6) Confusion matrix\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 7) Confusion matrix as percentages\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "class_labels = np.unique(y_test)\n",
    "cm_df = pd.DataFrame(cm_pct, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "# 8) Classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55003d34-288a-410b-b5b4-6dffba2c8de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN final accuracy: 0.6973684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.75      0.43      0.55        14\n",
      "       BROSS       0.75      0.30      0.43        10\n",
      "    Camelina       0.75      0.86      0.80         7\n",
      "      Canola       0.57      0.89      0.70         9\n",
      "       DIPMU       1.00      1.00      1.00        11\n",
      "       LOLMU       0.57      0.89      0.70         9\n",
      "       PAPRH       0.88      0.78      0.82         9\n",
      "      Salvia       0.44      0.57      0.50         7\n",
      "\n",
      "    accuracy                           0.70        76\n",
      "   macro avg       0.71      0.71      0.69        76\n",
      "weighted avg       0.73      0.70      0.68        76\n",
      "\n",
      "              ASGPR      BROSS   Camelina     Canola  DIPMU      LOLMU  \\\n",
      "ASGPR     42.857143   0.000000  14.285714  14.285714    0.0   0.000000   \n",
      "BROSS      0.000000  30.000000   0.000000  20.000000    0.0  50.000000   \n",
      "Camelina   0.000000   0.000000  85.714286   0.000000    0.0   0.000000   \n",
      "Canola    11.111111   0.000000   0.000000  88.888889    0.0   0.000000   \n",
      "DIPMU      0.000000   0.000000   0.000000   0.000000  100.0   0.000000   \n",
      "LOLMU      0.000000  11.111111   0.000000   0.000000    0.0  88.888889   \n",
      "PAPRH     11.111111   0.000000   0.000000  11.111111    0.0   0.000000   \n",
      "Salvia     0.000000   0.000000   0.000000  14.285714    0.0  14.285714   \n",
      "\n",
      "              PAPRH     Salvia  \n",
      "ASGPR      0.000000  28.571429  \n",
      "BROSS      0.000000   0.000000  \n",
      "Camelina   0.000000  14.285714  \n",
      "Canola     0.000000   0.000000  \n",
      "DIPMU      0.000000   0.000000  \n",
      "LOLMU      0.000000   0.000000  \n",
      "PAPRH     77.777778   0.000000  \n",
      "Salvia    14.285714  57.142857  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1) First split & train Level 1 (Monocot vs Dicot) with KNN\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "knn_cat1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "# 2) Train Level 2 KNNs\n",
    "knn_cat2_monocot = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat2_monocot.fit(X_monocot, y_monocot)\n",
    "\n",
    "knn_cat2_dicot = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat2_dicot.fit(X_dicot, y_dicot)\n",
    "\n",
    "# 3) Train Level 3 species‑models\n",
    "knn_mono_weed = KNeighborsClassifier(n_neighbors=5).fit(X_mono_weed, y_mono_weed)\n",
    "knn_mono_crop = (KNeighborsClassifier(n_neighbors=5).fit(X_mono_crop, y_mono_crop)\n",
    "                 if len(y_mono_crop)>0 else None)\n",
    "knn_dicot_weed = KNeighborsClassifier(n_neighbors=5).fit(X_dicot_weed, y_dicot_weed)\n",
    "knn_dicot_crop = (KNeighborsClassifier(n_neighbors=5).fit(X_dicot_crop, y_dicot_crop)\n",
    "                  if len(y_dicot_crop)>0 else None)\n",
    "\n",
    "# 4) Three‑stage prediction loop\n",
    "final_preds_knn = []\n",
    "for idx in X_test_cat1.index:\n",
    "    c1 = knn_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if c1=='monocot':\n",
    "        c2 = knn_cat2_monocot.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        if c2=='weed':\n",
    "            final_preds_knn.append(knn_mono_weed.predict(X_test_cat1.loc[[idx]])[0])\n",
    "        else:\n",
    "            final_preds_knn.append(\n",
    "                knn_mono_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "                if knn_mono_crop else \"unknown\"\n",
    "            )\n",
    "    else:\n",
    "        c2 = knn_cat2_dicot.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        if c2=='weed':\n",
    "            final_preds_knn.append(knn_dicot_weed.predict(X_test_cat1.loc[[idx]])[0])\n",
    "        else:\n",
    "            final_preds_knn.append(\n",
    "                knn_dicot_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "                if knn_dicot_crop else \"unknown\"\n",
    "            )\n",
    "\n",
    "# 5) Evaluate\n",
    "print(\"KNN final accuracy:\", accuracy_score(y_test_species, final_preds_knn))\n",
    "print(classification_report(y_test_species, final_preds_knn))\n",
    "\n",
    "cm_knn = confusion_matrix(y_test_species, final_preds_knn)\n",
    "cm_pct_knn = cm_knn.astype(float)/cm_knn.sum(axis=1)[:,None]*100\n",
    "cm_knn_df = pd.DataFrame(cm_pct_knn, index=np.unique(y_test_species), columns=np.unique(y_test_species))\n",
    "print(cm_knn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a925e78-e69e-43dd-be0f-968cae227803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6447368421052632\n",
      "              ASGPR      BROSS   Camelina     Canola  DIPMU      LOLMU  \\\n",
      "ASGPR     66.666667   0.000000  11.111111  11.111111    0.0   0.000000   \n",
      "BROSS      0.000000  50.000000   0.000000  10.000000    0.0  40.000000   \n",
      "Camelina  10.000000   0.000000  80.000000   0.000000    0.0   0.000000   \n",
      "Canola    30.000000  10.000000   0.000000  60.000000    0.0   0.000000   \n",
      "DIPMU      0.000000   0.000000   0.000000   0.000000  100.0   0.000000   \n",
      "LOLMU      0.000000  55.555556   0.000000   0.000000    0.0  44.444444   \n",
      "PAPRH     44.444444   0.000000   0.000000   0.000000    0.0   0.000000   \n",
      "Salvia    20.000000   0.000000  10.000000  10.000000    0.0   0.000000   \n",
      "\n",
      "              PAPRH  Salvia  \n",
      "ASGPR     11.111111     0.0  \n",
      "BROSS      0.000000     0.0  \n",
      "Camelina   0.000000    10.0  \n",
      "Canola     0.000000     0.0  \n",
      "DIPMU      0.000000     0.0  \n",
      "LOLMU      0.000000     0.0  \n",
      "PAPRH     55.555556     0.0  \n",
      "Salvia     0.000000    60.0  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.38      0.67      0.48         9\n",
      "       BROSS       0.45      0.50      0.48        10\n",
      "    Camelina       0.80      0.80      0.80        10\n",
      "      Canola       0.67      0.60      0.63        10\n",
      "       DIPMU       1.00      1.00      1.00         9\n",
      "       LOLMU       0.50      0.44      0.47         9\n",
      "       PAPRH       0.83      0.56      0.67         9\n",
      "      Salvia       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.64        76\n",
      "   macro avg       0.69      0.65      0.65        76\n",
      "weighted avg       0.69      0.64      0.65        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepare data\n",
    "\n",
    "y = df[\"species\"]\n",
    "\n",
    "# 2) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3) Build a pipeline: scaling + SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(\n",
    "        kernel=\"rbf\",       # try \"linear\" if you want coefficients\n",
    "        C=1.0,              # regularization parameter\n",
    "        probability=False,  # set True if you need predict_proba\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4) Train\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate accuracy\n",
    "accuracy = svm_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 6) Confusion matrix\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 7) Confusion matrix as percentages\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "class_labels = np.unique(y_test)\n",
    "cm_df = pd.DataFrame(cm_pct, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "# 8) Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 9) (Optional) Feature “importance” for a linear SVM:\n",
    "# If you switch to kernel=\"linear\", you can inspect svm_pipeline.named_steps['svc'].coef_\n",
    "# to see per-class feature weights:\n",
    "#\n",
    "# linear_svc = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"svc\",    SVC(kernel=\"linear\", C=1.0, random_state=42))\n",
    "# ])\n",
    "# linear_svc.fit(X_train, y_train)\n",
    "# coefs = linear_svc.named_steps['svc'].coef_\n",
    "# feature_names = X.columns\n",
    "# # coefs is shape (n_classes, n_features) for multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "473d08ee-4a12-40b9-bd90-5f976e9d93bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Level‑2 monocot model: only one class present: ['weed']\n",
      "Skipping monocot→crop model: no samples for that group.\n",
      "Accuracy: 0.8157894736842105\n",
      "Accuracy: 0.8157894736842105\n",
      "              ASGPR      BROSS    Camelina      Canola  DIPMU      LOLMU  \\\n",
      "ASGPR     85.714286   0.000000    7.142857    0.000000    0.0   0.000000   \n",
      "BROSS      0.000000  60.000000    0.000000    0.000000    0.0  40.000000   \n",
      "Camelina   0.000000   0.000000  100.000000    0.000000    0.0   0.000000   \n",
      "Canola     0.000000   0.000000    0.000000  100.000000    0.0   0.000000   \n",
      "DIPMU      0.000000   0.000000    0.000000    0.000000  100.0   0.000000   \n",
      "LOLMU      0.000000  22.222222    0.000000    0.000000    0.0  77.777778   \n",
      "PAPRH     33.333333   0.000000    0.000000    0.000000    0.0   0.000000   \n",
      "Salvia     0.000000   0.000000   14.285714   14.285714    0.0  14.285714   \n",
      "\n",
      "              PAPRH     Salvia  \n",
      "ASGPR      0.000000   7.142857  \n",
      "BROSS      0.000000   0.000000  \n",
      "Camelina   0.000000   0.000000  \n",
      "Canola     0.000000   0.000000  \n",
      "DIPMU      0.000000   0.000000  \n",
      "LOLMU      0.000000   0.000000  \n",
      "PAPRH     66.666667   0.000000  \n",
      "Salvia     0.000000  57.142857  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.80      0.86      0.83        14\n",
      "       BROSS       0.75      0.60      0.67        10\n",
      "    Camelina       0.78      1.00      0.88         7\n",
      "      Canola       0.90      1.00      0.95         9\n",
      "       DIPMU       1.00      1.00      1.00        11\n",
      "       LOLMU       0.58      0.78      0.67         9\n",
      "       PAPRH       1.00      0.67      0.80         9\n",
      "      Salvia       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.82        76\n",
      "   macro avg       0.83      0.81      0.81        76\n",
      "weighted avg       0.83      0.82      0.81        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# --- 1) Define your species groups ---\n",
    "monocot_species = [\"LOLMU\",\"BROSS\"]  # example species\n",
    "dicot_species   = [\"PAPRH\",\"ASGPR\",\"Camelina\",\"Canola\",\"DIPMU\",\"Salvia\" ]\n",
    "weed_species    = [\"LOLMU\",\"BROSS\",\"PAPRH\",\"ASGPR\",\"DIPMU\"]  # example of some species labeled as weeds\n",
    "crop_species    = [\"Camelina\",\"Canola\",\"Salvia\"]\n",
    "\n",
    "\n",
    "# --- 2) Prepare your DataFrame ---\n",
    "# assume df is already loaded, with numeric features + a \"species\" column\n",
    "X = df.select_dtypes(include=[np.number])\n",
    "df[\"species\"] = df[\"species\"].astype(str)  # ensure no weird types\n",
    "\n",
    "# create hierarchical labels\n",
    "df[\"category1\"] = df[\"species\"].map(lambda s: \"monocot\" if s in monocot_species else \"dicot\")\n",
    "df[\"category2\"] = df[\"species\"].map(lambda s: \"weed\"    if s in weed_species    else \"crop\")\n",
    "\n",
    "# --- 3) Level‑1: monocot vs dicot ---\n",
    "X_train_l1, X_test_l1, y_train_l1, y_test_l1 = train_test_split(\n",
    "    X, df[\"category1\"], test_size=0.2, random_state=42, stratify=df[\"category1\"]\n",
    ")\n",
    "clf_l1 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_l1.fit(X_train_l1, y_train_l1)\n",
    "y_pred_l1 = clf_l1.predict(X_test_l1)\n",
    "\n",
    "# split test by predicted level‑1\n",
    "X_test_mono = X_test_l1[y_pred_l1 == \"monocot\"]\n",
    "X_test_dico = X_test_l1[y_pred_l1 == \"dicot\"]\n",
    "\n",
    "# --- 4) Level‑2 for monocot ---\n",
    "# --- Level‑2 for monocot (guarded) ---\n",
    "mono_mask = df[\"category1\"] == \"monocot\"\n",
    "X_mono    = X[mono_mask]\n",
    "y_mono    = df.loc[mono_mask, \"category2\"]\n",
    "\n",
    "if len(y_mono.unique()) > 1:\n",
    "    X_tr_mono, X_val_mono, y_tr_mono, y_val_mono = train_test_split(\n",
    "        X_mono, y_mono, test_size=0.2, random_state=42, stratify=y_mono\n",
    "    )\n",
    "    clf_l2_mono = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "    ])\n",
    "    clf_l2_mono.fit(X_tr_mono, y_tr_mono)\n",
    "else:\n",
    "    clf_l2_mono = None\n",
    "    print(\"Skipping Level‑2 monocot model: only one class present:\", y_mono.unique())\n",
    "\n",
    "\n",
    "# --- 5) Level‑2 for dicot (guarded) ---\n",
    "dicot_mask = df[\"category1\"] == \"dicot\"\n",
    "X_dicot    = X[dicot_mask]\n",
    "y_dicot    = df.loc[dicot_mask, \"category2\"]\n",
    "\n",
    "if len(y_dicot.unique()) > 1:\n",
    "    X_tr_dico, X_val_dico, y_tr_dico, y_val_dico = train_test_split(\n",
    "        X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot\n",
    "    )\n",
    "    clf_l2_dico = RandomForestClassifier(random_state=42)\n",
    "    clf_l2_dico.fit(X_tr_dico, y_tr_dico)\n",
    "else:\n",
    "    clf_l2_dico = None\n",
    "    print(\"Skipping Level‑2 dicot model: only one class present:\", y_dicot.unique())\n",
    "\n",
    "# --- 6) Level‑3 species models (each guarded if needed) ---\n",
    "# Monocot‑Weed\n",
    "mask = (df[\"category1\"]==\"monocot\") & (df[\"category2\"]==\"weed\")\n",
    "clf_mono_weed = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_mono_weed.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# Monocot‑Crop\n",
    "# Monocot‑Crop\n",
    "mask = (df[\"category1\"]==\"monocot\") & (df[\"category2\"]==\"crop\")\n",
    "X_mono_crop = X.loc[mask]\n",
    "y_mono_crop = df.loc[mask, \"species\"]\n",
    "\n",
    "if len(y_mono_crop) > 0:\n",
    "    clf_mono_crop = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "    ])\n",
    "    clf_mono_crop.fit(X_mono_crop, y_mono_crop)\n",
    "else:\n",
    "    clf_mono_crop = None\n",
    "    print(\"Skipping monocot→crop model: no samples for that group.\")\n",
    "\n",
    "\n",
    "# Dicot‑Weed\n",
    "mask = (df[\"category1\"]==\"dicot\") & (df[\"category2\"]==\"weed\")\n",
    "clf_dico_weed = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_dico_weed.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# Dicot‑Crop\n",
    "mask = (df[\"category1\"]==\"dicot\") & (df[\"category2\"]==\"crop\")\n",
    "if mask.sum() > 0:\n",
    "    clf_dico_crop = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "    ])\n",
    "    clf_dico_crop.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "else:\n",
    "    clf_dico_crop = None\n",
    "\n",
    "# --- 7) Final species‑level prediction (with guard) ---\n",
    "final_preds = []\n",
    "for idx in X_test_l1.index:\n",
    "    cat1 = clf_l1.predict(X_test_l1.loc[[idx]])[0]\n",
    "\n",
    "    if cat1 == \"monocot\":\n",
    "        # —— guard monocot level‑2 ——\n",
    "        if clf_l2_mono is not None:\n",
    "            cat2 = clf_l2_mono.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            # if you only ever had 'weed' in training:\n",
    "            cat2 = df.loc[df[\"category1\"]==\"monocot\", \"category2\"].unique()[0]\n",
    "\n",
    "        # then species:\n",
    "        if cat2 == \"weed\":\n",
    "            sp = clf_mono_weed.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            # note: clf_mono_crop may also be None if that group was empty\n",
    "            if clf_mono_crop is not None:\n",
    "                sp = clf_mono_crop.predict(X_test_l1.loc[[idx]])[0]\n",
    "            else:\n",
    "                sp = df.loc[(df[\"category1\"]==\"monocot\") & \n",
    "                            (df[\"category2\"]==\"crop\"), \"species\"].unique()[0]\n",
    "\n",
    "    else:  # dicot branch\n",
    "        # —— guard dicot level‑2 ——\n",
    "        if clf_l2_dico is not None:\n",
    "            cat2 = clf_l2_dico.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            cat2 = df.loc[df[\"category1\"]==\"dicot\", \"category2\"].unique()[0]\n",
    "\n",
    "        # then species:\n",
    "        if cat2 == \"weed\":\n",
    "            sp = clf_dico_weed.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            if clf_dico_crop is not None:\n",
    "                sp = clf_dico_crop.predict(X_test_l1.loc[[idx]])[0]\n",
    "            else:\n",
    "                sp = df.loc[(df[\"category1\"]==\"dicot\") & \n",
    "                            (df[\"category2\"]==\"crop\"), \"species\"].unique()[0]\n",
    "\n",
    "    final_preds.append(sp)\n",
    "# right after your final_preds loop, but before evaluating:\n",
    "y_true = df.loc[X_test_l1.index, \"species\"]\n",
    "\n",
    "# now you can do:\n",
    "print(\"Accuracy:\", accuracy_score(y_true, final_preds))\n",
    "\n",
    "# --- 8) Evaluate ---\n",
    "print(\"Accuracy:\", accuracy_score(y_true, final_preds))\n",
    "cm      = confusion_matrix(y_true, final_preds)\n",
    "cm_pct  = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "print(pd.DataFrame(cm_pct, index=np.unique(y_true), columns=np.unique(y_true)))\n",
    "print(classification_report(y_true, final_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
