{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864b57f9-1f2d-4ccc-b126-4285f78e6ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"Indices weed-crop.xlsx\", sheet_name=\"LDA-P\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70be28f3-b7da-4851-9ddb-16b9822e31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 379 entries, 0 to 378\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   species  379 non-null    object \n",
      " 1   NDVI705  379 non-null    float64\n",
      " 2   PSNDa    379 non-null    float64\n",
      " 3   YI       379 non-null    float64\n",
      " 4   RES      379 non-null    float64\n",
      " 5   PRI      379 non-null    float64\n",
      " 6   NDVIa    379 non-null    float64\n",
      " 7   NDVIb    379 non-null    float64\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 23.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDVI705</th>\n",
       "      <th>PSNDa</th>\n",
       "      <th>YI</th>\n",
       "      <th>RES</th>\n",
       "      <th>PRI</th>\n",
       "      <th>NDVIa</th>\n",
       "      <th>NDVIb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.387010</td>\n",
       "      <td>0.751096</td>\n",
       "      <td>-0.003455</td>\n",
       "      <td>0.483246</td>\n",
       "      <td>0.019236</td>\n",
       "      <td>0.746177</td>\n",
       "      <td>0.745999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.068598</td>\n",
       "      <td>0.044318</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.051766</td>\n",
       "      <td>0.010576</td>\n",
       "      <td>0.043712</td>\n",
       "      <td>0.044391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.151134</td>\n",
       "      <td>0.633845</td>\n",
       "      <td>-0.008149</td>\n",
       "      <td>0.366196</td>\n",
       "      <td>-0.016347</td>\n",
       "      <td>0.631567</td>\n",
       "      <td>0.631622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.348724</td>\n",
       "      <td>0.713734</td>\n",
       "      <td>-0.004991</td>\n",
       "      <td>0.447254</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>0.709026</td>\n",
       "      <td>0.708186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.389580</td>\n",
       "      <td>0.754927</td>\n",
       "      <td>-0.003738</td>\n",
       "      <td>0.483541</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.749266</td>\n",
       "      <td>0.750070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.431031</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>0.781393</td>\n",
       "      <td>0.781890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.568353</td>\n",
       "      <td>0.831626</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.597451</td>\n",
       "      <td>0.040113</td>\n",
       "      <td>0.828343</td>\n",
       "      <td>0.829363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NDVI705       PSNDa          YI         RES         PRI       NDVIa  \\\n",
       "count  379.000000  379.000000  379.000000  379.000000  379.000000  379.000000   \n",
       "mean     0.387010    0.751096   -0.003455    0.483246    0.019236    0.746177   \n",
       "std      0.068598    0.044318    0.002185    0.051766    0.010576    0.043712   \n",
       "min      0.151134    0.633845   -0.008149    0.366196   -0.016347    0.631567   \n",
       "25%      0.348724    0.713734   -0.004991    0.447254    0.012936    0.709026   \n",
       "50%      0.389580    0.754927   -0.003738    0.483541    0.020106    0.749266   \n",
       "75%      0.431031    0.786404   -0.002300    0.522679    0.027104    0.781393   \n",
       "max      0.568353    0.831626    0.006127    0.597451    0.040113    0.828343   \n",
       "\n",
       "            NDVIb  \n",
       "count  379.000000  \n",
       "mean     0.745999  \n",
       "std      0.044391  \n",
       "min      0.631622  \n",
       "25%      0.708186  \n",
       "50%      0.750070  \n",
       "75%      0.781890  \n",
       "max      0.829363  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()       # Shows the first five rows\n",
    "df.info()       # Gives an overview of columns, data types, and non-null counts\n",
    "df.describe()   # Provides summary statistics for numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b07fbca-40f0-48f4-997d-599221148bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.82      1.00      0.90         9\n",
      "       BROSS       0.62      0.50      0.56        10\n",
      "    Camelina       0.82      0.90      0.86        10\n",
      "      Canola       0.75      0.60      0.67        10\n",
      "       DIPMU       0.80      0.89      0.84         9\n",
      "       LOLMU       0.56      0.56      0.56         9\n",
      "       PAPRH       0.88      0.78      0.82         9\n",
      "      Salvia       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.75        76\n",
      "   macro avg       0.75      0.75      0.75        76\n",
      "weighted avg       0.75      0.75      0.74        76\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGPR</th>\n",
       "      <th>BROSS</th>\n",
       "      <th>Camelina</th>\n",
       "      <th>Canola</th>\n",
       "      <th>DIPMU</th>\n",
       "      <th>LOLMU</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>Salvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASGPR</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROSS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camelina</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canola</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIPMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOLMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ASGPR      BROSS   Camelina  Canola      DIPMU      LOLMU  \\\n",
       "ASGPR     100.000000   0.000000   0.000000     0.0   0.000000   0.000000   \n",
       "BROSS       0.000000  50.000000  10.000000     0.0   0.000000  40.000000   \n",
       "Camelina    0.000000   0.000000  90.000000     0.0   0.000000   0.000000   \n",
       "Canola      0.000000   0.000000   0.000000    60.0  10.000000   0.000000   \n",
       "DIPMU       0.000000   0.000000  11.111111     0.0  88.888889   0.000000   \n",
       "LOLMU       0.000000  33.333333   0.000000     0.0  11.111111  55.555556   \n",
       "PAPRH      22.222222   0.000000   0.000000     0.0   0.000000   0.000000   \n",
       "Salvia      0.000000   0.000000   0.000000    20.0   0.000000   0.000000   \n",
       "\n",
       "              PAPRH  Salvia  \n",
       "ASGPR      0.000000     0.0  \n",
       "BROSS      0.000000     0.0  \n",
       "Camelina   0.000000    10.0  \n",
       "Canola    10.000000    20.0  \n",
       "DIPMU      0.000000     0.0  \n",
       "LOLMU      0.000000     0.0  \n",
       "PAPRH     77.777778     0.0  \n",
       "Salvia     0.000000    80.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'target' is the name of your target column:\n",
    "X = df.drop(\"species\", axis=1)  # Features\n",
    "y = df[\"species\"]               # Target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and train the random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = rf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Variable Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances from Random Forest')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()\n",
    "\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ea9118-8256-40ff-a898-3f54e18770ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Species-Level Accuracy: 0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       1.00      0.93      0.96        14\n",
      "       BROSS       1.00      0.80      0.89        10\n",
      "    Camelina       0.78      1.00      0.88         7\n",
      "      Canola       1.00      1.00      1.00         9\n",
      "       DIPMU       1.00      0.91      0.95        11\n",
      "       LOLMU       0.90      1.00      0.95         9\n",
      "       PAPRH       1.00      1.00      1.00         9\n",
      "      Salvia       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.95        76\n",
      "   macro avg       0.94      0.95      0.94        76\n",
      "weighted avg       0.96      0.95      0.95        76\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGPR</th>\n",
       "      <th>BROSS</th>\n",
       "      <th>Camelina</th>\n",
       "      <th>Canola</th>\n",
       "      <th>DIPMU</th>\n",
       "      <th>LOLMU</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>Salvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASGPR</th>\n",
       "      <td>92.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROSS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camelina</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canola</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIPMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOLMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ASGPR  BROSS    Camelina  Canola      DIPMU       LOLMU  PAPRH  \\\n",
       "ASGPR     92.857143    0.0    7.142857     0.0   0.000000    0.000000    0.0   \n",
       "BROSS      0.000000   80.0   10.000000     0.0   0.000000    0.000000    0.0   \n",
       "Camelina   0.000000    0.0  100.000000     0.0   0.000000    0.000000    0.0   \n",
       "Canola     0.000000    0.0    0.000000   100.0   0.000000    0.000000    0.0   \n",
       "DIPMU      0.000000    0.0    0.000000     0.0  90.909091    9.090909    0.0   \n",
       "LOLMU      0.000000    0.0    0.000000     0.0   0.000000  100.000000    0.0   \n",
       "PAPRH      0.000000    0.0    0.000000     0.0   0.000000    0.000000  100.0   \n",
       "Salvia     0.000000    0.0    0.000000     0.0   0.000000    0.000000    0.0   \n",
       "\n",
       "          Salvia  \n",
       "ASGPR        0.0  \n",
       "BROSS       10.0  \n",
       "Camelina     0.0  \n",
       "Canola       0.0  \n",
       "DIPMU        0.0  \n",
       "LOLMU        0.0  \n",
       "PAPRH        0.0  \n",
       "Salvia     100.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example lists of species for each category\n",
    "monocot_species = [\"LOLMU\",\"BROSS\"]  # example species\n",
    "dicot_species   = [\"PAPRH\",\"ASGPR\",\"Camelina\",\"Canola\",\"DIPMU\",\"Salvia\" ]\n",
    "weed_species    = [\"LOLMU\",\"BROSS\",\"PAPRH\",\"ASGPR\",\"DIPMU\"]  # example of some species labeled as weeds\n",
    "crop_species    = [\"Camelina\",\"Canola\",\"Salvia\"]\n",
    "\n",
    "# Third-level species groups (adjust these depending on your actual data):\n",
    "monocot_weed_species = [\"LOLMU\",\"BROSS\"]\n",
    "dicot_weed_species   = [\"PAPRH\",\"ASGPR\",\"DIPMU\"]\n",
    "dicot_crop_species = [\"Camelina\",\"Canola\",\"Salvia\"]\n",
    "\n",
    "# Assume df is your main dataframe with features and species\n",
    "# Example:\n",
    "# df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df[[\"NDVI705\",\"PSNDa\",\"YI\",\"RES\",\"PRI\",\"NDVIa\",\"NDVIb\"]]  # Features\n",
    "\n",
    "\n",
    "# Create first-level category\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "# Create second-level category\n",
    "df['category2'] = df['species'].apply(lambda s: 'weed' if s in weed_species else 'crop')\n",
    "\n",
    "\n",
    "y_cat1 = df[\"category1\"]  # Level 1 target \n",
    "\n",
    "# Level 1: Monocot vs Dicot\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1)\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "y_pred_cat1 = clf_cat1.predict(X_test_cat1)\n",
    "\n",
    "# Split test data by predicted category1\n",
    "X_test_monocot = X_test_cat1[y_pred_cat1 == 'monocot']\n",
    "X_test_dicot   = X_test_cat1[y_pred_cat1 == 'dicot']\n",
    "\n",
    "y_test_monocot = df.loc[X_test_monocot.index, 'category2']\n",
    "y_test_dicot   = df.loc[X_test_dicot.index, 'category2']\n",
    "\n",
    "# Level 2: Weed vs Crop (for monocot)\n",
    "monocot_mask = df['category1'] == 'monocot'\n",
    "X_monocot = X[monocot_mask]\n",
    "y_monocot = df['category2'][monocot_mask]\n",
    "\n",
    "X_train_mono, X_val_mono, y_train_mono, y_val_mono = train_test_split(X_monocot, y_monocot, test_size=0.2, random_state=42, stratify=y_monocot)\n",
    "clf_cat2_monocot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_monocot.fit(X_train_mono, y_train_mono)\n",
    "\n",
    "y_pred_cat2_monocot = clf_cat2_monocot.predict(X_test_monocot)\n",
    "\n",
    "# Level 2: Weed vs Crop (for dicot)\n",
    "dicot_mask = df['category1'] == 'dicot'\n",
    "X_dicot = X[dicot_mask]\n",
    "y_dicot = df['category2'][dicot_mask]\n",
    "\n",
    "X_train_di, X_val_di, y_train_di, y_val_di = train_test_split(X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot)\n",
    "clf_cat2_dicot = RandomForestClassifier(random_state=42)\n",
    "clf_cat2_dicot.fit(X_train_di, y_train_di)\n",
    "\n",
    "y_pred_cat2_dicot = clf_cat2_dicot.predict(X_test_dicot)\n",
    "\n",
    "# Now we have predictions for category1 and category2. Next: species level.\n",
    "\n",
    "# For the third level, we train separate models for each final group:\n",
    "# Monocot-Weed, Monocot-Crop, Dicot-Weed, Dicot-Crop.\n",
    "\n",
    "# Example: Monocot-Weed model (if multiple species in that group)\n",
    "mono_weed_mask = (df['category1'] == 'monocot') & (df['category2'] == 'weed')\n",
    "X_mono_weed = X[mono_weed_mask]\n",
    "y_mono_weed = df['species'][mono_weed_mask]\n",
    "\n",
    "clf_mono_weed = RandomForestClassifier(random_state=42)\n",
    "clf_mono_weed.fit(X_mono_weed, y_mono_weed)\n",
    "\n",
    "# Monocot-Crop model\n",
    "mono_crop_mask = (df['category1'] == 'monocot') & (df['category2'] == 'crop')\n",
    "X_mono_crop = X[mono_crop_mask]\n",
    "y_mono_crop = df['species'][mono_crop_mask]\n",
    "\n",
    "clf_mono_crop = RandomForestClassifier(random_state=42).fit(\n",
    "    X_mono_crop, y_mono_crop\n",
    ") if len(y_mono_crop) > 0 else None\n",
    "\n",
    "\n",
    "# Dicot-Weed model\n",
    "dicot_weed_mask = (df['category1'] == 'dicot') & (df['category2'] == 'weed')\n",
    "X_dicot_weed = X[dicot_weed_mask]\n",
    "y_dicot_weed = df['species'][dicot_weed_mask]\n",
    "\n",
    "clf_dicot_weed = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_weed.fit(X_dicot_weed, y_dicot_weed)\n",
    "\n",
    "# Dicot-Crop model\n",
    "dicot_crop_mask = (df['category1'] == 'dicot') & (df['category2'] == 'crop')\n",
    "X_dicot_crop = X[dicot_crop_mask]\n",
    "y_dicot_crop = df['species'][dicot_crop_mask]\n",
    "\n",
    "clf_dicot_crop = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_crop.fit(X_dicot_crop, y_dicot_crop)\n",
    "\n",
    "\n",
    "# Predict species level on the test set:\n",
    "# For each test sample, use the predicted category1 and category2 to decide which classifier to use at level 3.\n",
    "\n",
    "final_species_preds = []\n",
    "\n",
    "for idx in X_test_cat1.index:\n",
    "    cat1_pred = clf_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if cat1_pred == 'monocot':\n",
    "        cat2_pred = clf_cat2_monocot.predict(X_test_cat1.loc[[idx]])[0]  # use monocot model for cat2\n",
    "        if cat2_pred == 'weed':\n",
    "            sp_pred = clf_mono_weed.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        else:  # crop\n",
    "            sp_pred = clf_mono_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    else:  # dicot\n",
    "        cat2_pred = clf_cat2_dicot.predict(X_test_cat1.loc[[idx]])[0]  # use dicot model for cat2\n",
    "        if cat2_pred == 'weed':\n",
    "            sp_pred = clf_dicot_weed.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        else:  # crop\n",
    "            sp_pred = clf_dicot_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate accuracy of final species predictions:\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test_species,final_species_preds)\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "class_labels = np.unique(y_test_species)  # Adjust if needed\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "cm_df\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate and print the classification report\n",
    "report = classification_report(y_test_species, final_species_preds)\n",
    "print(report)\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633a958d-9b47-4a27-995e-4b31d67e4593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Species-Level Accuracy: 0.7368421052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.83      0.71      0.77        14\n",
      "       BROSS       0.60      0.30      0.40        10\n",
      "    Camelina       0.60      0.86      0.71         7\n",
      "      Canola       0.89      0.89      0.89         9\n",
      "       DIPMU       0.91      0.91      0.91        11\n",
      "       LOLMU       0.54      0.78      0.64         9\n",
      "       PAPRH       0.70      0.78      0.74         9\n",
      "      Salvia       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.74        76\n",
      "   macro avg       0.74      0.74      0.73        76\n",
      "weighted avg       0.75      0.74      0.73        76\n",
      "\n",
      "              ASGPR      BROSS   Camelina     Canola      DIPMU      LOLMU  \\\n",
      "ASGPR     71.428571   0.000000  14.285714   0.000000   0.000000   0.000000   \n",
      "BROSS      0.000000  30.000000  20.000000   0.000000   0.000000  50.000000   \n",
      "Camelina  14.285714   0.000000  85.714286   0.000000   0.000000   0.000000   \n",
      "Canola     0.000000   0.000000   0.000000  88.888889   0.000000   0.000000   \n",
      "DIPMU      0.000000   0.000000   0.000000   0.000000  90.909091   9.090909   \n",
      "LOLMU      0.000000  22.222222   0.000000   0.000000   0.000000  77.777778   \n",
      "PAPRH     11.111111   0.000000   0.000000  11.111111   0.000000   0.000000   \n",
      "Salvia     0.000000   0.000000   0.000000   0.000000  14.285714   0.000000   \n",
      "\n",
      "              PAPRH     Salvia  \n",
      "ASGPR     14.285714   0.000000  \n",
      "BROSS      0.000000   0.000000  \n",
      "Camelina   0.000000   0.000000  \n",
      "Canola     0.000000  11.111111  \n",
      "DIPMU      0.000000   0.000000  \n",
      "LOLMU      0.000000   0.000000  \n",
      "PAPRH     77.777778   0.000000  \n",
      "Salvia    14.285714  71.428571  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGPR</th>\n",
       "      <th>BROSS</th>\n",
       "      <th>Camelina</th>\n",
       "      <th>Canola</th>\n",
       "      <th>DIPMU</th>\n",
       "      <th>LOLMU</th>\n",
       "      <th>PAPRH</th>\n",
       "      <th>Salvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASGPR</th>\n",
       "      <td>71.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROSS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camelina</th>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canola</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIPMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOLMU</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPRH</th>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salvia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ASGPR      BROSS   Camelina     Canola      DIPMU      LOLMU  \\\n",
       "ASGPR     71.428571   0.000000  14.285714   0.000000   0.000000   0.000000   \n",
       "BROSS      0.000000  30.000000  20.000000   0.000000   0.000000  50.000000   \n",
       "Camelina  14.285714   0.000000  85.714286   0.000000   0.000000   0.000000   \n",
       "Canola     0.000000   0.000000   0.000000  88.888889   0.000000   0.000000   \n",
       "DIPMU      0.000000   0.000000   0.000000   0.000000  90.909091   9.090909   \n",
       "LOLMU      0.000000  22.222222   0.000000   0.000000   0.000000  77.777778   \n",
       "PAPRH     11.111111   0.000000   0.000000  11.111111   0.000000   0.000000   \n",
       "Salvia     0.000000   0.000000   0.000000   0.000000  14.285714   0.000000   \n",
       "\n",
       "              PAPRH     Salvia  \n",
       "ASGPR     14.285714   0.000000  \n",
       "BROSS      0.000000   0.000000  \n",
       "Camelina   0.000000   0.000000  \n",
       "Canola     0.000000  11.111111  \n",
       "DIPMU      0.000000   0.000000  \n",
       "LOLMU      0.000000   0.000000  \n",
       "PAPRH     77.777778   0.000000  \n",
       "Salvia    14.285714  71.428571  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1) Define your highlevel category\n",
    "# Example lists of species for each category\n",
    "monocot_species = [\"LOLMU\",\"BROSS\"]  # example species\n",
    "# everything else is dicot in your toy example\n",
    "df['category1'] = df['species'].apply(lambda s: 'monocot' if s in monocot_species else 'dicot')\n",
    "\n",
    "# 2) Pick only your numeric features automatically\n",
    "X = df[[\"NDVI705\",\"PSNDa\",\"YI\",\"RES\",\"PRI\",\"NDVIa\",\"NDVIb\"]]  # Features\n",
    "y_cat1 = df['category1']\n",
    "\n",
    "# 3) Split & train level1\n",
    "X1_tr, X1_te, y1_tr, y1_te = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "clf_cat1 = RandomForestClassifier(random_state=42)\n",
    "clf_cat1.fit(X1_tr, y1_tr)\n",
    "\n",
    "# 4) Train one speciesclassifier per category1 (on your existing train split)\n",
    "mono_idx = X_train_cat1[y_train_cat1=='monocot'].index\n",
    "dicot_idx = X_train_cat1[y_train_cat1=='dicot'].index\n",
    "\n",
    "clf_mono_species = RandomForestClassifier(random_state=42)\n",
    "clf_mono_species.fit(\n",
    "    X_train_cat1.loc[mono_idx],\n",
    "    df.loc[mono_idx, 'species']\n",
    ")\n",
    "\n",
    "clf_dicot_species = RandomForestClassifier(random_state=42)\n",
    "clf_dicot_species.fit(\n",
    "    X_train_cat1.loc[dicot_idx],\n",
    "    df.loc[dicot_idx, 'species']\n",
    ")\n",
    "\n",
    "# 5) Twostage prediction on X_test_cat1\n",
    "final_species_preds = []\n",
    "for idx in X_test_cat1.index:\n",
    "    cat1_pred = clf_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if cat1_pred == 'monocot':\n",
    "        sp_pred = clf_mono_species.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    else:  # dicot\n",
    "        sp_pred = clf_dicot_species.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    final_species_preds.append(sp_pred)\n",
    "\n",
    "final_species_preds = np.array(final_species_preds)\n",
    "y_test_species = df.loc[X_test_cat1.index, 'species']\n",
    "\n",
    "# Evaluate\n",
    "final_accuracy = accuracy_score(y_test_species, final_species_preds)\n",
    "print(\"Final Species-Level Accuracy:\", final_accuracy)\n",
    "print(classification_report(y_test_species, final_species_preds))\n",
    "\n",
    "cm = confusion_matrix(y_test_species, final_species_preds)\n",
    "cm_percentage = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "class_labels = np.unique(y_test_species)\n",
    "cm_df = pd.DataFrame(cm_percentage, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "cm_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8f282e-fd42-488f-81f3-6448038b4595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7368421052631579\n",
      "              ASGPR      BROSS   Camelina  Canola  DIPMU      LOLMU  \\\n",
      "ASGPR     77.777778   0.000000  11.111111     0.0    0.0   0.000000   \n",
      "BROSS      0.000000  70.000000   0.000000     0.0    0.0  30.000000   \n",
      "Camelina  10.000000   0.000000  90.000000     0.0    0.0   0.000000   \n",
      "Canola     0.000000   0.000000   0.000000    60.0    0.0   0.000000   \n",
      "DIPMU      0.000000   0.000000   0.000000     0.0  100.0   0.000000   \n",
      "LOLMU      0.000000  55.555556   0.000000     0.0    0.0  44.444444   \n",
      "PAPRH     22.222222   0.000000   0.000000     0.0    0.0   0.000000   \n",
      "Salvia     0.000000   0.000000  10.000000    20.0    0.0   0.000000   \n",
      "\n",
      "              PAPRH  Salvia  \n",
      "ASGPR     11.111111     0.0  \n",
      "BROSS      0.000000     0.0  \n",
      "Camelina   0.000000     0.0  \n",
      "Canola     0.000000    40.0  \n",
      "DIPMU      0.000000     0.0  \n",
      "LOLMU      0.000000     0.0  \n",
      "PAPRH     77.777778     0.0  \n",
      "Salvia     0.000000    70.0  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.70      0.78      0.74         9\n",
      "       BROSS       0.58      0.70      0.64        10\n",
      "    Camelina       0.82      0.90      0.86        10\n",
      "      Canola       0.75      0.60      0.67        10\n",
      "       DIPMU       1.00      1.00      1.00         9\n",
      "       LOLMU       0.57      0.44      0.50         9\n",
      "       PAPRH       0.88      0.78      0.82         9\n",
      "      Salvia       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.74        76\n",
      "   macro avg       0.74      0.74      0.74        76\n",
      "weighted avg       0.74      0.74      0.73        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepare data\n",
    "\n",
    "y = df[\"species\"]\n",
    "\n",
    "# 2) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3) Build a pipeline: scaling + KNN\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\",    KNeighborsClassifier(n_neighbors=5))  # you can tune n_neighbors\n",
    "])\n",
    "\n",
    "# 4) Train\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate accuracy\n",
    "accuracy = knn_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 6) Confusion matrix\n",
    "y_pred = knn_pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 7) Confusion matrix as percentages\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "class_labels = np.unique(y_test)\n",
    "cm_df = pd.DataFrame(cm_pct, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "# 8) Classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab829ea2-2ea4-49f0-8236-3c92ca730af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN final accuracy: 0.7368421052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.77      0.71      0.74        14\n",
      "       BROSS       1.00      0.40      0.57        10\n",
      "    Camelina       0.45      0.71      0.56         7\n",
      "      Canola       0.88      0.78      0.82         9\n",
      "       DIPMU       0.91      0.91      0.91        11\n",
      "       LOLMU       0.64      1.00      0.78         9\n",
      "       PAPRH       0.70      0.78      0.74         9\n",
      "      Salvia       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.74        76\n",
      "   macro avg       0.77      0.73      0.72        76\n",
      "weighted avg       0.78      0.74      0.73        76\n",
      "\n",
      "              ASGPR  BROSS   Camelina     Canola      DIPMU       LOLMU  \\\n",
      "ASGPR     71.428571    0.0  14.285714   0.000000   0.000000    0.000000   \n",
      "BROSS     10.000000   40.0  10.000000   0.000000   0.000000   40.000000   \n",
      "Camelina  14.285714    0.0  71.428571  14.285714   0.000000    0.000000   \n",
      "Canola     0.000000    0.0  11.111111  77.777778   0.000000    0.000000   \n",
      "DIPMU      0.000000    0.0   0.000000   0.000000  90.909091    9.090909   \n",
      "LOLMU      0.000000    0.0   0.000000   0.000000   0.000000  100.000000   \n",
      "PAPRH     11.111111    0.0  11.111111   0.000000   0.000000    0.000000   \n",
      "Salvia     0.000000    0.0  14.285714   0.000000  14.285714    0.000000   \n",
      "\n",
      "              PAPRH     Salvia  \n",
      "ASGPR     14.285714   0.000000  \n",
      "BROSS      0.000000   0.000000  \n",
      "Camelina   0.000000   0.000000  \n",
      "Canola     0.000000  11.111111  \n",
      "DIPMU      0.000000   0.000000  \n",
      "LOLMU      0.000000   0.000000  \n",
      "PAPRH     77.777778   0.000000  \n",
      "Salvia    14.285714  57.142857  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1) First split & train Level1 (Monocot vs Dicot) with KNN\n",
    "X_train_cat1, X_test_cat1, y_train_cat1, y_test_cat1 = train_test_split(\n",
    "    X, y_cat1, test_size=0.2, random_state=42, stratify=y_cat1\n",
    ")\n",
    "knn_cat1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat1.fit(X_train_cat1, y_train_cat1)\n",
    "\n",
    "# 2) Train Level2 KNNs\n",
    "knn_cat2_monocot = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat2_monocot.fit(X_monocot, y_monocot)\n",
    "\n",
    "knn_cat2_dicot = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_cat2_dicot.fit(X_dicot, y_dicot)\n",
    "\n",
    "# 3) Train Level3 speciesmodels\n",
    "knn_mono_weed = KNeighborsClassifier(n_neighbors=5).fit(X_mono_weed, y_mono_weed)\n",
    "knn_mono_crop = (KNeighborsClassifier(n_neighbors=5).fit(X_mono_crop, y_mono_crop)\n",
    "                 if len(y_mono_crop)>0 else None)\n",
    "knn_dicot_weed = KNeighborsClassifier(n_neighbors=5).fit(X_dicot_weed, y_dicot_weed)\n",
    "knn_dicot_crop = (KNeighborsClassifier(n_neighbors=5).fit(X_dicot_crop, y_dicot_crop)\n",
    "                  if len(y_dicot_crop)>0 else None)\n",
    "\n",
    "# 4) Threestage prediction loop\n",
    "final_preds_knn = []\n",
    "for idx in X_test_cat1.index:\n",
    "    c1 = knn_cat1.predict(X_test_cat1.loc[[idx]])[0]\n",
    "    if c1=='monocot':\n",
    "        c2 = knn_cat2_monocot.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        if c2=='weed':\n",
    "            final_preds_knn.append(knn_mono_weed.predict(X_test_cat1.loc[[idx]])[0])\n",
    "        else:\n",
    "            final_preds_knn.append(\n",
    "                knn_mono_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "                if knn_mono_crop else \"unknown\"\n",
    "            )\n",
    "    else:\n",
    "        c2 = knn_cat2_dicot.predict(X_test_cat1.loc[[idx]])[0]\n",
    "        if c2=='weed':\n",
    "            final_preds_knn.append(knn_dicot_weed.predict(X_test_cat1.loc[[idx]])[0])\n",
    "        else:\n",
    "            final_preds_knn.append(\n",
    "                knn_dicot_crop.predict(X_test_cat1.loc[[idx]])[0]\n",
    "                if knn_dicot_crop else \"unknown\"\n",
    "            )\n",
    "\n",
    "# 5) Evaluate\n",
    "print(\"KNN final accuracy:\", accuracy_score(y_test_species, final_preds_knn))\n",
    "print(classification_report(y_test_species, final_preds_knn))\n",
    "\n",
    "cm_knn = confusion_matrix(y_test_species, final_preds_knn)\n",
    "cm_pct_knn = cm_knn.astype(float)/cm_knn.sum(axis=1)[:,None]*100\n",
    "cm_knn_df = pd.DataFrame(cm_pct_knn, index=np.unique(y_test_species), columns=np.unique(y_test_species))\n",
    "print(cm_knn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d19654ed-7fdd-4a91-a109-7253ae45d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "              ASGPR      BROSS    Camelina  Canola      DIPMU      LOLMU  \\\n",
      "ASGPR     77.777778   0.000000   11.111111     0.0   0.000000   0.000000   \n",
      "BROSS      0.000000  70.000000    0.000000     0.0   0.000000  30.000000   \n",
      "Camelina   0.000000   0.000000  100.000000     0.0   0.000000   0.000000   \n",
      "Canola     0.000000   0.000000    0.000000    70.0   0.000000   0.000000   \n",
      "DIPMU      0.000000   0.000000   11.111111     0.0  88.888889   0.000000   \n",
      "LOLMU      0.000000  55.555556    0.000000     0.0   0.000000  44.444444   \n",
      "PAPRH     22.222222   0.000000    0.000000     0.0   0.000000   0.000000   \n",
      "Salvia     0.000000   0.000000   10.000000    20.0   0.000000   0.000000   \n",
      "\n",
      "              PAPRH  Salvia  \n",
      "ASGPR     11.111111     0.0  \n",
      "BROSS      0.000000     0.0  \n",
      "Camelina   0.000000     0.0  \n",
      "Canola     0.000000    30.0  \n",
      "DIPMU      0.000000     0.0  \n",
      "LOLMU      0.000000     0.0  \n",
      "PAPRH     77.777778     0.0  \n",
      "Salvia     0.000000    70.0  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.78      0.78      0.78         9\n",
      "       BROSS       0.58      0.70      0.64        10\n",
      "    Camelina       0.77      1.00      0.87        10\n",
      "      Canola       0.78      0.70      0.74        10\n",
      "       DIPMU       1.00      0.89      0.94         9\n",
      "       LOLMU       0.57      0.44      0.50         9\n",
      "       PAPRH       0.88      0.78      0.82         9\n",
      "      Salvia       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.75        76\n",
      "   macro avg       0.76      0.75      0.75        76\n",
      "weighted avg       0.75      0.75      0.75        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepare data\n",
    "\n",
    "y = df[\"species\"]\n",
    "\n",
    "# 2) Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3) Build a pipeline: scaling + SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(\n",
    "        kernel=\"rbf\",       # try \"linear\" if you want coefficients\n",
    "        C=1.0,              # regularization parameter\n",
    "        probability=False,  # set True if you need predict_proba\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4) Train\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate accuracy\n",
    "accuracy = svm_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 6) Confusion matrix\n",
    "y_pred = svm_pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 7) Confusion matrix as percentages\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "class_labels = np.unique(y_test)\n",
    "cm_df = pd.DataFrame(cm_pct, index=class_labels, columns=class_labels)\n",
    "print(cm_df)\n",
    "\n",
    "# 8) Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 9) (Optional) Feature importance for a linear SVM:\n",
    "# If you switch to kernel=\"linear\", you can inspect svm_pipeline.named_steps['svc'].coef_\n",
    "# to see per-class feature weights:\n",
    "#\n",
    "# linear_svc = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"svc\",    SVC(kernel=\"linear\", C=1.0, random_state=42))\n",
    "# ])\n",
    "# linear_svc.fit(X_train, y_train)\n",
    "# coefs = linear_svc.named_steps['svc'].coef_\n",
    "# feature_names = X.columns\n",
    "# # coefs is shape (n_classes, n_features) for multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd66fd4f-7b6e-4c01-8888-a7f129043e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Level2 monocot model: only one class present: ['weed']\n",
      "Skipping monocotcrop model: no samples for that group.\n",
      "Accuracy: 0.8552631578947368\n",
      "Accuracy: 0.8552631578947368\n",
      "              ASGPR      BROSS    Camelina     Canola      DIPMU      LOLMU  \\\n",
      "ASGPR     92.857143   0.000000    7.142857   0.000000   0.000000   0.000000   \n",
      "BROSS      0.000000  60.000000   10.000000   0.000000   0.000000  30.000000   \n",
      "Camelina   0.000000   0.000000  100.000000   0.000000   0.000000   0.000000   \n",
      "Canola     0.000000   0.000000    0.000000  88.888889   0.000000   0.000000   \n",
      "DIPMU      0.000000   0.000000    0.000000   0.000000  90.909091   9.090909   \n",
      "LOLMU      0.000000  11.111111    0.000000   0.000000   0.000000  88.888889   \n",
      "PAPRH     11.111111   0.000000    0.000000   0.000000   0.000000   0.000000   \n",
      "Salvia     0.000000   0.000000    0.000000  28.571429   0.000000   0.000000   \n",
      "\n",
      "              PAPRH     Salvia  \n",
      "ASGPR      0.000000   0.000000  \n",
      "BROSS      0.000000   0.000000  \n",
      "Camelina   0.000000   0.000000  \n",
      "Canola     0.000000  11.111111  \n",
      "DIPMU      0.000000   0.000000  \n",
      "LOLMU      0.000000   0.000000  \n",
      "PAPRH     88.888889   0.000000  \n",
      "Salvia     0.000000  71.428571  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ASGPR       0.93      0.93      0.93        14\n",
      "       BROSS       0.86      0.60      0.71        10\n",
      "    Camelina       0.78      1.00      0.88         7\n",
      "      Canola       0.80      0.89      0.84         9\n",
      "       DIPMU       1.00      0.91      0.95        11\n",
      "       LOLMU       0.67      0.89      0.76         9\n",
      "       PAPRH       1.00      0.89      0.94         9\n",
      "      Salvia       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.86        76\n",
      "   macro avg       0.86      0.85      0.85        76\n",
      "weighted avg       0.87      0.86      0.85        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# --- 1) Define your species groups ---\n",
    "monocot_species = [\"LOLMU\",\"BROSS\"]  # example species\n",
    "dicot_species   = [\"PAPRH\",\"ASGPR\",\"Camelina\",\"Canola\",\"DIPMU\",\"Salvia\" ]\n",
    "weed_species    = [\"LOLMU\",\"BROSS\",\"PAPRH\",\"ASGPR\",\"DIPMU\"]  # example of some species labeled as weeds\n",
    "crop_species    = [\"Camelina\",\"Canola\",\"Salvia\"]\n",
    "\n",
    "\n",
    "# --- 2) Prepare your DataFrame ---\n",
    "# assume df is already loaded, with numeric features + a \"species\" column\n",
    "X = df.select_dtypes(include=[np.number])\n",
    "df[\"species\"] = df[\"species\"].astype(str)  # ensure no weird types\n",
    "\n",
    "# create hierarchical labels\n",
    "df[\"category1\"] = df[\"species\"].map(lambda s: \"monocot\" if s in monocot_species else \"dicot\")\n",
    "df[\"category2\"] = df[\"species\"].map(lambda s: \"weed\"    if s in weed_species    else \"crop\")\n",
    "\n",
    "# --- 3) Level1: monocot vs dicot ---\n",
    "X_train_l1, X_test_l1, y_train_l1, y_test_l1 = train_test_split(\n",
    "    X, df[\"category1\"], test_size=0.2, random_state=42, stratify=df[\"category1\"]\n",
    ")\n",
    "clf_l1 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_l1.fit(X_train_l1, y_train_l1)\n",
    "y_pred_l1 = clf_l1.predict(X_test_l1)\n",
    "\n",
    "# split test by predicted level1\n",
    "X_test_mono = X_test_l1[y_pred_l1 == \"monocot\"]\n",
    "X_test_dico = X_test_l1[y_pred_l1 == \"dicot\"]\n",
    "\n",
    "# --- 4) Level2 for monocot ---\n",
    "# --- Level2 for monocot (guarded) ---\n",
    "mono_mask = df[\"category1\"] == \"monocot\"\n",
    "X_mono    = X[mono_mask]\n",
    "y_mono    = df.loc[mono_mask, \"category2\"]\n",
    "\n",
    "if len(y_mono.unique()) > 1:\n",
    "    X_tr_mono, X_val_mono, y_tr_mono, y_val_mono = train_test_split(\n",
    "        X_mono, y_mono, test_size=0.2, random_state=42, stratify=y_mono\n",
    "    )\n",
    "    clf_l2_mono = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "    ])\n",
    "    clf_l2_mono.fit(X_tr_mono, y_tr_mono)\n",
    "else:\n",
    "    clf_l2_mono = None\n",
    "    print(\"Skipping Level2 monocot model: only one class present:\", y_mono.unique())\n",
    "\n",
    "\n",
    "# --- 5) Level2 for dicot (guarded) ---\n",
    "dicot_mask = df[\"category1\"] == \"dicot\"\n",
    "X_dicot    = X[dicot_mask]\n",
    "y_dicot    = df.loc[dicot_mask, \"category2\"]\n",
    "\n",
    "if len(y_dicot.unique()) > 1:\n",
    "    X_tr_dico, X_val_dico, y_tr_dico, y_val_dico = train_test_split(\n",
    "        X_dicot, y_dicot, test_size=0.2, random_state=42, stratify=y_dicot\n",
    "    )\n",
    "    clf_l2_dico = RandomForestClassifier(random_state=42)\n",
    "    clf_l2_dico.fit(X_tr_dico, y_tr_dico)\n",
    "else:\n",
    "    clf_l2_dico = None\n",
    "    print(\"Skipping Level2 dicot model: only one class present:\", y_dicot.unique())\n",
    "\n",
    "# --- 6) Level3 species models (each guarded if needed) ---\n",
    "# MonocotWeed\n",
    "mask = (df[\"category1\"]==\"monocot\") & (df[\"category2\"]==\"weed\")\n",
    "clf_mono_weed = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_mono_weed.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# MonocotCrop\n",
    "# MonocotCrop\n",
    "mask = (df[\"category1\"]==\"monocot\") & (df[\"category2\"]==\"crop\")\n",
    "X_mono_crop = X.loc[mask]\n",
    "y_mono_crop = df.loc[mask, \"species\"]\n",
    "\n",
    "if len(y_mono_crop) > 0:\n",
    "    clf_mono_crop = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "    ])\n",
    "    clf_mono_crop.fit(X_mono_crop, y_mono_crop)\n",
    "else:\n",
    "    clf_mono_crop = None\n",
    "    print(\"Skipping monocotcrop model: no samples for that group.\")\n",
    "\n",
    "\n",
    "# DicotWeed\n",
    "mask = (df[\"category1\"]==\"dicot\") & (df[\"category2\"]==\"weed\")\n",
    "clf_dico_weed = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "])\n",
    "clf_dico_weed.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "\n",
    "# DicotCrop\n",
    "mask = (df[\"category1\"]==\"dicot\") & (df[\"category2\"]==\"crop\")\n",
    "if mask.sum() > 0:\n",
    "    clf_dico_crop = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\",    SVC(kernel=\"rbf\", C=1.0, random_state=42))\n",
    "    ])\n",
    "    clf_dico_crop.fit(X.loc[mask], df.loc[mask, \"species\"])\n",
    "else:\n",
    "    clf_dico_crop = None\n",
    "\n",
    "# --- 7) Final specieslevel prediction (with guard) ---\n",
    "final_preds = []\n",
    "for idx in X_test_l1.index:\n",
    "    cat1 = clf_l1.predict(X_test_l1.loc[[idx]])[0]\n",
    "\n",
    "    if cat1 == \"monocot\":\n",
    "        #  guard monocot level2 \n",
    "        if clf_l2_mono is not None:\n",
    "            cat2 = clf_l2_mono.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            # if you only ever had 'weed' in training:\n",
    "            cat2 = df.loc[df[\"category1\"]==\"monocot\", \"category2\"].unique()[0]\n",
    "\n",
    "        # then species:\n",
    "        if cat2 == \"weed\":\n",
    "            sp = clf_mono_weed.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            # note: clf_mono_crop may also be None if that group was empty\n",
    "            if clf_mono_crop is not None:\n",
    "                sp = clf_mono_crop.predict(X_test_l1.loc[[idx]])[0]\n",
    "            else:\n",
    "                sp = df.loc[(df[\"category1\"]==\"monocot\") & \n",
    "                            (df[\"category2\"]==\"crop\"), \"species\"].unique()[0]\n",
    "\n",
    "    else:  # dicot branch\n",
    "        #  guard dicot level2 \n",
    "        if clf_l2_dico is not None:\n",
    "            cat2 = clf_l2_dico.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            cat2 = df.loc[df[\"category1\"]==\"dicot\", \"category2\"].unique()[0]\n",
    "\n",
    "        # then species:\n",
    "        if cat2 == \"weed\":\n",
    "            sp = clf_dico_weed.predict(X_test_l1.loc[[idx]])[0]\n",
    "        else:\n",
    "            if clf_dico_crop is not None:\n",
    "                sp = clf_dico_crop.predict(X_test_l1.loc[[idx]])[0]\n",
    "            else:\n",
    "                sp = df.loc[(df[\"category1\"]==\"dicot\") & \n",
    "                            (df[\"category2\"]==\"crop\"), \"species\"].unique()[0]\n",
    "\n",
    "    final_preds.append(sp)\n",
    "# right after your final_preds loop, but before evaluating:\n",
    "y_true = df.loc[X_test_l1.index, \"species\"]\n",
    "\n",
    "# now you can do:\n",
    "print(\"Accuracy:\", accuracy_score(y_true, final_preds))\n",
    "\n",
    "# --- 8) Evaluate ---\n",
    "print(\"Accuracy:\", accuracy_score(y_true, final_preds))\n",
    "cm      = confusion_matrix(y_true, final_preds)\n",
    "cm_pct  = cm.astype(float) / cm.sum(axis=1)[:, None] * 100\n",
    "print(pd.DataFrame(cm_pct, index=np.unique(y_true), columns=np.unique(y_true)))\n",
    "print(classification_report(y_true, final_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
